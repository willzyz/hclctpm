{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scaffold for Michelangelo customers \n",
    "## authors: will.zou@uber.com dmantar@uber.com \n",
    "## Causal Models for real-time incentives \n",
    "## import libraries and modules \n",
    "\n",
    "import sys, os, pandas as pd, numpy as np, pickle as pkl, tensorflow as tf \n",
    "sys.path.append('../dataprep/') \n",
    "from QueryFunctions import * \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### pull data either using queryrunner or using csv \n",
    "use_query = 0 ### turn this switch on (to 1.0/True vs 0.0/False) to run query using QueryRunner \n",
    "use_python3 = True \n",
    "\n",
    "if use_query: \n",
    "    from queryrunner_client import Client \n",
    "    qr = Client(user_email='will.zou@uber.com') \n",
    "    ##label_dates_weekly = \"'2019-07-14', '2019-07-21', '2019-07-28', '2019-08-04'\" \n",
    "    ##city_ids = '1,5,6,8,10,12,20,23,198' \n",
    "    #feature_dates=\"'2019-06-30'\" \n",
    "    #proposal_start_date = '2019-07-08' \n",
    "    \n",
    "    predFrame2 = qr.execute('presto', rt_data_presto_first()) \n",
    "    predFrame2 = pd.DataFrame(predFrame2.load_data()) \n",
    "else: \n",
    "    predFrame2 = pd.read_csv('../data/rt_query_result_rider.csv') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of dataset:\n",
      "152417\n",
      "size of control cohort:\n",
      "124645\n",
      "size of treatment cohort:\n",
      "27772\n"
     ]
    }
   ],
   "source": [
    "### Cross check on treatment and control cohort sizes \n",
    "cohort_column_name = 'treatment' \n",
    "treatment_indicator_value = True \n",
    "control_indicator_value = False \n",
    "print('size of dataset:') \n",
    "print(len(predFrame2)) \n",
    "print('size of control cohort:') \n",
    "print(sum(predFrame2[cohort_column_name] == control_indicator_value)) \n",
    "print('size of treatment cohort:') \n",
    "print(sum(predFrame2[cohort_column_name] == treatment_indicator_value)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### we should process the data such that route level cost and gains are per-session \n",
    "### so it's possible to rank the routes separately and it should be able to compare with results for \n",
    "### using rider information only \n",
    "\n",
    "### three data tables: \n",
    "### 1. with rider + route features and per route metrics \n",
    "### 2. with rider features and per rider metrics \n",
    "### 3. with route features and per route metrics \n",
    "\n",
    "### for table 1, we can have two algorithms \n",
    "### a. train a model on Table 2, score the riders as a feature for route-level model, then use route level model to evaluate \n",
    "### b. train a combined model on table 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nans: 28779\n",
      "number of nans: 3011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/will.zou/code/deeplearning_hscls/py3/lib/python3.6/site-packages/ipykernel_launcher.py:90: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nans: 3011\n",
      "number of nans: 3016\n",
      "number of nans: 3016\n",
      "number of nans: 3011\n",
      "number of nans: 3011\n",
      "number of nans: 3011\n",
      "number of nans: 4123\n",
      "number of nans: 4123\n",
      "number of nans: 3011\n",
      "number of nans: 100966\n",
      "number of nans: 3011\n",
      "number of nans: 3011\n",
      "number of nans: 3025\n",
      "number of nans: 3089\n",
      "number of nans: 3011\n",
      "number of nans: 4123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/will.zou/code/deeplearning_hscls/py3/lib/python3.6/site-packages/ipykernel_launcher.py:94: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rpu_treated : 67.8501334702578\n",
      "nipu_treated : -4.760137201665052\n",
      "rpu_untreated : 58.15015138020138\n",
      "nipu_untreated : 6.383521133572327\n",
      "cpit : 1.1488328773989065\n"
     ]
    }
   ],
   "source": [
    "### preprocess the data \n",
    "### -- sample treatment to match control cohort \n",
    "### -- eliminate nulls, standard normalization \n",
    "\n",
    "D = predFrame2 \n",
    "D = D.sample(frac=1.0) \n",
    "\n",
    "\"\"\"\n",
    "feature_list = [ \n",
    "    'rating_2driver_min_avg_84d'\n",
    "    , 'trip_incomplete_total_84d'\n",
    "    , 'days_active_84d'\n",
    "    , 'days_since_trip_first_lifetime'\n",
    "    , 'days_since_last_hard_churn_lifetime'\n",
    "    , 'days_since_last_soft_churn_lifetime'\n",
    "    , 'fare_max_sd_84d'\n",
    "    , 'churns_hard_lifetime'\n",
    "    , 'trips_lifetime'\n",
    "    , 'fare_max_p50_84d'\n",
    "    , 'duration_session_pre_request_max_p50_84d'\n",
    "    , 'trip_pool_per_x_84d'\n",
    "    , 'fare_total_win7d_sd_84d'\n",
    "    , 'trip_complete_win7d_sd_84d'\n",
    "    , 'session_per_days_active_84d'\n",
    "    , 'churns_soft_lifetime'\n",
    "    , 'trip_complete_per_days_active_84d'\n",
    "    , 'trip_pool_prc_84d'\n",
    "    , 'session_background_pre_request_prc_84d'\n",
    "    , 'session_lt_1m_prc_84d'\n",
    "    , 'session_request_prc_84d'\n",
    "    , 'duration_session_outside_total_prc_84d'\n",
    "    , 'trip_x_prc_84d'\n",
    "    , 'days_since_trip_last_lifetime'\n",
    "    , 'promo_used_84d'\n",
    "    , 'has_session_request_84d'\n",
    "    , 'has_session_without_request_84d' \n",
    "    , 'fare_promo_total_avg_84d', \n",
    "    'fare_total_avg_84d', \n",
    "    'surge_trip_avg_84d', \n",
    "    'fare_total_win7d_potential_84d', \n",
    "    'fare_total_win28d_potential_84d', \n",
    "    'fare_lifetime', \n",
    "    'time_to_first_message_minutes_mean_lifetime', \n",
    "    'ata_trip_max_avg_84d', \n",
    "    'eta_trip_max_avg_84d', \n",
    "    'trip_pool_matched_avg_84d', \n",
    "    'payment_cash_trip_total_84d', \n",
    "    'duration_trip_total_p50_84d'\n",
    "] \n",
    "\"\"\"\n",
    "feature_list = [ \n",
    "    'rating_2driver_min_avg_84d'\n",
    "    , 'days_active_84d'\n",
    "    , 'days_since_trip_first_lifetime'\n",
    "    , 'days_since_last_soft_churn_lifetime'\n",
    "    , 'churns_hard_lifetime'\n",
    "    , 'fare_max_p50_84d'\n",
    "    , 'fare_total_win7d_sd_84d'\n",
    "    , 'trip_complete_win7d_sd_84d'\n",
    "    , 'trip_pool_prc_84d'\n",
    "    , 'session_request_prc_84d'\n",
    "    , 'days_since_trip_last_lifetime'\n",
    "    , 'fare_promo_total_avg_84d'\n",
    "    , 'fare_total_avg_84d'\n",
    "    , 'surge_trip_avg_84d'\n",
    "    , 'fare_total_win28d_potential_84d'\n",
    "    , 'ata_trip_max_avg_84d'\n",
    "    , 'duration_trip_total_p50_84d'\n",
    "    , 'promo_used_84d'\n",
    "#    , 'estimate_fare_distance_in_miles' \n",
    "#    , 'estimate_fare_duration_in_minutes' \n",
    "#    , 'origin_destination_haversine_miles' \n",
    "#    , 'origin_lat' \n",
    "#    , 'origin_lng'\n",
    "#    , 'destination_lat'\n",
    "#    , 'destination_lng'  \n",
    "] \n",
    "\n",
    "label_list = [ \n",
    "    'gross_bookings_usd', \n",
    "    'variable_contribution_usd', \n",
    "    'num_sessions' \n",
    "] \n",
    "\n",
    "for l in feature_list: \n",
    "    print('number of nans: ' + str(sum(D[l] == '\\\\N'))) \n",
    "    D[l] = pd.to_numeric(D[l], errors='coerce') \n",
    "    D[l] = D[l] - D[l].mean() \n",
    "    D[l] = D[l] / D[l].std() \n",
    "    D[l][pd.isnull(D[l])] = 0.0 ## at zero mean due to standard normalization \n",
    "\n",
    "for l in label_list: \n",
    "    D[l] = pd.to_numeric(D[l], errors='coerce') \n",
    "    D[l][pd.isnull(D[l])] = 0.0 ## for zero gain/cost for financial data \n",
    "\n",
    "### -- compute simple statistics \n",
    "### compute cpit \n",
    "treated_entries = D[D[cohort_column_name] == treatment_indicator_value] \n",
    "untreated_entries = D[D[cohort_column_name] == control_indicator_value] \n",
    "\n",
    "rpu_treated = float(treated_entries[label_list[0]].sum()) / len(treated_entries) \n",
    "nipu_treated = float(treated_entries[label_list[1]].sum()) / len(treated_entries) \n",
    "\n",
    "rpu_untreated = float(untreated_entries[label_list[0]].sum()) / len(untreated_entries) \n",
    "nipu_untreated = float(untreated_entries[label_list[1]].sum()) / len(untreated_entries) \n",
    "\n",
    "cpit = -1.0 * (nipu_treated - nipu_untreated) / (rpu_treated - rpu_untreated) \n",
    "\n",
    "print('rpu_treated : ' + str(rpu_treated)) \n",
    "print('nipu_treated : ' + str(nipu_treated)) \n",
    "print('rpu_untreated : ' + str(rpu_untreated)) \n",
    "print('nipu_untreated : ' + str(nipu_untreated)) \n",
    "print('cpit : ' + str(cpit)) \n",
    "\n",
    "### split the data into 3/1/1 train/val/test \n",
    "len_tr = int(len(D) / 5 * 3) \n",
    "len_va = int(len(D) / 10 * 1) \n",
    "\n",
    "nX = D[feature_list].values \n",
    "w = D[cohort_column_name].apply(lambda x: 1.0 if x == treatment_indicator_value else 0.0) \n",
    "w = w.values \n",
    "values = D[label_list[0]] \n",
    "values = values.values * 1.0 \n",
    "negcost = D[label_list[1]] \n",
    "negcost = negcost.values * 1.0 \n",
    "num_sessions = D[label_list[2]].values \n",
    "#values = np.divide(values, num_sessions) \n",
    "#negcost = np.divide(negcost, num_sessions) \n",
    "\n",
    "## split train/val/test sets \n",
    "\n",
    "nX_tr = nX[0:len_tr, :] \n",
    "nX_va = nX[len_tr:len_tr + len_va, :] \n",
    "nX_te = nX[len_tr + len_va:, :] \n",
    "\n",
    "w_tr = w[0:len_tr]\n",
    "w_va = w[len_tr:len_tr + len_va] \n",
    "w_te = w[len_tr + len_va:] \n",
    "\n",
    "values_tr = values[0:len_tr] \n",
    "values_va = values[len_tr:len_tr + len_va] \n",
    "values_te = values[len_tr + len_va:] \n",
    "\n",
    "negcost_tr = negcost[0:len_tr] \n",
    "\n",
    "negcost_va = negcost[len_tr:len_tr + len_va] \n",
    "\n",
    "negcost_te = negcost[len_tr + len_va:] \n",
    "\n",
    "## saving data using cPickel and naming the dictionaries \n",
    "saveD = {'nX_tr':nX_tr, \n",
    "         'w_tr':w_tr, \n",
    "         'values_tr':values_tr, \n",
    "         'nX_va':nX_va, \n",
    "         'w_va':w_va, \n",
    "         'values_va':values_va, \n",
    "         'nX_te':nX_te, \n",
    "         'w_te':w_te, \n",
    "         'values_te':values_te, \n",
    "         'feature_list':feature_list, \n",
    "         #'avg_ni_usd_tr':avg_ni_usd_tr, \n",
    "         'negcost_tr': negcost_tr, \n",
    "         #'avg_ni_usd_va':avg_ni_usd_va, \n",
    "         'negcost_va': negcost_va, \n",
    "         #'avg_ni_usd_te':avg_ni_usd_te, \n",
    "         'negcost_te': negcost_te \n",
    "         } \n",
    "\n",
    "pkl.dump(saveD, open('../data/rt_ma_training_data_v5_2019_07_08_vc_tr_featuremod3_rider', 'wb')) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total gross bookings: 9132459.525520967\n",
      "total variable contribution: 663475.4613294642\n"
     ]
    }
   ],
   "source": [
    "sum(num_sessions)\n",
    "print('total gross bookings: ' + str(sum(values)))\n",
    "print('total variable contribution: ' + str(sum(negcost)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nD=predFrame2\\nD[D['rider_uuid']=='b57c08f5-edfd-441c-ad2d-08ecda3391fb']\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "D=predFrame2\n",
    "D[D['rider_uuid']=='b57c08f5-edfd-441c-ad2d-08ecda3391fb']\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24428"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(negcost == 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data from ../data/rt_ma_training_data_v5_2019_07_08_vc_tr_featuremod3_rider\n",
      "printing averages of c_tr, c_unt, o_tre, o_unt ... :\n",
      "4.030008179960382\n",
      "-6.293439949881827\n",
      "68.08112415559155\n",
      "58.4632452017676\n",
      "### ----- start the training of deep learning models ------ \n",
      "------> Training TQR ranking model .... \n",
      "---> running cross validation, iteration: 0\n",
      "WARNING:tensorflow:From ../ModelDefinitions.py:37: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From ../ModelDefinitions.py:37: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "WARNING:tensorflow:From ../ModelDefinitions.py:38: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /Users/will.zou/code/deeplearning_hscls/py3/lib/python3.6/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From ../ModelDefinitions.py:74: The name tf.ceil is deprecated. Please use tf.math.ceil instead.\n",
      "\n",
      "WARNING:tensorflow:From ../ModelDefinitions.py:115: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "opt. step : 0 obj: 1.1172842481901468\n",
      "setting temperature to :0.6\n",
      "opt. step : 100 obj: 1.071792302798357\n",
      "setting temperature to :0.7\n",
      "opt. step : 200 obj: 1.010369510145437\n",
      "setting temperature to :0.7999999999999999\n",
      "opt. step : 300 obj: 0.954210090953986\n",
      "setting temperature to :0.8999999999999999\n",
      "opt. step : 400 obj: 0.9128870729026213\n",
      "setting temperature to :0.9999999999999999\n",
      "opt. step : 500 obj: 0.8810362769412781\n",
      "setting temperature to :1.0999999999999999\n",
      "opt. step : 600 obj: 0.8535306885286423\n",
      "setting temperature to :1.2\n",
      "opt. step : 700 obj: 0.8306744247916548\n",
      "setting temperature to :1.3\n",
      "opt. step : 800 obj: 0.8133385785150158\n",
      "setting temperature to :1.4000000000000001\n",
      "opt. step : 900 obj: 0.7996762304159803\n",
      "setting temperature to :1.5000000000000002\n",
      "opt. step : 1000 obj: 0.7885910583878382\n",
      "setting temperature to :1.6000000000000003\n",
      "opt. step : 1100 obj: 0.7793674340937503\n",
      "setting temperature to :1.7000000000000004\n",
      "opt. step : 1200 obj: 0.7712292070369247\n",
      "setting temperature to :1.8000000000000005\n",
      "opt. step : 1300 obj: 0.7642070510024218\n",
      "setting temperature to :1.9000000000000006\n",
      "opt. step : 1400 obj: 0.7584141725567725\n",
      "setting temperature to :2.0000000000000004\n",
      "opt. step : 1500 obj: 0.7532534082093851\n",
      "setting temperature to :2.1000000000000005\n",
      "opt. step : 1600 obj: 0.7486419639478801\n",
      "setting temperature to :2.2000000000000006\n",
      "opt. step : 1700 obj: 0.7441584309044317\n",
      "setting temperature to :2.3000000000000007\n",
      "opt. step : 1800 obj: 0.7395005003522213\n",
      "setting temperature to :2.400000000000001\n",
      "opt. step : 1900 obj: 0.7357274454622847\n",
      "setting temperature to :2.500000000000001\n",
      "---> optimization finished ... \n",
      "temp:\n",
      "2.5341311445373425\n",
      "p_quantile:\n",
      "0.4\n",
      "validation CPIT:\n",
      "1.9803275923471755\n",
      "---> running cross validation, iteration: 1\n",
      "opt. step : 0 obj: 1.0225496493098825\n",
      "setting temperature to :0.6\n",
      "opt. step : 100 obj: 0.9668035917762111\n",
      "setting temperature to :0.7\n",
      "opt. step : 200 obj: 0.9278348652709622\n",
      "setting temperature to :0.7999999999999999\n",
      "opt. step : 300 obj: 0.8931993395262112\n",
      "setting temperature to :0.8999999999999999\n",
      "opt. step : 400 obj: 0.8640095550988037\n",
      "setting temperature to :0.9999999999999999\n",
      "opt. step : 500 obj: 0.8402240047951229\n",
      "setting temperature to :1.0999999999999999\n",
      "opt. step : 600 obj: 0.8199669412847178\n",
      "setting temperature to :1.2\n",
      "opt. step : 700 obj: 0.803470902652023\n",
      "setting temperature to :1.3\n",
      "opt. step : 800 obj: 0.7905358270683771\n",
      "setting temperature to :1.4000000000000001\n",
      "opt. step : 900 obj: 0.7799198278895346\n",
      "setting temperature to :1.5000000000000002\n",
      "opt. step : 1000 obj: 0.7707448193688893\n",
      "setting temperature to :1.6000000000000003\n",
      "opt. step : 1100 obj: 0.7629044800248125\n",
      "setting temperature to :1.7000000000000004\n",
      "opt. step : 1200 obj: 0.7560879478301039\n",
      "setting temperature to :1.8000000000000005\n",
      "opt. step : 1300 obj: 0.7499189939919303\n",
      "setting temperature to :1.9000000000000006\n",
      "opt. step : 1400 obj: 0.7438806839363266\n",
      "setting temperature to :2.0000000000000004\n",
      "opt. step : 1500 obj: 0.7388103803220794\n",
      "setting temperature to :2.1000000000000005\n",
      "opt. step : 1600 obj: 0.7347133801939381\n",
      "setting temperature to :2.2000000000000006\n",
      "opt. step : 1700 obj: 0.7311288590776198\n",
      "setting temperature to :2.3000000000000007\n",
      "opt. step : 1800 obj: 0.7281203034799528\n",
      "setting temperature to :2.400000000000001\n",
      "opt. step : 1900 obj: 0.7254816724846761\n",
      "setting temperature to :2.500000000000001\n",
      "---> optimization finished ... \n",
      "temp:\n",
      "2.531837396198079\n",
      "p_quantile:\n",
      "0.4\n",
      "validation CPIT:\n",
      "2.07454471803775\n",
      "best performing model: iteration 0\n",
      "------> Training DRM ranking model .... \n",
      "---> running cross validation, iteration: 0\n",
      "opt. step : 0 obj: 1.1522713042472823\n",
      "opt. step : 100 obj: 1.0104248017837563\n",
      "opt. step : 200 obj: 0.921286928438385\n",
      "opt. step : 300 obj: 0.8456572718915772\n",
      "opt. step : 400 obj: 0.7113891453086942\n",
      "opt. step : 500 obj: 0.6516320108298362\n",
      "opt. step : 600 obj: 0.6169724469894949\n",
      "opt. step : 700 obj: 0.5966726702737439\n",
      "opt. step : 800 obj: 0.5824714882938232\n",
      "opt. step : 900 obj: 0.5713559385623261\n",
      "opt. step : 1000 obj: 0.5622080323529668\n",
      "opt. step : 1100 obj: 0.554321922384537\n",
      "opt. step : 1200 obj: 0.547486184859335\n",
      "opt. step : 1300 obj: 0.5416622237669741\n",
      "opt. step : 1400 obj: 0.5366804705301469\n",
      "opt. step : 1500 obj: 0.5323357809987789\n",
      "opt. step : 1600 obj: 0.5284720791535058\n",
      "opt. step : 1700 obj: 0.5249781275124336\n",
      "opt. step : 1800 obj: 0.5217654343266077\n",
      "opt. step : 1900 obj: 0.5187303494231496\n",
      "---> optimization finished ... \n",
      "validation CPIT:\n",
      "2.5751231240738295\n",
      "---> running cross validation, iteration: 1\n",
      "opt. step : 0 obj: 0.8362269296030275\n",
      "opt. step : 100 obj: 0.7346487791611993\n",
      "opt. step : 200 obj: 0.6773799234624626\n",
      "opt. step : 300 obj: 0.6426204951659246\n",
      "opt. step : 400 obj: 0.619753337928934\n",
      "opt. step : 500 obj: 0.6031916650723819\n",
      "opt. step : 600 obj: 0.588076846014025\n",
      "opt. step : 700 obj: 0.5752587000258169\n",
      "opt. step : 800 obj: 0.5655951520835482\n",
      "opt. step : 900 obj: 0.5574460389026556\n",
      "opt. step : 1000 obj: 0.550642199480866\n",
      "opt. step : 1100 obj: 0.5449158462671595\n",
      "opt. step : 1200 obj: 0.5400160979731623\n",
      "opt. step : 1300 obj: 0.5357594868950155\n",
      "opt. step : 1400 obj: 0.5320082169644899\n",
      "opt. step : 1500 obj: 0.5286588486282802\n",
      "opt. step : 1600 obj: 0.5256335557694353\n",
      "opt. step : 1700 obj: 0.522873345544304\n",
      "opt. step : 1800 obj: 0.5203329919759987\n",
      "opt. step : 1900 obj: 0.5179773374781812\n",
      "---> optimization finished ... \n",
      "validation CPIT:\n",
      "2.5082241806443624\n",
      "best performing model: iteration 1\n",
      "rpu_control: 57.541300766652434\n",
      "nipu_control: 6.395390112802487\n",
      "rpu_ft: 67.05182163537381\n",
      "nipu_ft: -4.223677512349505\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.10\n",
      "treated_target_rpu: 75.35\n",
      "treated_target_nipu: -2.94\n",
      "nontreated_target_rpu: 58.54\n",
      "nontreated_target_nipu: 6.24\n",
      "treated_nontarget_rpu: 66.09\n",
      "treated_nontarget_nipu: -4.37\n",
      "nontreated_nontarget_rpu: 57.43\n",
      "nontreated_nontarget_nipu: 6.41\n",
      "--- with 9.998687836241963% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 0.5463007776144976\n",
      "--> in non-targeted users: \n",
      "cpit = 1.246271451361194\n",
      "rpu_control: 57.54\n",
      "nipu_control: 6.40\n",
      "rpu_ft: 67.05\n",
      "nipu_ft: -4.22\n",
      "rpu_cohort: 59.22\n",
      "nipu_cohort: 5.48\n",
      "lift targeted cohort vs control: 0.03\n",
      "lift random vs control: 0.17\n",
      "cpit cohort vs control: 0.55\n",
      "lift targeted-treated vs control: 0.31\n",
      "cpit cohort: 0.546056\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.20\n",
      "treated_target_rpu: 72.04\n",
      "treated_target_nipu: -2.73\n",
      "nontreated_target_rpu: 59.41\n",
      "nontreated_target_nipu: 6.71\n",
      "treated_nontarget_rpu: 65.75\n",
      "treated_nontarget_nipu: -4.61\n",
      "nontreated_nontarget_rpu: 57.08\n",
      "nontreated_nontarget_nipu: 6.32\n",
      "--- with 19.997375672483926% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 0.7475782411204974\n",
      "--> in non-targeted users: \n",
      "cpit = 1.2602809322723523\n",
      "rpu_control: 57.54\n",
      "nipu_control: 6.40\n",
      "rpu_ft: 67.05\n",
      "nipu_ft: -4.22\n",
      "rpu_cohort: 60.07\n",
      "nipu_cohort: 4.51\n",
      "lift targeted cohort vs control: 0.04\n",
      "lift random vs control: 0.17\n",
      "cpit cohort vs control: 0.75\n",
      "lift targeted-treated vs control: 0.25\n",
      "cpit cohort: 0.746313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------->>>>>>\n",
      "perc - target: 0.30\n",
      "treated_target_rpu: 69.77\n",
      "treated_target_nipu: -2.70\n",
      "nontreated_target_rpu: 58.50\n",
      "nontreated_target_nipu: 6.68\n",
      "treated_nontarget_rpu: 65.87\n",
      "treated_nontarget_nipu: -4.89\n",
      "nontreated_nontarget_rpu: 57.13\n",
      "nontreated_nontarget_nipu: 6.27\n",
      "--- with 29.99606350872589% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 0.8327594728355239\n",
      "--> in non-targeted users: \n",
      "cpit = 1.2772081183666502\n",
      "rpu_control: 57.54\n",
      "nipu_control: 6.40\n",
      "rpu_ft: 67.05\n",
      "nipu_ft: -4.22\n",
      "rpu_cohort: 60.92\n",
      "nipu_cohort: 3.58\n",
      "lift targeted cohort vs control: 0.06\n",
      "lift random vs control: 0.17\n",
      "cpit cohort vs control: 0.83\n",
      "lift targeted-treated vs control: 0.21\n",
      "cpit cohort: 0.832422\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.40\n",
      "treated_target_rpu: 69.83\n",
      "treated_target_nipu: -2.58\n",
      "nontreated_target_rpu: 58.83\n",
      "nontreated_target_nipu: 6.87\n",
      "treated_nontarget_rpu: 65.16\n",
      "treated_nontarget_nipu: -5.34\n",
      "nontreated_nontarget_rpu: 56.69\n",
      "nontreated_nontarget_nipu: 6.08\n",
      "--- with 39.99475134496785% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 0.8591200656813865\n",
      "--> in non-targeted users: \n",
      "cpit = 1.3474407160275665\n",
      "rpu_control: 57.54\n",
      "nipu_control: 6.40\n",
      "rpu_ft: 67.05\n",
      "nipu_ft: -4.22\n",
      "rpu_cohort: 61.94\n",
      "nipu_cohort: 2.61\n",
      "lift targeted cohort vs control: 0.08\n",
      "lift random vs control: 0.17\n",
      "cpit cohort vs control: 0.86\n",
      "lift targeted-treated vs control: 0.21\n",
      "cpit cohort: 0.858498\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.50\n",
      "treated_target_rpu: 69.57\n",
      "treated_target_nipu: -2.50\n",
      "nontreated_target_rpu: 58.01\n",
      "nontreated_target_nipu: 6.76\n",
      "treated_nontarget_rpu: 64.50\n",
      "treated_nontarget_nipu: -5.97\n",
      "nontreated_nontarget_rpu: 57.07\n",
      "nontreated_nontarget_nipu: 6.03\n",
      "--- with 49.993439181209816% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 0.8017576414131872\n",
      "--> in non-targeted users: \n",
      "cpit = 1.614814551939696\n",
      "rpu_control: 57.54\n",
      "nipu_control: 6.40\n",
      "rpu_ft: 67.05\n",
      "nipu_ft: -4.22\n",
      "rpu_cohort: 63.32\n",
      "nipu_cohort: 1.76\n",
      "lift targeted cohort vs control: 0.10\n",
      "lift random vs control: 0.17\n",
      "cpit cohort vs control: 0.80\n",
      "lift targeted-treated vs control: 0.21\n",
      "cpit cohort: 0.801561\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.60\n",
      "treated_target_rpu: 68.36\n",
      "treated_target_nipu: -2.47\n",
      "nontreated_target_rpu: 57.54\n",
      "nontreated_target_nipu: 6.66\n",
      "treated_nontarget_rpu: 65.08\n",
      "treated_nontarget_nipu: -6.86\n",
      "nontreated_nontarget_rpu: 57.54\n",
      "nontreated_nontarget_nipu: 6.00\n",
      "--- with 59.99212701745178% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 0.8440628876240891\n",
      "--> in non-targeted users: \n",
      "cpit = 1.7051802011974204\n",
      "rpu_control: 57.54\n",
      "nipu_control: 6.40\n",
      "rpu_ft: 67.05\n",
      "nipu_ft: -4.22\n",
      "rpu_cohort: 64.03\n",
      "nipu_cohort: 0.92\n",
      "lift targeted cohort vs control: 0.11\n",
      "lift random vs control: 0.17\n",
      "cpit cohort vs control: 0.84\n",
      "lift targeted-treated vs control: 0.19\n",
      "cpit cohort: 0.844043\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.70\n",
      "treated_target_rpu: 67.83\n",
      "treated_target_nipu: -2.55\n",
      "nontreated_target_rpu: 57.58\n",
      "nontreated_target_nipu: 6.19\n",
      "treated_nontarget_rpu: 65.30\n",
      "treated_nontarget_nipu: -7.96\n",
      "nontreated_nontarget_rpu: 57.44\n",
      "nontreated_nontarget_nipu: 6.88\n",
      "--- with 69.99081485369373% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 0.8532617048896773\n",
      "--> in non-targeted users: \n",
      "cpit = 1.8887633071891488\n",
      "rpu_control: 57.54\n",
      "nipu_control: 6.40\n",
      "rpu_ft: 67.05\n",
      "nipu_ft: -4.22\n",
      "rpu_cohort: 64.72\n",
      "nipu_cohort: 0.28\n",
      "lift targeted cohort vs control: 0.12\n",
      "lift random vs control: 0.17\n",
      "cpit cohort vs control: 0.85\n",
      "lift targeted-treated vs control: 0.18\n",
      "cpit cohort: 0.853116\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.80\n",
      "treated_target_rpu: 66.84\n",
      "treated_target_nipu: -3.23\n",
      "nontreated_target_rpu: 57.34\n",
      "nontreated_target_nipu: 6.25\n",
      "treated_nontarget_rpu: 67.88\n",
      "treated_nontarget_nipu: -8.03\n",
      "nontreated_nontarget_rpu: 58.36\n",
      "nontreated_nontarget_nipu: 6.98\n",
      "--- with 79.9895026899357% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 0.9981924316570838\n",
      "--> in non-targeted users: \n",
      "cpit = 1.5773760010797793\n",
      "rpu_control: 57.54\n",
      "nipu_control: 6.40\n",
      "rpu_ft: 67.05\n",
      "nipu_ft: -4.22\n",
      "rpu_cohort: 65.14\n",
      "nipu_cohort: -1.19\n",
      "lift targeted cohort vs control: 0.13\n",
      "lift random vs control: 0.17\n",
      "cpit cohort vs control: 1.00\n",
      "lift targeted-treated vs control: 0.16\n",
      "cpit cohort: 0.997849\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.90\n",
      "treated_target_rpu: 67.13\n",
      "treated_target_nipu: -4.51\n",
      "nontreated_target_rpu: 57.44\n",
      "nontreated_target_nipu: 6.33\n",
      "treated_nontarget_rpu: 66.31\n",
      "treated_nontarget_nipu: -1.59\n",
      "nontreated_nontarget_rpu: 58.44\n",
      "nontreated_nontarget_nipu: 6.95\n",
      "--- with 89.98819052617768% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.1191544075174524\n",
      "--> in non-targeted users: \n",
      "cpit = 1.0843490671812808\n",
      "rpu_control: 57.54\n",
      "nipu_control: 6.40\n",
      "rpu_ft: 67.05\n",
      "nipu_ft: -4.22\n",
      "rpu_cohort: 66.26\n",
      "nipu_cohort: -3.37\n",
      "lift targeted cohort vs control: 0.15\n",
      "lift random vs control: 0.17\n",
      "cpit cohort vs control: 1.12\n",
      "lift targeted-treated vs control: 0.17\n",
      "cpit cohort: 1.119205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../experimentation.py:109: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  treated_untarget_rpu = sum(1.0 * values[treated_untargeted_filter]) / sum(treated_untargeted_filter)\n",
      "../experimentation.py:110: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  treated_untarget_nipu = sum(1.0 * n9d_ni_usd[treated_untargeted_filter]) / sum(treated_untargeted_filter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rpu_cohort\n",
      "66.26241439614891\n",
      "treated_target_rpu\n",
      "67.05182163537394\n",
      "---------------------------->>>>>>\n",
      "perc - target: 1.00\n",
      "treated_target_rpu: 67.05\n",
      "treated_target_nipu: -4.22\n",
      "nontreated_target_rpu: 57.55\n",
      "nontreated_target_nipu: 6.40\n",
      "treated_nontarget_rpu: nan\n",
      "treated_nontarget_nipu: nan\n",
      "nontreated_nontarget_rpu: 23.44\n",
      "nontreated_nontarget_nipu: 2.23\n",
      "--- with 99.98687836241963% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.1172720209140743\n",
      "--> in non-targeted users: \n",
      "cpit = nan\n",
      "rpu_control: 57.54\n",
      "nipu_control: 6.40\n",
      "rpu_ft: 67.05\n",
      "nipu_ft: -4.22\n",
      "rpu_cohort: 67.05\n",
      "nipu_cohort: -4.22\n",
      "lift targeted cohort vs control: 0.17\n",
      "lift random vs control: 0.17\n",
      "cpit cohort vs control: 1.12\n",
      "lift targeted-treated vs control: 0.17\n",
      "cpit cohort: 1.116560\n",
      "rpu_control: 57.541300766652434\n",
      "nipu_control: 6.395390112802487\n",
      "rpu_ft: 67.05182163537381\n",
      "nipu_ft: -4.223677512349505\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.10\n",
      "treated_target_rpu: 152.31\n",
      "treated_target_nipu: -10.66\n",
      "nontreated_target_rpu: 114.74\n",
      "nontreated_target_nipu: 7.61\n",
      "treated_nontarget_rpu: 58.00\n",
      "treated_nontarget_nipu: -3.54\n",
      "nontreated_nontarget_rpu: 51.12\n",
      "nontreated_nontarget_nipu: 6.26\n",
      "--- with 9.998687836241963% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 0.4861284605353192\n",
      "--> in non-targeted users: \n",
      "cpit = 1.4243540522733409\n",
      "rpu_control: 57.54\n",
      "nipu_control: 6.40\n",
      "rpu_ft: 67.05\n",
      "nipu_ft: -4.22\n",
      "rpu_cohort: 61.24\n",
      "nipu_cohort: 4.57\n",
      "lift targeted cohort vs control: 0.06\n",
      "lift random vs control: 0.17\n",
      "cpit cohort vs control: 0.49\n",
      "lift targeted-treated vs control: 1.65\n",
      "cpit cohort: 0.493926\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.20\n",
      "treated_target_rpu: 118.72\n",
      "treated_target_nipu: -7.72\n",
      "nontreated_target_rpu: 95.23\n",
      "nontreated_target_nipu: 7.94\n",
      "treated_nontarget_rpu: 54.50\n",
      "treated_nontarget_nipu: -3.37\n",
      "nontreated_nontarget_rpu: 48.06\n",
      "nontreated_nontarget_nipu: 6.01\n",
      "--- with 19.997375672483926% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 0.666561341380937\n",
      "--> in non-targeted users: \n",
      "cpit = 1.4581618781357037\n",
      "rpu_control: 57.54\n",
      "nipu_control: 6.40\n",
      "rpu_ft: 67.05\n",
      "nipu_ft: -4.22\n",
      "rpu_cohort: 62.19\n",
      "nipu_cohort: 3.26\n",
      "lift targeted cohort vs control: 0.08\n",
      "lift random vs control: 0.17\n",
      "cpit cohort vs control: 0.67\n",
      "lift targeted-treated vs control: 1.06\n",
      "cpit cohort: 0.673646\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.30\n",
      "treated_target_rpu: 103.23\n",
      "treated_target_nipu: -5.92\n",
      "nontreated_target_rpu: 83.83\n",
      "nontreated_target_nipu: 7.37\n",
      "treated_nontarget_rpu: 51.78\n",
      "treated_nontarget_nipu: -3.51\n",
      "nontreated_nontarget_rpu: 46.24\n",
      "nontreated_nontarget_nipu: 5.98\n",
      "--- with 29.99606350872589% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 0.6850196430991897\n",
      "--> in non-targeted users: \n",
      "cpit = 1.7133405492000684\n",
      "rpu_control: 57.54\n",
      "nipu_control: 6.40\n",
      "rpu_ft: 67.05\n",
      "nipu_ft: -4.22\n",
      "rpu_cohort: 63.34\n",
      "nipu_cohort: 2.41\n",
      "lift targeted cohort vs control: 0.10\n",
      "lift random vs control: 0.17\n",
      "cpit cohort vs control: 0.69\n",
      "lift targeted-treated vs control: 0.79\n",
      "cpit cohort: 0.688204\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.40\n",
      "treated_target_rpu: 92.86\n",
      "treated_target_nipu: -6.23\n",
      "nontreated_target_rpu: 76.58\n",
      "nontreated_target_nipu: 7.14\n",
      "treated_nontarget_rpu: 49.96\n",
      "treated_nontarget_nipu: -2.89\n",
      "nontreated_nontarget_rpu: 44.84\n",
      "nontreated_nontarget_nipu: 5.90\n",
      "--- with 39.99475134496785% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 0.821421892684078\n",
      "--> in non-targeted users: \n",
      "cpit = 1.7144166313731097\n",
      "rpu_control: 57.54\n",
      "nipu_control: 6.40\n",
      "rpu_ft: 67.05\n",
      "nipu_ft: -4.22\n",
      "rpu_cohort: 64.04\n",
      "nipu_cohort: 1.05\n",
      "lift targeted cohort vs control: 0.11\n",
      "lift random vs control: 0.17\n",
      "cpit cohort vs control: 0.82\n",
      "lift targeted-treated vs control: 0.61\n",
      "cpit cohort: 0.822876\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.50\n",
      "treated_target_rpu: 86.06\n",
      "treated_target_nipu: -5.30\n",
      "nontreated_target_rpu: 70.29\n",
      "nontreated_target_nipu: 6.81\n",
      "treated_nontarget_rpu: 48.14\n",
      "treated_nontarget_nipu: -3.15\n",
      "nontreated_nontarget_rpu: 44.78\n",
      "nontreated_nontarget_nipu: 5.98\n",
      "--- with 49.993439181209816% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 0.7682588899894035\n",
      "--> in non-targeted users: \n",
      "cpit = 2.711723548900605\n",
      "rpu_control: 57.54\n",
      "nipu_control: 6.40\n",
      "rpu_ft: 67.05\n",
      "nipu_ft: -4.22\n",
      "rpu_cohort: 65.42\n",
      "nipu_cohort: 0.34\n",
      "lift targeted cohort vs control: 0.14\n",
      "lift random vs control: 0.17\n",
      "cpit cohort vs control: 0.77\n",
      "lift targeted-treated vs control: 0.50\n",
      "cpit cohort: 0.768983\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.60\n",
      "treated_target_rpu: 80.32\n",
      "treated_target_nipu: -4.70\n",
      "nontreated_target_rpu: 66.51\n",
      "nontreated_target_nipu: 6.73\n",
      "treated_nontarget_rpu: 47.32\n",
      "treated_nontarget_nipu: -3.51\n",
      "nontreated_nontarget_rpu: 44.06\n",
      "nontreated_nontarget_nipu: 5.89\n",
      "--- with 59.99212701745178% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 0.828642074367843\n",
      "--> in non-targeted users: \n",
      "cpit = 2.8825532424408\n",
      "rpu_control: 57.54\n",
      "nipu_control: 6.40\n",
      "rpu_ft: 67.05\n",
      "nipu_ft: -4.22\n",
      "rpu_cohort: 65.81\n",
      "nipu_cohort: -0.47\n",
      "lift targeted cohort vs control: 0.14\n",
      "lift random vs control: 0.17\n",
      "cpit cohort vs control: 0.83\n",
      "lift targeted-treated vs control: 0.40\n",
      "cpit cohort: 0.829643\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.70\n",
      "treated_target_rpu: 75.78\n",
      "treated_target_nipu: -6.04\n",
      "nontreated_target_rpu: 63.61\n",
      "nontreated_target_nipu: 6.62\n",
      "treated_nontarget_rpu: 46.81\n",
      "treated_nontarget_nipu: -0.00\n",
      "nontreated_nontarget_rpu: 43.36\n",
      "nontreated_nontarget_nipu: 5.87\n",
      "--- with 69.99081485369373% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.0403577238072603\n",
      "--> in non-targeted users: \n",
      "cpit = 1.7059457737307617\n",
      "rpu_control: 57.54\n",
      "nipu_control: 6.40\n",
      "rpu_ft: 67.05\n",
      "nipu_ft: -4.22\n",
      "rpu_cohort: 66.05\n",
      "nipu_cohort: -2.47\n",
      "lift targeted cohort vs control: 0.15\n",
      "lift random vs control: 0.17\n",
      "cpit cohort vs control: 1.04\n",
      "lift targeted-treated vs control: 0.32\n",
      "cpit cohort: 1.041072\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.80\n",
      "treated_target_rpu: 72.23\n",
      "treated_target_nipu: -5.33\n",
      "nontreated_target_rpu: 61.26\n",
      "nontreated_target_nipu: 6.52\n",
      "treated_nontarget_rpu: 46.33\n",
      "treated_nontarget_nipu: 0.22\n",
      "nontreated_nontarget_rpu: 42.69\n",
      "nontreated_nontarget_nipu: 5.89\n",
      "--- with 79.9895026899357% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.0808888837627189\n",
      "--> in non-targeted users: \n",
      "cpit = 1.5556394187303602\n",
      "rpu_control: 57.54\n",
      "nipu_control: 6.40\n",
      "rpu_ft: 67.05\n",
      "nipu_ft: -4.22\n",
      "rpu_cohort: 66.32\n",
      "nipu_cohort: -3.09\n",
      "lift targeted cohort vs control: 0.15\n",
      "lift random vs control: 0.17\n",
      "cpit cohort vs control: 1.08\n",
      "lift targeted-treated vs control: 0.26\n",
      "cpit cohort: 1.080759\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.90\n",
      "treated_target_rpu: 69.45\n",
      "treated_target_nipu: -4.75\n",
      "nontreated_target_rpu: 59.25\n",
      "nontreated_target_nipu: 6.44\n",
      "treated_nontarget_rpu: 45.35\n",
      "treated_nontarget_nipu: 0.57\n",
      "nontreated_nontarget_rpu: 42.18\n",
      "nontreated_nontarget_nipu: 5.99\n",
      "--- with 89.98819052617768% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.0981727156838006\n",
      "--> in non-targeted users: \n",
      "cpit = 1.7129986574607408\n",
      "rpu_control: 57.54\n",
      "nipu_control: 6.40\n",
      "rpu_ft: 67.05\n",
      "nipu_ft: -4.22\n",
      "rpu_cohort: 66.72\n",
      "nipu_cohort: -3.68\n",
      "lift targeted cohort vs control: 0.16\n",
      "lift random vs control: 0.17\n",
      "cpit cohort vs control: 1.10\n",
      "lift targeted-treated vs control: 0.21\n",
      "cpit cohort: 1.097805\n",
      "rpu_cohort\n",
      "66.71537641975326\n",
      "treated_target_rpu\n",
      "67.05182163537394\n",
      "---------------------------->>>>>>\n",
      "perc - target: 1.00\n",
      "treated_target_rpu: 67.05\n",
      "treated_target_nipu: -4.22\n",
      "nontreated_target_rpu: 57.53\n",
      "nontreated_target_nipu: 6.39\n",
      "treated_nontarget_rpu: nan\n",
      "treated_nontarget_nipu: nan\n",
      "nontreated_nontarget_rpu: 109.55\n",
      "nontreated_nontarget_nipu: 15.86\n",
      "--- with 99.98687836241963% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.1154236066428616\n",
      "--> in non-targeted users: \n",
      "cpit = nan\n",
      "rpu_control: 57.54\n",
      "nipu_control: 6.40\n",
      "rpu_ft: 67.05\n",
      "nipu_ft: -4.22\n",
      "rpu_cohort: 67.05\n",
      "nipu_cohort: -4.22\n",
      "lift targeted cohort vs control: 0.17\n",
      "lift random vs control: 0.17\n",
      "cpit cohort vs control: 1.12\n",
      "lift targeted-treated vs control: 0.17\n",
      "cpit cohort: 1.116560\n",
      "rpu_control: 57.541300766652434\n",
      "nipu_control: 6.395390112802487\n",
      "rpu_ft: 67.05182163537381\n",
      "nipu_ft: -4.223677512349505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------->>>>>>\n",
      "perc - target: 0.10\n",
      "treated_target_rpu: 143.53\n",
      "treated_target_nipu: -10.08\n",
      "nontreated_target_rpu: 106.64\n",
      "nontreated_target_nipu: 6.88\n",
      "treated_nontarget_rpu: 58.81\n",
      "treated_nontarget_nipu: -3.59\n",
      "nontreated_nontarget_rpu: 52.05\n",
      "nontreated_nontarget_nipu: 6.34\n",
      "--- with 9.998687836241963% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 0.4595705721094528\n",
      "--> in non-targeted users: \n",
      "cpit = 1.4694192252856568\n",
      "rpu_control: 57.54\n",
      "nipu_control: 6.40\n",
      "rpu_ft: 67.05\n",
      "nipu_ft: -4.22\n",
      "rpu_cohort: 61.20\n",
      "nipu_cohort: 4.70\n",
      "lift targeted cohort vs control: 0.06\n",
      "lift random vs control: 0.17\n",
      "cpit cohort vs control: 0.46\n",
      "lift targeted-treated vs control: 1.49\n",
      "cpit cohort: 0.463778\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.20\n",
      "treated_target_rpu: 114.19\n",
      "treated_target_nipu: -7.43\n",
      "nontreated_target_rpu: 89.74\n",
      "nontreated_target_nipu: 7.23\n",
      "treated_nontarget_rpu: 55.37\n",
      "treated_nontarget_nipu: -3.43\n",
      "nontreated_nontarget_rpu: 49.48\n",
      "nontreated_nontarget_nipu: 6.19\n",
      "--- with 19.997375672483926% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 0.5992090474003278\n",
      "--> in non-targeted users: \n",
      "cpit = 1.630764529699965\n",
      "rpu_control: 57.54\n",
      "nipu_control: 6.40\n",
      "rpu_ft: 67.05\n",
      "nipu_ft: -4.22\n",
      "rpu_cohort: 62.42\n",
      "nipu_cohort: 3.46\n",
      "lift targeted cohort vs control: 0.08\n",
      "lift random vs control: 0.17\n",
      "cpit cohort vs control: 0.60\n",
      "lift targeted-treated vs control: 0.98\n",
      "cpit cohort: 0.600859\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.30\n",
      "treated_target_rpu: 99.40\n",
      "treated_target_nipu: -5.81\n",
      "nontreated_target_rpu: 80.80\n",
      "nontreated_target_nipu: 6.93\n",
      "treated_nontarget_rpu: 53.45\n",
      "treated_nontarget_nipu: -3.56\n",
      "nontreated_nontarget_rpu: 47.53\n",
      "nontreated_nontarget_nipu: 6.16\n",
      "--- with 29.99606350872589% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 0.6850292428999205\n",
      "--> in non-targeted users: \n",
      "cpit = 1.6432162577260392\n",
      "rpu_control: 57.54\n",
      "nipu_control: 6.40\n",
      "rpu_ft: 67.05\n",
      "nipu_ft: -4.22\n",
      "rpu_cohort: 63.09\n",
      "nipu_cohort: 2.57\n",
      "lift targeted cohort vs control: 0.10\n",
      "lift random vs control: 0.17\n",
      "cpit cohort vs control: 0.69\n",
      "lift targeted-treated vs control: 0.73\n",
      "cpit cohort: 0.688710\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.40\n",
      "treated_target_rpu: 89.94\n",
      "treated_target_nipu: -6.14\n",
      "nontreated_target_rpu: 74.73\n",
      "nontreated_target_nipu: 6.94\n",
      "treated_nontarget_rpu: 51.76\n",
      "treated_nontarget_nipu: -2.95\n",
      "nontreated_nontarget_rpu: 46.09\n",
      "nontreated_nontarget_nipu: 6.03\n",
      "--- with 39.99475134496785% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 0.8593119799489477\n",
      "--> in non-targeted users: \n",
      "cpit = 1.5834438649798612\n",
      "rpu_control: 57.54\n",
      "nipu_control: 6.40\n",
      "rpu_ft: 67.05\n",
      "nipu_ft: -4.22\n",
      "rpu_cohort: 63.63\n",
      "nipu_cohort: 1.17\n",
      "lift targeted cohort vs control: 0.11\n",
      "lift random vs control: 0.17\n",
      "cpit cohort vs control: 0.86\n",
      "lift targeted-treated vs control: 0.56\n",
      "cpit cohort: 0.858861\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.50\n",
      "treated_target_rpu: 83.97\n",
      "treated_target_nipu: -5.28\n",
      "nontreated_target_rpu: 68.95\n",
      "nontreated_target_nipu: 6.66\n",
      "treated_nontarget_rpu: 50.12\n",
      "treated_nontarget_nipu: -3.16\n",
      "nontreated_nontarget_rpu: 46.14\n",
      "nontreated_nontarget_nipu: 6.13\n",
      "--- with 49.993439181209816% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 0.7950834420651209\n",
      "--> in non-targeted users: \n",
      "cpit = 2.332103861033027\n",
      "rpu_control: 57.54\n",
      "nipu_control: 6.40\n",
      "rpu_ft: 67.05\n",
      "nipu_ft: -4.22\n",
      "rpu_cohort: 65.05\n",
      "nipu_cohort: 0.42\n",
      "lift targeted cohort vs control: 0.13\n",
      "lift random vs control: 0.17\n",
      "cpit cohort vs control: 0.79\n",
      "lift targeted-treated vs control: 0.46\n",
      "cpit cohort: 0.794981\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.60\n",
      "treated_target_rpu: 79.46\n",
      "treated_target_nipu: -4.68\n",
      "nontreated_target_rpu: 65.83\n",
      "nontreated_target_nipu: 6.61\n",
      "treated_nontarget_rpu: 48.50\n",
      "treated_nontarget_nipu: -3.54\n",
      "nontreated_nontarget_rpu: 45.11\n",
      "nontreated_nontarget_nipu: 6.07\n",
      "--- with 59.99212701745178% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 0.828557136346703\n",
      "--> in non-targeted users: \n",
      "cpit = 2.8327431321788974\n",
      "rpu_control: 57.54\n",
      "nipu_control: 6.40\n",
      "rpu_ft: 67.05\n",
      "nipu_ft: -4.22\n",
      "rpu_cohort: 65.72\n",
      "nipu_cohort: -0.38\n",
      "lift targeted cohort vs control: 0.14\n",
      "lift random vs control: 0.17\n",
      "cpit cohort vs control: 0.83\n",
      "lift targeted-treated vs control: 0.38\n",
      "cpit cohort: 0.828901\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.70\n",
      "treated_target_rpu: 75.18\n",
      "treated_target_nipu: -5.98\n",
      "nontreated_target_rpu: 62.97\n",
      "nontreated_target_nipu: 6.54\n",
      "treated_nontarget_rpu: 48.21\n",
      "treated_nontarget_nipu: -0.14\n",
      "nontreated_nontarget_rpu: 44.85\n",
      "nontreated_nontarget_nipu: 6.05\n",
      "--- with 69.99081485369373% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.0264287541042\n",
      "--> in non-targeted users: \n",
      "cpit = 1.8439384503664975\n",
      "rpu_control: 57.54\n",
      "nipu_control: 6.40\n",
      "rpu_ft: 67.05\n",
      "nipu_ft: -4.22\n",
      "rpu_cohort: 66.08\n",
      "nipu_cohort: -2.37\n",
      "lift targeted cohort vs control: 0.15\n",
      "lift random vs control: 0.17\n",
      "cpit cohort vs control: 1.03\n",
      "lift targeted-treated vs control: 0.31\n",
      "cpit cohort: 1.027052\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.80\n",
      "treated_target_rpu: 71.99\n",
      "treated_target_nipu: -5.34\n",
      "nontreated_target_rpu: 60.97\n",
      "nontreated_target_nipu: 6.52\n",
      "treated_nontarget_rpu: 47.15\n",
      "treated_nontarget_nipu: 0.26\n",
      "nontreated_nontarget_rpu: 43.86\n",
      "nontreated_nontarget_nipu: 5.92\n",
      "--- with 79.9895026899357% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.0754340477310804\n",
      "--> in non-targeted users: \n",
      "cpit = 1.7222431791798414\n",
      "rpu_control: 57.54\n",
      "nipu_control: 6.40\n",
      "rpu_ft: 67.05\n",
      "nipu_ft: -4.22\n",
      "rpu_cohort: 66.36\n",
      "nipu_cohort: -3.08\n",
      "lift targeted cohort vs control: 0.15\n",
      "lift random vs control: 0.17\n",
      "cpit cohort vs control: 1.07\n",
      "lift targeted-treated vs control: 0.25\n",
      "cpit cohort: 1.074798\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.90\n",
      "treated_target_rpu: 69.32\n",
      "treated_target_nipu: -4.77\n",
      "nontreated_target_rpu: 59.13\n",
      "nontreated_target_nipu: 6.42\n",
      "treated_nontarget_rpu: 46.67\n",
      "treated_nontarget_nipu: 0.72\n",
      "nontreated_nontarget_rpu: 43.27\n",
      "nontreated_nontarget_nipu: 6.14\n",
      "--- with 89.98819052617768% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.0989991904059149\n",
      "--> in non-targeted users: \n",
      "cpit = 1.5939108568342943\n",
      "rpu_control: 57.54\n",
      "nipu_control: 6.40\n",
      "rpu_ft: 67.05\n",
      "nipu_ft: -4.22\n",
      "rpu_cohort: 66.71\n",
      "nipu_cohort: -3.68\n",
      "lift targeted cohort vs control: 0.16\n",
      "lift random vs control: 0.17\n",
      "cpit cohort vs control: 1.10\n",
      "lift targeted-treated vs control: 0.20\n",
      "cpit cohort: 1.098969\n",
      "rpu_cohort\n",
      "66.70949958671879\n",
      "treated_target_rpu\n",
      "67.05182163537394\n",
      "---------------------------->>>>>>\n",
      "perc - target: 1.00\n",
      "treated_target_rpu: 67.05\n",
      "treated_target_nipu: -4.22\n",
      "nontreated_target_rpu: 57.53\n",
      "nontreated_target_nipu: 6.39\n",
      "treated_nontarget_rpu: nan\n",
      "treated_nontarget_nipu: nan\n",
      "nontreated_nontarget_rpu: 109.55\n",
      "nontreated_nontarget_nipu: 15.86\n",
      "--- with 99.98687836241963% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.1154236066428616\n",
      "--> in non-targeted users: \n",
      "cpit = nan\n",
      "rpu_control: 57.54\n",
      "nipu_control: 6.40\n",
      "rpu_ft: 67.05\n",
      "nipu_ft: -4.22\n",
      "rpu_cohort: 67.05\n",
      "nipu_cohort: -4.22\n",
      "lift targeted cohort vs control: 0.17\n",
      "lift random vs control: 0.17\n",
      "cpit cohort vs control: 1.12\n",
      "lift targeted-treated vs control: 0.17\n",
      "cpit cohort: 1.116560\n",
      "rpu_control: 57.541300766652434\n",
      "nipu_control: 6.395390112802487\n",
      "rpu_ft: 67.05182163537381\n",
      "nipu_ft: -4.223677512349505\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.10\n",
      "treated_target_rpu: 51.76\n",
      "treated_target_nipu: -3.65\n",
      "nontreated_target_rpu: 32.44\n",
      "nontreated_target_nipu: -1.85\n",
      "treated_nontarget_rpu: 68.88\n",
      "treated_nontarget_nipu: -4.29\n",
      "nontreated_nontarget_rpu: 60.28\n",
      "nontreated_nontarget_nipu: 7.30\n",
      "--- with 9.998687836241963% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 0.0931278568502543\n",
      "--> in non-targeted users: \n",
      "cpit = 1.348289921397962\n",
      "rpu_control: 57.54\n",
      "nipu_control: 6.40\n",
      "rpu_ft: 67.05\n",
      "nipu_ft: -4.22\n",
      "rpu_cohort: 59.43\n",
      "nipu_cohort: 6.20\n",
      "lift targeted cohort vs control: 0.03\n",
      "lift random vs control: 0.17\n",
      "cpit cohort vs control: 0.10\n",
      "lift targeted-treated vs control: -0.10\n",
      "cpit cohort: 0.102335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------->>>>>>\n",
      "perc - target: 0.20\n",
      "treated_target_rpu: 54.17\n",
      "treated_target_nipu: -3.56\n",
      "nontreated_target_rpu: 37.92\n",
      "nontreated_target_nipu: 1.16\n",
      "treated_nontarget_rpu: 70.31\n",
      "treated_nontarget_nipu: -4.39\n",
      "nontreated_nontarget_rpu: 62.43\n",
      "nontreated_nontarget_nipu: 7.70\n",
      "--- with 19.997375672483926% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 0.2902529519206703\n",
      "--> in non-targeted users: \n",
      "cpit = 1.5342994533638987\n",
      "rpu_control: 57.54\n",
      "nipu_control: 6.40\n",
      "rpu_ft: 67.05\n",
      "nipu_ft: -4.22\n",
      "rpu_cohort: 60.78\n",
      "nipu_cohort: 5.45\n",
      "lift targeted cohort vs control: 0.06\n",
      "lift random vs control: 0.17\n",
      "cpit cohort vs control: 0.29\n",
      "lift targeted-treated vs control: -0.06\n",
      "cpit cohort: 0.292169\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.30\n",
      "treated_target_rpu: 54.06\n",
      "treated_target_nipu: -3.12\n",
      "nontreated_target_rpu: 40.59\n",
      "nontreated_target_nipu: 2.40\n",
      "treated_nontarget_rpu: 72.82\n",
      "treated_nontarget_nipu: -4.71\n",
      "nontreated_nontarget_rpu: 64.75\n",
      "nontreated_nontarget_nipu: 8.09\n",
      "--- with 29.99606350872589% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 0.4097182196944632\n",
      "--> in non-targeted users: \n",
      "cpit = 1.5868355260902904\n",
      "rpu_control: 57.54\n",
      "nipu_control: 6.40\n",
      "rpu_ft: 67.05\n",
      "nipu_ft: -4.22\n",
      "rpu_cohort: 61.54\n",
      "nipu_cohort: 4.73\n",
      "lift targeted cohort vs control: 0.07\n",
      "lift random vs control: 0.17\n",
      "cpit cohort vs control: 0.42\n",
      "lift targeted-treated vs control: -0.06\n",
      "cpit cohort: 0.416121\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.40\n",
      "treated_target_rpu: 56.27\n",
      "treated_target_nipu: -4.38\n",
      "nontreated_target_rpu: 43.41\n",
      "nontreated_target_nipu: 3.26\n",
      "treated_nontarget_rpu: 74.45\n",
      "treated_nontarget_nipu: -4.11\n",
      "nontreated_nontarget_rpu: 66.90\n",
      "nontreated_nontarget_nipu: 8.47\n",
      "--- with 39.99475134496785% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 0.5946295140168835\n",
      "--> in non-targeted users: \n",
      "cpit = 1.6665689637027365\n",
      "rpu_control: 57.54\n",
      "nipu_control: 6.40\n",
      "rpu_ft: 67.05\n",
      "nipu_ft: -4.22\n",
      "rpu_cohort: 62.65\n",
      "nipu_cohort: 3.33\n",
      "lift targeted cohort vs control: 0.09\n",
      "lift random vs control: 0.17\n",
      "cpit cohort vs control: 0.60\n",
      "lift targeted-treated vs control: -0.02\n",
      "cpit cohort: 0.600445\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.50\n",
      "treated_target_rpu: 57.14\n",
      "treated_target_nipu: -4.00\n",
      "nontreated_target_rpu: 44.84\n",
      "nontreated_target_nipu: 3.84\n",
      "treated_nontarget_rpu: 77.15\n",
      "treated_nontarget_nipu: -4.45\n",
      "nontreated_nontarget_rpu: 70.18\n",
      "nontreated_nontarget_nipu: 8.94\n",
      "--- with 49.993439181209816% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 0.6371856979410353\n",
      "--> in non-targeted users: \n",
      "cpit = 1.9235939332605114\n",
      "rpu_control: 57.54\n",
      "nipu_control: 6.40\n",
      "rpu_ft: 67.05\n",
      "nipu_ft: -4.22\n",
      "rpu_cohort: 63.66\n",
      "nipu_cohort: 2.47\n",
      "lift targeted cohort vs control: 0.11\n",
      "lift random vs control: 0.17\n",
      "cpit cohort vs control: 0.64\n",
      "lift targeted-treated vs control: -0.01\n",
      "cpit cohort: 0.640758\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.60\n",
      "treated_target_rpu: 59.24\n",
      "treated_target_nipu: -3.55\n",
      "nontreated_target_rpu: 47.41\n",
      "nontreated_target_nipu: 4.34\n",
      "treated_nontarget_rpu: 78.83\n",
      "treated_nontarget_nipu: -5.23\n",
      "nontreated_nontarget_rpu: 72.71\n",
      "nontreated_nontarget_nipu: 9.47\n",
      "--- with 59.99212701745178% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 0.6675675559062741\n",
      "--> in non-targeted users: \n",
      "cpit = 2.4012761589056586\n",
      "rpu_control: 57.54\n",
      "nipu_control: 6.40\n",
      "rpu_ft: 67.05\n",
      "nipu_ft: -4.22\n",
      "rpu_cohort: 64.63\n",
      "nipu_cohort: 1.66\n",
      "lift targeted cohort vs control: 0.12\n",
      "lift random vs control: 0.17\n",
      "cpit cohort vs control: 0.67\n",
      "lift targeted-treated vs control: 0.03\n",
      "cpit cohort: 0.668484\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.70\n",
      "treated_target_rpu: 61.04\n",
      "treated_target_nipu: -3.50\n",
      "nontreated_target_rpu: 49.63\n",
      "nontreated_target_nipu: 4.85\n",
      "treated_nontarget_rpu: 81.07\n",
      "treated_nontarget_nipu: -5.92\n",
      "nontreated_nontarget_rpu: 75.99\n",
      "nontreated_nontarget_nipu: 10.00\n",
      "--- with 69.99081485369373% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 0.731767529961341\n",
      "--> in non-targeted users: \n",
      "cpit = 3.132019951266928\n",
      "rpu_control: 57.54\n",
      "nipu_control: 6.40\n",
      "rpu_ft: 67.05\n",
      "nipu_ft: -4.22\n",
      "rpu_cohort: 65.53\n",
      "nipu_cohort: 0.55\n",
      "lift targeted cohort vs control: 0.14\n",
      "lift random vs control: 0.17\n",
      "cpit cohort vs control: 0.73\n",
      "lift targeted-treated vs control: 0.06\n",
      "cpit cohort: 0.731732\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.80\n",
      "treated_target_rpu: 61.77\n",
      "treated_target_nipu: -4.94\n",
      "nontreated_target_rpu: 52.03\n",
      "nontreated_target_nipu: 5.32\n",
      "treated_nontarget_rpu: 87.71\n",
      "treated_nontarget_nipu: -1.42\n",
      "nontreated_nontarget_rpu: 79.69\n",
      "nontreated_nontarget_nipu: 10.71\n",
      "--- with 79.9895026899357% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.0524517113202347\n",
      "--> in non-targeted users: \n",
      "cpit = 1.513568419843739\n",
      "rpu_control: 57.54\n",
      "nipu_control: 6.40\n",
      "rpu_ft: 67.05\n",
      "nipu_ft: -4.22\n",
      "rpu_cohort: 65.36\n",
      "nipu_cohort: -1.81\n",
      "lift targeted cohort vs control: 0.14\n",
      "lift random vs control: 0.17\n",
      "cpit cohort vs control: 1.05\n",
      "lift targeted-treated vs control: 0.07\n",
      "cpit cohort: 1.049161\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.90\n",
      "treated_target_rpu: 63.56\n",
      "treated_target_nipu: -4.61\n",
      "nontreated_target_rpu: 54.10\n",
      "nontreated_target_nipu: 5.79\n",
      "treated_nontarget_rpu: 97.98\n",
      "treated_nontarget_nipu: -0.78\n",
      "nontreated_nontarget_rpu: 88.57\n",
      "nontreated_nontarget_nipu: 11.88\n",
      "--- with 89.98819052617768% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.0989806210744832\n",
      "--> in non-targeted users: \n",
      "cpit = 1.345169829976249\n",
      "rpu_control: 57.54\n",
      "nipu_control: 6.40\n",
      "rpu_ft: 67.05\n",
      "nipu_ft: -4.22\n",
      "rpu_cohort: 66.07\n",
      "nipu_cohort: -2.96\n",
      "lift targeted cohort vs control: 0.15\n",
      "lift random vs control: 0.17\n",
      "cpit cohort vs control: 1.10\n",
      "lift targeted-treated vs control: 0.10\n",
      "cpit cohort: 1.097545\n",
      "rpu_cohort\n",
      "66.06625023086869\n",
      "treated_target_rpu\n",
      "67.05862887332135\n",
      "---------------------------->>>>>>\n",
      "perc - target: 1.00\n",
      "treated_target_rpu: 67.06\n",
      "treated_target_nipu: -4.22\n",
      "nontreated_target_rpu: 57.53\n",
      "nontreated_target_nipu: 6.39\n",
      "treated_nontarget_rpu: 10.79\n",
      "treated_nontarget_nipu: -0.72\n",
      "nontreated_nontarget_rpu: 108.08\n",
      "nontreated_nontarget_nipu: 13.83\n",
      "--- with 99.98687836241963% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.1149113795046284\n",
      "--> in non-targeted users: \n",
      "cpit = -0.1495355731318738\n",
      "rpu_control: 57.54\n",
      "nipu_control: 6.40\n",
      "rpu_ft: 67.05\n",
      "nipu_ft: -4.22\n",
      "rpu_cohort: 67.06\n",
      "nipu_cohort: -4.22\n",
      "lift targeted cohort vs control: 0.17\n",
      "lift random vs control: 0.17\n",
      "cpit cohort vs control: 1.12\n",
      "lift targeted-treated vs control: 0.17\n",
      "cpit cohort: 1.115806\n",
      "rpu_control: 57.541300766652434\n",
      "nipu_control: 6.395390112802487\n",
      "rpu_ft: 67.05182163537381\n",
      "nipu_ft: -4.223677512349505\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.10\n",
      "treated_target_rpu: 65.28\n",
      "treated_target_nipu: -4.68\n",
      "nontreated_target_rpu: 43.53\n",
      "nontreated_target_nipu: -1.20\n",
      "treated_nontarget_rpu: 67.25\n",
      "treated_nontarget_nipu: -4.17\n",
      "nontreated_nontarget_rpu: 59.09\n",
      "nontreated_nontarget_nipu: 7.23\n",
      "--- with 9.998687836241963% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 0.16022514227199913\n",
      "--> in non-targeted users: \n",
      "cpit = 1.3966521133252334\n",
      "rpu_control: 57.54\n",
      "nipu_control: 6.40\n",
      "rpu_ft: 67.05\n",
      "nipu_ft: -4.22\n",
      "rpu_cohort: 59.71\n",
      "nipu_cohort: 6.04\n",
      "lift targeted cohort vs control: 0.04\n",
      "lift random vs control: 0.17\n",
      "cpit cohort vs control: 0.16\n",
      "lift targeted-treated vs control: 0.13\n",
      "cpit cohort: 0.162987\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.20\n",
      "treated_target_rpu: 63.71\n",
      "treated_target_nipu: -4.23\n",
      "nontreated_target_rpu: 45.41\n",
      "nontreated_target_nipu: 1.69\n",
      "treated_nontarget_rpu: 67.92\n",
      "treated_nontarget_nipu: -4.22\n",
      "nontreated_nontarget_rpu: 60.55\n",
      "nontreated_nontarget_nipu: 7.56\n",
      "--- with 19.997375672483926% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 0.32381135408211786\n",
      "--> in non-targeted users: \n",
      "cpit = 1.5993172318016002\n",
      "rpu_control: 57.54\n",
      "nipu_control: 6.40\n",
      "rpu_ft: 67.05\n",
      "nipu_ft: -4.22\n",
      "rpu_cohort: 61.18\n",
      "nipu_cohort: 5.20\n",
      "lift targeted cohort vs control: 0.06\n",
      "lift random vs control: 0.17\n",
      "cpit cohort vs control: 0.33\n",
      "lift targeted-treated vs control: 0.11\n",
      "cpit cohort: 0.327447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------->>>>>>\n",
      "perc - target: 0.30\n",
      "treated_target_rpu: 62.50\n",
      "treated_target_nipu: -3.95\n",
      "nontreated_target_rpu: 46.50\n",
      "nontreated_target_nipu: 2.82\n",
      "treated_nontarget_rpu: 69.08\n",
      "treated_nontarget_nipu: -4.35\n",
      "nontreated_nontarget_rpu: 62.23\n",
      "nontreated_nontarget_nipu: 7.92\n",
      "--- with 29.99606350872589% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 0.42280926685353565\n",
      "--> in non-targeted users: \n",
      "cpit = 1.7894274944395252\n",
      "rpu_control: 57.54\n",
      "nipu_control: 6.40\n",
      "rpu_ft: 67.05\n",
      "nipu_ft: -4.22\n",
      "rpu_cohort: 62.31\n",
      "nipu_cohort: 4.36\n",
      "lift targeted cohort vs control: 0.08\n",
      "lift random vs control: 0.17\n",
      "cpit cohort vs control: 0.43\n",
      "lift targeted-treated vs control: 0.09\n",
      "cpit cohort: 0.427448\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.40\n",
      "treated_target_rpu: 62.53\n",
      "treated_target_nipu: -3.51\n",
      "nontreated_target_rpu: 48.08\n",
      "nontreated_target_nipu: 3.63\n",
      "treated_nontarget_rpu: 70.17\n",
      "treated_nontarget_nipu: -4.71\n",
      "nontreated_nontarget_rpu: 63.80\n",
      "nontreated_nontarget_nipu: 8.23\n",
      "--- with 39.99475134496785% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 0.49447839506207536\n",
      "--> in non-targeted users: \n",
      "cpit = 2.0321061992448373\n",
      "rpu_control: 57.54\n",
      "nipu_control: 6.40\n",
      "rpu_ft: 67.05\n",
      "nipu_ft: -4.22\n",
      "rpu_cohort: 63.29\n",
      "nipu_cohort: 3.53\n",
      "lift targeted cohort vs control: 0.10\n",
      "lift random vs control: 0.17\n",
      "cpit cohort vs control: 0.50\n",
      "lift targeted-treated vs control: 0.09\n",
      "cpit cohort: 0.498213\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.50\n",
      "treated_target_rpu: 61.94\n",
      "treated_target_nipu: -4.30\n",
      "nontreated_target_rpu: 48.78\n",
      "nontreated_target_nipu: 4.10\n",
      "treated_nontarget_rpu: 72.20\n",
      "treated_nontarget_nipu: -4.14\n",
      "nontreated_nontarget_rpu: 66.29\n",
      "nontreated_nontarget_nipu: 8.69\n",
      "--- with 49.993439181209816% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 0.6385623180499398\n",
      "--> in non-targeted users: \n",
      "cpit = 2.170478489932322\n",
      "rpu_control: 57.54\n",
      "nipu_control: 6.40\n",
      "rpu_ft: 67.05\n",
      "nipu_ft: -4.22\n",
      "rpu_cohort: 64.11\n",
      "nipu_cohort: 2.19\n",
      "lift targeted cohort vs control: 0.11\n",
      "lift random vs control: 0.17\n",
      "cpit cohort vs control: 0.64\n",
      "lift targeted-treated vs control: 0.08\n",
      "cpit cohort: 0.639493\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.60\n",
      "treated_target_rpu: 62.49\n",
      "treated_target_nipu: -4.05\n",
      "nontreated_target_rpu: 50.74\n",
      "nontreated_target_nipu: 4.66\n",
      "treated_nontarget_rpu: 73.85\n",
      "treated_nontarget_nipu: -4.49\n",
      "nontreated_nontarget_rpu: 67.75\n",
      "nontreated_nontarget_nipu: 9.00\n",
      "--- with 59.99212701745178% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 0.741170412941532\n",
      "--> in non-targeted users: \n",
      "cpit = 2.2106241507403808\n",
      "rpu_control: 57.54\n",
      "nipu_control: 6.40\n",
      "rpu_ft: 67.05\n",
      "nipu_ft: -4.22\n",
      "rpu_cohort: 64.59\n",
      "nipu_cohort: 1.17\n",
      "lift targeted cohort vs control: 0.12\n",
      "lift random vs control: 0.17\n",
      "cpit cohort vs control: 0.74\n",
      "lift targeted-treated vs control: 0.09\n",
      "cpit cohort: 0.740404\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.70\n",
      "treated_target_rpu: 63.49\n",
      "treated_target_nipu: -5.67\n",
      "nontreated_target_rpu: 52.13\n",
      "nontreated_target_nipu: 5.07\n",
      "treated_nontarget_rpu: 75.37\n",
      "treated_nontarget_nipu: -0.84\n",
      "nontreated_nontarget_rpu: 70.16\n",
      "nontreated_nontarget_nipu: 9.48\n",
      "--- with 69.99081485369373% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 0.9464861965812866\n",
      "--> in non-targeted users: \n",
      "cpit = 1.9773816995155489\n",
      "rpu_control: 57.54\n",
      "nipu_control: 6.40\n",
      "rpu_ft: 67.05\n",
      "nipu_ft: -4.22\n",
      "rpu_cohort: 65.49\n",
      "nipu_cohort: -1.13\n",
      "lift targeted cohort vs control: 0.14\n",
      "lift random vs control: 0.17\n",
      "cpit cohort vs control: 0.95\n",
      "lift targeted-treated vs control: 0.10\n",
      "cpit cohort: 0.946599\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.80\n",
      "treated_target_rpu: 64.01\n",
      "treated_target_nipu: -5.20\n",
      "nontreated_target_rpu: 53.53\n",
      "nontreated_target_nipu: 5.51\n",
      "treated_nontarget_rpu: 79.08\n",
      "treated_nontarget_nipu: -0.35\n",
      "nontreated_nontarget_rpu: 73.60\n",
      "nontreated_nontarget_nipu: 9.95\n",
      "--- with 79.9895026899357% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.0222883433528491\n",
      "--> in non-targeted users: \n",
      "cpit = 1.8795274297985027\n",
      "rpu_control: 57.54\n",
      "nipu_control: 6.40\n",
      "rpu_ft: 67.05\n",
      "nipu_ft: -4.22\n",
      "rpu_cohort: 65.93\n",
      "nipu_cohort: -2.17\n",
      "lift targeted cohort vs control: 0.15\n",
      "lift random vs control: 0.17\n",
      "cpit cohort vs control: 1.02\n",
      "lift targeted-treated vs control: 0.11\n",
      "cpit cohort: 1.021182\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.90\n",
      "treated_target_rpu: 64.86\n",
      "treated_target_nipu: -4.79\n",
      "nontreated_target_rpu: 55.22\n",
      "nontreated_target_nipu: 5.92\n",
      "treated_nontarget_rpu: 86.17\n",
      "treated_nontarget_nipu: 0.75\n",
      "nontreated_nontarget_rpu: 78.51\n",
      "nontreated_nontarget_nipu: 10.66\n",
      "--- with 89.98819052617768% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.112626041761766\n",
      "--> in non-targeted users: \n",
      "cpit = 1.2945083514759725\n",
      "rpu_control: 57.54\n",
      "nipu_control: 6.40\n",
      "rpu_ft: 67.05\n",
      "nipu_ft: -4.22\n",
      "rpu_cohort: 66.22\n",
      "nipu_cohort: -3.25\n",
      "lift targeted cohort vs control: 0.15\n",
      "lift random vs control: 0.17\n",
      "cpit cohort vs control: 1.11\n",
      "lift targeted-treated vs control: 0.13\n",
      "cpit cohort: 1.110420\n",
      "rpu_cohort\n",
      "66.22471195474496\n",
      "treated_target_rpu\n",
      "67.05182163537394\n",
      "---------------------------->>>>>>\n",
      "perc - target: 1.00\n",
      "treated_target_rpu: 67.05\n",
      "treated_target_nipu: -4.22\n",
      "nontreated_target_rpu: 57.52\n",
      "nontreated_target_nipu: 6.39\n",
      "treated_nontarget_rpu: nan\n",
      "treated_nontarget_nipu: nan\n",
      "nontreated_nontarget_rpu: 191.17\n",
      "nontreated_nontarget_nipu: 36.48\n",
      "--- with 99.98687836241963% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.1135468691260453\n",
      "--> in non-targeted users: \n",
      "cpit = nan\n",
      "rpu_control: 57.54\n",
      "nipu_control: 6.40\n",
      "rpu_ft: 67.05\n",
      "nipu_ft: -4.22\n",
      "rpu_cohort: 67.05\n",
      "nipu_cohort: -4.22\n",
      "lift targeted cohort vs control: 0.17\n",
      "lift random vs control: 0.17\n",
      "cpit cohort vs control: 1.12\n",
      "lift targeted-treated vs control: 0.17\n",
      "cpit cohort: 1.116560\n",
      "temp:\n",
      "2.531837396198079\n",
      "p_quantile:\n",
      "0.4\n",
      "AUCC results: \n",
      "random: [0.5]\n",
      "rlearner: [0.65153086]\n",
      "duality rlearner 1 with lambda = 0.1:[0.65172751]\n",
      "drm: [0.69074803]\n",
      "tqr: [0.6864024]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOydeXwURfbAv9WTaxJykIM7yCEQQIT9KQjigdcicq2rqIsuKCB4IIqgyOKJ14LggboqgigqioIKCAoqIopCAAUFQUAQwhFyEXInk+n6/dGdycyQSXqAIVd9P598MlNdXf36mHpdr169J6SUKBQKhaL+olW3AAqFQqGoXpQiUCgUinqOUgQKhUJRz1GKQKFQKOo5ShEoFApFPUcpAoVCoajnKEVQTQghHhdCvOdjWx8hxMEzLZN57JuFEKuq49iKk0MIcbEQ4o/qluNMIYT4QggxvLrl8BchhBRCnG2h3hn//dcbRSCEGCqE2CSEyBNCHDEfpouqW66ahpTyfSnl36tbDisIIdYIIUZVtxzVjZTyeyllh0C0Xd3XuKIXJillPynlO9UlU12kXigCIcT9wIvAM0BjoCXwP2Bwdcp1phFCBFW3DLURdd1OHnXtaglSyjr9B0QDecCQSur0AH4CsoEjwCtAiLmtFSCBILf6a4BR5uezge+A40AGsNCt3ktACpADbAYudtv2OPCeD3n6AAfdvjcDFgPpwD5gnBXZze0SuBvYDexzK7vDLMsGXgWEue1W4Aev/X3VtQEzzfPeB4z1vlZe55UIfGKeRybwilmuAQ8D+4E0YD4QbW4LA94z62cDGzGU+dOAEygy7+8rPo55EfCjuW8KcKv3PazkvF3XDXgNmOHV9hLgfov3aJP5HBwFnvchq4cMbnKcbX6+BvgdyAUOARN9PC9/AROBXzGey4VAmNv2B81n5TAwyv0YXseu8BpT9XO9yLxnOWb7duAd4Biwwzx+lc83cDVQAjjM42+t4Pd3K/ADMMNsfx/Qz63t1sBa85p9jfH8Vvq7M+VLM6/RP8zrvgvIAv7jVj8U4wXzsPn3IhDqtv0Bt+s8wutehpoyHzCfidcBu4/7Ocm837nAH8AVp72fPN0N1rQ/82EqxUfnZNY5D+gJBGF0/DuA+8xtrahcEXwATMHozMKAi9zq3QLEme1OAFIxf5BYVARmu5uBR4EQoA2wF+hblezmdgl8BcS6PWgS+ByIwRgdpQNXu/+wvPb3VfcOjI6pBdAQ44dWoSLAUBpbgReACPdrZf5I9pjn1gBDWbxrbhsDLAPCzTbOA6K874OP63iW+eP5FxBs3otuFe3r47xd1w24BKPzK1OCDYFCjE6sqnv0E/Bv83MDoKcPeT1kcJOjrPM4gtnpmsf/P+/nxfz+F5BsyhZrPhN3uP0eUoHO5jV9Dx+KwNc1purn2oHRgWrmtfsvxstSQ/NZ+RXrz/fjeP1OOFEROIDbzefjToyOV7hd+xlm2xdhKKfKfnelpizBZpvpwAIg0rxmhUBrs/5UYD3QCEjAeOF40u06HwXOwXjeF3jdyxeApeb9icR4xp+t4PffAeO5a+bWH7U97f3k6W6wpv0BNwOpfu5zH/Cp24WvTBHMB2YDLSy0ewzo6usB93ogyx6EC4ADXtsnA/Oqkt38LoHLvepIPBXWR8BD5udbObFD9FV3NTDGbduV3tfKbVsv80dV0bZvgLvcvnfA+HEHYSiJH4FzK9jPdR98XIvJ7teisn19nPflbt8FxtvbJeb324HVVu4RxhvpE0B8Fc+HhwxucpR1HgcwFGOUr+fF/P4XcIvb9+nA6+bntzA7HPP72fipCCw812u9trs6dvP7KCw+31hTBHvctoWb59ME48WlFAh32/6ed3te17EQsJnfI822LnCrsxn4h/n5T+Aat219gb/crvN/3ba1L7vO5rOUj1uHjvH72Od9P836aRi/reDK7sOp/NWHOYJMIL4yW6UQor0Q4nMhRKoQIgdjLiHeYvsPYtzYZCHEdiHECLd2JwohdgghjgshsjHMVFbbLeMsoJkQIrvsD/gPhnnEquwpFbSb6va5AONN1Re+6jbzarui45SRCOyXUpZWsK0ZhlmojP0YSqAx8C6wEvhQCHFYCDFdCBFcyXG8j/mnxboV4TofafwqP8QYXQAMBd43P1d6j4CRGB3BTiHERiHEgJOU5zoMM8V+IcR3QoheldQ9HfesQiw8195tVnbMqq6dFVznKqUsMD82MI+b5VZWkWzeZEopnebnQvP/UbfthXheS+/ntpnbthSvbWUkYCiszW7n/KVZ7oGUcg/Gy93jQJoQ4kMhRDPveqdKfVAEPwHFGENVX7wG7ATaSSmjMB5EYW7LN/+Hu9VvUvZBSpkqpbxdStkM423tf0KIs4UQF2MoiRuAhlLKGAx7rcA/UjDeFGLc/iKllNdYkN0lpp/HtMoRjKF+GYmV1E0BWvpQyIcxOoQyyt7kjkopHVLKJ6SUnYALgQHAMLNeVeeVArT1sS0fH/fUDe/2PwCuF0KchfEmu9jtOD7vkZRyt5TyXxgmhGnAIiFERFUyCSE8ZJJSbpRSDjbb+QxjdOYv/twz8LoGFp9r7+tW2TGrer5P5dk9AsQKIdzvc1Xn6w8VPbeH3Y6d6LWtjAwMhdLZ7ZyjpZQVvoxJKRdIKS8yjyUxnqHTSp1XBFLK4xg2v1eFEP8QQoQLIYKFEP2EENPNapEYtsM8IUQShp2xbP90jImaW4QQNvON39W5CCGGCCHKHvJjGDdKN9ssxTSHCCEeBaJO4hSSgVwhxCQhhN2U4RwhRPeqZD8DfATcK4RoLoSIwZjU8kUyxo/jv0KICCFEmBCit7ntA2C8EKK1EKIBxqhmoZSyVAhxmRCiixDChnGeDozrC8abWptKjvk+cKUQ4gYhRJAQIk4I0c3ctgX4p/k8nI3x1l4pUspfMH7Ec4CVUspst3PzeY+EELcIIRKklDrGpDVu5+DOVqCzEKKbECIM4y0Qs40Qc41HtJTSYV6Litqoio+A24QQHc0O8pEq6ntf45N5rj8CJgshGgohmmM4FZRR1fN9FGglhPC7r5JS7seYpH/cvH69gIH+tlMJHwAPCyEShBDxGP1MmavrR8CtQohO5nV+zE0uHXgTeEEI0QjA/A319T6AEKKDEOJyIUQoxqR9ISd33yulzisCACnlTOB+DM+UdIy3kLEYb1VgeFgMxZhYfBPDy8Kd2zE8ADIxJox+dNvWHdgghMjDmPy5V0q5F8Oc8SWGt8F+jJvo9zDcHKYOALpheESUdUTRFmUPJG8CqzAm/34BVmB0Ek7viuZ5DMSweR7A8M640dz8FoYJaC3GORYB95jbmmB4oeRgTHp+Z9YFw3vleiHEMSHErAqOeQDDlDIBw+NjC9DV3PwChkfKUQyPlve99/fBAgx77QKvc6vsHl0NbDefkZeAm6SUhXghpdyFMQH5NYa30g9eVf4N/GWaAO/AmP/yCynlF8As4FuMCfr15qZiH7t4X+OTea6nYtzvfRjntqjseBau3cfm/0whxM+WT7ScmzHs75nAUxi/D1/n6i9PYSiaX4HfgJ/NsrLr/CLGPNoe8787k8zy9eb9/BpjbsybUIzJ9gwME1gjjDmU00rZzLpCccoIIfphTEqeVWVlRY1ACNER2Ibh9ljR/E0gjnknhjK89Ewcz+vYC4GdUsrHqqxcj6gXIwJFYDCH8teYZpfmGMPfT6tbLkXlCCGuFUKECiEaYtiblwVSCQghmgohegshNCFEB4wR2hl5ToQQ3YUQbc1jX42xiPSzqvarbyhFoDgVBIZb5DEM09AODDupomYzBsMl8U8MM16g55VCgDcwzJerMRbi/S/AxyyjCYa7aR6GSexOc65H4YYyDSkUCkU9R40IFAqFop5T6wJCxcfHy1atWp3Uvvn5+UREVOS+XXdR51w/UOdcPziVc968eXOGlPKERWtQCxVBq1at2LRp00ntu2bNGvr06XN6BarhqHOuH6hzrh+cyjkLIfb72qZMQwqFQlHPUYpAoVAo6jm1zjSkUCgU9YVSRynvjvqEZh9kYXe0AkJYy5cUBv/FkZvjuGX2tQQFn3o3rkYECoVCUQPJTsvhqwZv0nZ+FKGOduiEARo6YYQ62tHm7Ui+avAm2Wk5p3wspQgUCoWihlHqKOWnxPcJL2ltKgCbVw0bOmGEl7Tmp8T3KXWc2sLwgCkCIcRbQog0IcQ2H9uFEGKWEGKPEOJXIcT/BUoWhUKhqE28O+oTIkpaIwmrtJ4kjIiS1rw3+tQidgRyRPA2RtRFX/QD2pl/ozHi6isUCkW9p9kHWehYy7+kE0yT9zNO6XgBUwRSyrUYoX99MRiYLw3WAzFCiKaBkkehUChqC8bEsLc5yBc2wh2tT+l41ek11BzPOOYHzbIj3hWFEKMxRg00btyYNWvWnNQB8/LyTnrf2oo65/qBOue6RohftXVCTula1Ar3USnlbIwE8Zx//vnyZFfWqZWI9QN1zvWD2nDOui6Zt6aAx6aVcui7BlCiQYhOiz55TJ1kY/ilEWhaeZbPj3/O4+kn0niJP/EnpbxGCZf0qcwSX9X+1cchPHN6tjDLFAqFotZTUKzTemAOo/qHceirSCi2gRRQbOPgqkhGXGOn9cAccoucPL38GI0uzWDjeR/y5tLlSIvzAwZOCoL3nZKs1TkiWAqMFUJ8iJEI/LiU8gSzkEKhUNQ2dF3S8Z+5HPimgaEAvJEaFMGBVZFENSml3/GNLGM1RVxBvl9KADQcpN4cf0ryBkwRCCE+APoA8UKIgxjZq4IBpJSvY+S3vQYjb2cBcFugZFEoFIozybw1BRxY7UMJuNG+dDcvHn+FhvSi0MPJ0glkIIhBEupzf0ER+SH7uGX27ackb8AUgZTyX1Vsl8DdgTq+QqFQVBePTy+FYuFze0OyeJLpXEI4mVxHkdu2HLGDgofD6Xv3taxv+T4RJa1NV1J3peJEw0F+yD56pdx8ymEm1MpihUKhOM0cXNPAMP94EYSDe3iZH7mfc7mETC5xbXOSw/rOKzk/ZTA3TR1Ow8ZRXJV3O3tvzaU4eDcaRYCORhFFwbvYNyKPfsV3EtMo6pTlrRVeQwqFQlGrKDlRCVzNF/yXlynhOlK51WNbMsGcPbeUh0Y861EeFBzErfOGwDzj+5o1a07JO8gXShEoFArFaSI1VTJ5VhHI8tAQHfmdmUyhDW05woMe9TMpZSrn8WtYFHKE1QVkpx9lGlIoFIoKkBI2bIAhQyAiAjTN+H/DDZCcbGwvq7d+veSKIcU0S5S8/awdEMSRwcuM5SsmEsVwjjDA1bYTJ3NpyU1czq8imsQ+edVzkiZqRKBQKBReOBwwbJjks6VQVAToxsRvQQF8vFiybDkM7A99+8K0V5zs3hIEpndPMCXcxf+YxFukMpLdXO/R9mYa8BydOYrdKAh18sSD1TcaAKUIFAqFwgMp4d/DJIs+kziLvI0mko56LjcUpNDz40xCPtaZhcZPxPERLTibtTwXPIlgx0Xs4nmkWxd7DMFMOrGOeMD0KAp10vLyPIZfeuoTvqeCUgQKhULhxoYNkkVLTlQCNnQms5MLySAE3eXMGYbOpaTTh0PEsJcsx6OU0MS1nxPJxyTyDq0oKutyhQ6hkpaX57Hjk0iPMBPVgZojUCgUCjemTCvFWeRdKpnMTnqTgd1NCZShAYIQjtPVQwn8xq88/H9r+fSyaIrCBAgJYU4S++by9opC9i+PJjy0+rvh6pdAoVAoTgNWJ3cr48gRWLPcdsIagI7kciEZhKFbkiWPPJ4Pep68p/JZu/4/HF2dgCy0IXWBLLRx4Itohl/W4GROMyAo05BCoaj1GJO7sHQpFBVJdPfJ3UU6Hy+TJF6Wy4fvavSKjUQIY7vTaSiPFStgxXJJ8JZkPmAG/VmBnUIKsfM5/UllLCEWlYCOzoHYA0xfN52kpKSAnfPpxJIiEEI0xIgU6qovpfw5UEIpFAqFVaQsVwIFBeCaiHVVMAK8payO5JIbMxnw2BH+sa8dq77UWLkSsrKMFb/vMIxBLMVOETaz04+ggOtZzA+MrDTmjzsaGucUnVNrlABYUARCiCeBW4E/gbLBlQQuD5xYCoVCYY3kZFi2rEwJVEKxDefqBJZ8k8ASD2UheYdhDGYpERRQQjTHaU+u259VJVCGXmRt9FBTsDIiuAFoK6UsCbQwCoVCURVSSnKTc+FxWLtxLc4CnUUuF85EdhLJCaMC186e5TGUMNC+nvOL7OyTD5FLe4ppfMoyavbaNf1qRRFsA2KAtADLolAoFJWiO3R2DttJxtIMZCHoUkdguHBeQjo9yeRH4nmWJJxevjANKaYDebQnh/aR2bR35pFQ4IRCOMywKo7spMw3qEo0iOsfd5JnWD1YUQTPAr8IIbYBxWWFUspBAZNKoVAEBCklybm5zEhJYUVmJoW6jl3T6B8Xx8TERLpHlk+kVje5uZLte5xs2e1kx586e/7UuezzvZyTdowwUwG4YwPs6PQmg8fYzhc0oT15tCOP9uSSgJtRI9f3cQUlNOBPItlFJLtowB84CeNXnkMvWw1cCVqYRuKExCrr1SSsKIJ3gGnAb2Bx2lyhUNQ4HLrOsJ07WZqRQZGuu37MBbrO4vR0VmRmMjA+nvlJSQRrgTFt6FKS6XCQ5nBwuKCEHX+V8sde2LcXDu8XpO8P4vjBIAoPhqJnB2N0UUY31ZEcxnKsShfOMHQuJpOLyaxSHi1Yp4FjBw3MTj+SXYSzHw2nRz0JxPMjGfRGJ6zixjBMQvGD4onsHlnlsWsSVhRBgZRyVsAlUSgUAUPXJf0/2s83bySg/9TBlUSdnplwYwp6Ui75us6SjAyG7dzJgo4dLY8MinWd9JISjjocpJWUcNT8fLS4hANpTlL+EqTut5F1wEbewRA4YofUMEiNccXwscIQUiy7cFZEIRr7sKPHptAmdjU9/1pFjONPNAttCiCJZ9nJZDK4EAeh2NxMT06c6Dad5oObkzQ/qcaMqqxiRRF8L4R4FiPHsLtpSLmPKhS1AIcD+g8t5avPWxpZs8oWSxXbYG08bIiDCzNg8k4Kg3SWZWSwJjubxNBQ0hwOo2MvKXF9dv0vKSE1z8nxg0FwJMzo4I+EGX+HI43OvuAUlioF6YgmRYQ2L6FFfCEXf5GOzQ89oAOf0px9hNKcTVzFB9zG59iziiDLf3E0nLTnKXaQxK/cQE96EkooxRSz0baRq+ZcRadbO/nfcA3Ayl36m/m/p1uZch9VKGoBZT72qz+3wQkB1HD52LMuHp5Ngod3kK/rXL51q7FdBzJDzc69rLOPKn+rz/DPrdKbsHgHMYmlNGrppEVrSZs2kqQ2Gue2s9Gu2EHximNkLsskZ0VOufO6RQSSC3mUZ1lGA/IrrvS3v0GvXsh58xCFhVW2WQxMYycbmeoqs9vtDB48mEeGP+KfgDWIKhWBlPKyMyGIQqE4/ZT52J8YRdOLYht8nwAvO8ApjE6+rLN3nPx8QViETpOzdM5qLTm7taBzO432bTVat4ZWrSA8PBgIBkA6Jcd/Ok7m0nQy7s9g566qO+bKsFHEv/jwhPJtrVvz+4ABDLn7bkSHDvzy88+kLljAJYWFRFTSXj6wBNhoftc0jbCwMAYNGsT8+fNrnTnIHSsLyh6tqFxKObWicoVCYREpjZ56xgwjxkFhIdjt0L8/TJwI3bvDKXYuM2ZICgrBktujQ4NPW/jVvs0madkSWrcWtGkDrVvj8T8+XkMI34rEme8k66ssMpdkkPnZURzZPipqENQwiNKsUosjAydx/OT6trPxWXzU91KWXHEF7c8/n/lJSRSXlPDklClMmzYN4XTyDjAIsOOZJl5qGnpICL8kJHBXZiZaURF2u53+/fszceJEunfvbkWgGo0V05D7mCoMGADsCIw4CkU9wTM4Duim8bugABYvNhTDwIEwfz4EB/vVtJSSTbm5vH/0KIuWtQH91JKexMeXd+zunXyrVpKGqbkceTGFzBWZ6N/qaHaNuP5xJE5MJDK+YlfU4tRiMpdlkrk0k2NfH/O5ClejkFg2EReyibhrYimaOJMtfbeh51c9UaBRQnij73juqptZ0KcPu9u1o398PK8nJtI9Kop169YxcuRI/vjjD9c+I0NDeeP227klNRW++MKlmEX//tgmTuSi7t3xpadqO1ZMQzPdvwshZgArAyaRQlHXOTE4jie6Dvn5FH/2GUv69eOmKVOw22xV+vrvKShgQVoa7x89yq4ye3fJ2f4Kh7jrTy7sEML/+rSkdWuIrMATsmxh17alGUZHbvbNeoFO+uJ0MldkEj8w3vCgCRIU/F5AxtIMMpZkkLvBtxN/CJnE8RPxrCOGn7FRAiXASjvBOSnENx1Gxp7G6JWEfNCCSom/vAGtvviWBzSNB9y25eXlMW7cOF555RWkWzjSiy++mDlz5tC+fXs/r1fd4GSm9MMB/8aPCoWiHIvBcUKLirhm3TrO37mTjR07Vujrn1ZSwsK0NF4DdiQnezawtzKLtw/CdOw3Hub5bt0410fSLCmla3WvXlDB27kOer5O+qfp5HbJRXfoFO8tPrGeSbjYT7z8nnh+JJKdiIpsP4WFiNXfkMQalwunTggeRhxR5sffzFBAXmshVq1axejRo9m/f7+rrEGDBkyfPp0xY8agBWjtRG3AyhzBb5Rb5WxAAqDmBxSKk2XmTMPsYIHw4mL+98ILzOvXz1UWomm8FBKCXdPYWVCADlxm/gFQomFbH4++NRopkyto1RcSLTGPv63Ko/uvv/qcn8j9y07GJ63QSyrvOGWxpPCPCs5Tk8S0LSCuSy7xO+di3/ENVl2CNJx05ClyG/Zil/1WCrLao5fgYZKK6u6pwbKyspgwYQJvv/22R3m/fv14/fXXadmypaVj12WsjAgGuH0uBY5KKUsDJI9CUfdZvrx8TqAKNCk5f/duzt+9O8BCmewGnq68SgqPonOWX83aKCCWZOJYR5y+geDducax/CUoCLFyJVGXXkre99/Tp0+fSqsvXryYu+++m6NHj7rK4uLiePHFF7n55ptrtafP6cTKHMF+r3wEjYUQakGZQnGyWBwN1ERKCSOD3nBCskbfCErozT/QcJy6ALoOl1e9hOnIkSOMHTuWTz75xKP8xhtvZNasWTRq1OjUZalDqHwECsWZJCsLbDYotT6odthszB4w4IRyTQiGRDdix89B/PabRLq5iEZEQO/ecHZb0CV88zX89ZdxWHcjjABsQdC6FVxxJdi8rD1SQn5WFFkHmpB1oAnHjyQgdf9s6ZJgtLtur3jj7Nl+XQvslQd9k1LyzjvvMH78eLKzy318mjZtymuvvcbgwYOtH6seofIRKBRnAqcT5s6F//zHr47PKQSLL7mEsffd57lBB7GqCY/PSyLNLUB8UBDcfz888gg0MFPi2oCrJGzcWPmShTIc2Q6OfXWMrC+zyPoyi5LDp/bT1yJs8OqrFW9MTzfcZS2YyqSmkdWrF3cMGcKKFSsoLCz08OdPSEhgzJgxfPXVVx77jRo1iueee46YmJhTOo+6jMpHoFAEmh9/hHvugZ/9t6YWhYTw/JAhnoW7G8BL7ZDboz1+lFdeCS+/DBVlSBQCevSAjz46cZvUJTmbcl0df876HLyCb3pgi7bhzHFam9+tKjb/hAmGZsr3EQLCjWIhuPb771nncKCbiqOgoIDFixezZMkSnE4nTme54G3atGH27NlcccUVFgSt36h8BApFoDhyBCZNgnff9Sxv2dL427y50vmCfOwsierLRtkdZB7kBcHc1rCsmUfUzhYtYOTI7Tz2WGfLC5FL0ks4tuoYmV9kcmzVMRzpvu33QTFBNPx7Q2KvjiW2byzFKcVsuWKLtYVdVcXm79HDWDi3ZEml16LYZmMp8H3xiW6ouq5TUlI+ahFCMH78eKZOnUpExEm40NZDApqPQAhxNfASxuh0jpTyv17bW5rtx5h1HpJSrvDnGApFjaOkBGbNgqlTIddt8VRYGDz0EDz4oGHDGTYMli1DFhYi3EwjTjSKCGMJgxie/jZMCIJWeXDYDjkhrnpBwZKJEwRTpsCmTemVKgG9VCd3Q/lbf+7mXN9v9AIiu0caHf/VsUR2j0QLKp8XCGkaQvzAeDKWZKAX+u4SLMXmF8JYPW1eCwoLPc1EmoYzJIQlDgc3OysZpriaE8yZM4cRI0ZUWVdRTsDyEQghbMCrwFXAQWCjEGKplPJ3t2oPAx9JKV8TQnQCVgCt/D2WQlFjWLkS7r0X3EIXAPDPfxrrB1q1Ki9bsACZvJH1Q2ZwbsoKwiikEDuf05+ZTGQTpuG+CNgZ7dFckwvz+HZuRIVmoDKKDxWTtdLo+I99dYzSbN9zE8GNgonta3T8Da9qSEhCiM+6QgiS5icZi8qWmcrAXR9oxkggflC8tdj8wcGwYIHPSYyHMzOZ/u23lt5ChRCsXLlSKQI/CWQ+gh7AHinlXgAhxIfAYMBdEUigbPVHNHDYotwKRc1i715jlnbJEs/yjh2N0cGVV564jxAk04Orsj7yFST5RBoW0/uxNFaPbU6IzbOD1Ut0jq87TtYXRuef/1slrdog+sJo11t/g24NEJp1n3otWKPjgo7kbswlZYYZa6hQr3RhV6VUMokxKyLCNSdQFbqus3z5cuvHVQAg3ONtVFhBiG8rKJZSykrdR4UQ1wNXSylHmd//DVwgpRzrVqcpsApoCEQAV0opN1fQ1mhgNEDjxo3P+/DDE0PLWiEvL48GZa4U9QR1zoFFKyqi5YIFtPzwQzRHuZ29NCKCv4YP59C11yKDfL9vPf54J9aujUdKKy6Zkm4Xp/PCVLd3qSNAMpT+VErQ1iBj9OCLBIzXs+7AeUAteSwuv/xyquqn3BFCsHr16gBKVH2cyrN92WWXbZZSnl/RtioVwcliURHcb8owUwjRC5gLnCOl9Kn+zz//fLlp06aTkmnNmjVVrkSsa6hzDhBSwqJFhtdLSorntttug2efhcaNq2wmIqLKkEMeNAx3sntxtmHr/yKLwkpi9osQQfTF0cT1iyP26ljCO4XXupW0ubm5xMbGUuqHy21ERAR5eXkBlKr6OJVnWwjhUxH4fFURQtwipXzP7KxPQOuXuyUAACAASURBVEr5fBXHPYSxGrmMFmaZOyOBq832fhJChAHxKFdVRU1m2zYYNw6+9Rosd+9u+G9ecIHlpgoLJZXnCpAkUkAPsuhBFl0LjvNbP99mkrA2YcT2M8w9MX1iCGpwCqkiq5kvvviCMWPG+KUENE2jf//+AZSqblLZU1Lmd1XJlH+lbATaCSFaYyiAm4ChXnUOAFcAbwshOmLkO0g/yeMpFIElOxsee8xYHOXuwZKQYIwAbrsN/IxgaQuVlBZ5KgI7pfwf2XQ3O/+mldh7NLtGzGUxZLXNosc9PQhvF+7X8WsimZmZjB8/nne93W4tEBYWxoQJEwIgVd3GpyKQUr5h/n/Ce5sQwrdLQfn+pUKIsRi5C2zAW1LK7UKIqcAmKeVSYALwphBiPMbE8a0yULYqheJk0XWYNw8mTzZWwpZhs8HYsfD443ASq1a/OXaM0gsc8F0cbSl0dfxdOE5QJau1wjuGu976oy+OxhZmY82aNbVeCUgp+fjjjxk7dizpbtc5Li6O9u3bs2XLFgorWWtgt9sZNGhQncgYdqaxEmtoDUYH/Zf5vTswB+ha1b7mmoAVXmWPun3+Hejtl8QKxenCSqrI5GSjs3ebl5JA7v/dQkrcnWS+WYo+a4tnZq7uFSeOcefo0QL+N3sbDxYLuqMRj+8wDvnY2ExDtobE8sBHsfQYHHa6rkCN4fDhw9x999189tlnHuVDhw7lxRdfJCYmhmHDhrFs2TIKCws9vIjqUu7g6sLqyuIvhRCzgOZAP+C2gEqlUASaqlJFLl9uTPbu2+exm57Ymp0t/0fGL+HoRSWVZubSgsvNRFKX5G7OdU3yZm/I4Z5KPCJ304BkYkkmlu1EEWLXGDwYLqhj6/mllLz11ltMmDCB48ePu8qbN2/Oa6+9xsCBA11lCxYsYOPGjcyYMYMVK1ZQUFBAeHh4ncodXF1YCUO9UghxB/AVkAH8TUqZGnDJFIpAYSVVZEGBpxIIDUU+8CA7/7iejOXZlWbmyliSwc5hO2n7QltX8LZjq47hyCh3L/WeSThOEJuIZSOxbKQhWWYqRk0zFiQPGmQswK1LL7t79+5l9OjRfPPNNx7lY8aMYdq0aURHey6iE0LQo0cPPjLXGtRHj7hAYcU09AhGBNJLgHOBNUKICVJKtWpDUTuxmCrSxaWXwltvkZseT8YLWypWAm7ohTppH6WR9qFv5zddwM6WNjbub8EGYvmDKMbcKYjKgOIVoFUSHbS243Q6efnll5kyZQoFbvegbdu2zJkzR3Xu1YAV01Ac0ENKWQj8JIT4EmOOQCkCRe3Ej1SRCGGYiNq0IeWh7ZXG1vGggmrBjYNZ312y/G+lbO5go2BCD0rNN/8+fQzPU5v1fC+1kt9//52RI0eyfv16V5mmadx///088cQThIfX7gnv2ooV09B9Xt/3Y8QPUihqJ36kikRKoz6QuTzTz7CLEH1JeRiHGVHpTE05ABLEE0nIo4YSiI01ApTWZSVQUlLCtGnTeOqppzwihXbp0oW5c+cq+341Y8U0lABMAjph+PkDUFWICYWixuJvqsjCQhyZjipNQicg4G/f/Q2AdceP89QvB4zyL5ogv0twVZszxwglXVfZuHEjI0eO5LfffnOVBQcH8/DDD/PQQw8RElKlN7oiwFgxDb0PLAT6A3cAw1GLvhS1Gbvd0vxAKRFkcBFp4kqONfnR78No4caUcE5pKbfs2GEMJg7Y0V5u5xpYjBkD117rd9O1goKCAh5//HFmzpzp4e55wQUXMHfuXDp37lyN0incsTRHIKWcK4S4V0r5HfCdEGJjoAVTKAKClNCmjREmogJKCSOTC0njMrLogSTEzNbl5zpHt8xcY3fv5q+iInAIbE93xllk2ICSkuD5qgK11FK+++47Ro0axZ49e1xldrudp59+mnHjxmGry3awWoiV9fBlPm9HhBD9hRB/A2IDKJNCERhKSmDkyBOUgJMQ0rmY7TzKj3zKDh4hk4sMJeBG+DnhiBBr/ptlmbkWpqXx7tGjRuHc1jh3GZEjQ0Lggw+gts2NSinZsGEDQ4YMISIiAk3TiIiI4IYbbiA5OZnjx49z55130qdPHw8lcPnll7Nt2zbGjx+vlEANxMqI4CkhRDRGOIiXMfIHjA+oVAqFRaSU5CZ7xsQnBLYP2u65yjc7G667DszwxDpBHBPdSZN9yKA3TipOadigYTqNHrqARjc2IrRlKDuG7rCcmetYl2Du2PyrUbi5ISxs6aozbRp063b6rsOZwOFwMGzYMJYuXUpRUdEJeYOXLl2KpmkeYSCio6OZOXMmI0aMUCt+azBWvIY+Nz8eBy4LrDgKhXV0h25kyVqagV7kliWrGM9Vvk+Eof1jAPqOP8jmPNK4jIyQKyktCa2w3Qj2khD8A43+Hkz4p68YGbRMrGbmavdOB67a/ivZpaWQHYztvx1d+eCvvtoIXlqbkFK6lEBBBfMruq5T7JVPePDgwfzvf/+jWbNmZ0pMxUlixWuoNXAPRgpJV32VvF5RnUgpy5VAZat8P03j10W/Yi/tSwZP46Chsd0rtI9dHKKRXE0j+09EDOzicxWXr8xchGnsviSIV//h4NcOaQT9lI5DSmNq4bkOODMMM1OjRvD2234HKa12kpOTWbZsWYVKoCKefvppJk+erEYBtQQrpqHPMBLGLMNvL2qFIjDkJucab+VVrfIthmzOJZtzT9gWelYojW5sRKMbG9Hgb5cixM2Wji2EIKpHFJ0/6oxD1xm2cydLMzIo0ktcPxBHWRDdJc3gx3jXvvPmWcpXU+OYOXNmpZE/3dE0ja1btyolUIuwogiKTiZ5vUIRSFJmplhf5etGSNMQEm5IoNFNjYi6IOqUOisppUsJFFS0QG1fBLzW1vV13DjJNdfUzs5x+fLlKm9wHcaKInhJCPEYRm5hf5LXKxQBw99VvsIGXb/pRvRF0Qjb6emMk3NzWeZLCRRr8GRHKDE8ZLSz87h+io7ha1H7sDoaONn6iurFiiLoAvwbuJzyn540vysU1YK/owEpIeZS/5PHVMbMlBQKfb0lv9EG9plJxkOdyCm/80p6BBc3qn2LqJxOJ0FBQTgcjqorm9jt9gBKpDjdWFEEQ4A2UkrfmTMUijNE0f4iDr580P/1XfbTPzu7PDOz4kHJT3HwqVvMiLv2IFsVsDzTd8rJmsq2bdsYOXKkX0pA5Q2ufVhRBNuAGFRCeUU1kpOcQ8rzKaQvSgdn1fU9cFvlezr4s7CQd1JTKzYJZYbAtA7l3y9Kh4FHAHyPHmogJSUlPPPMMzzzzDN+KQFQeYNrI1YUQQyw0wwr4T5HoNxHFQFFOiUZSzJIeT6FnHU5J1YQWBoZlK3yPRVyS0tZlJ7O26mprHXLpOWBDvw3CY6bK5Lji2HiH4acgL2W+IwmJyczYsQItm/f7ioLDg4mKSmJPXv2qLzBdRAriuCxgEuhULhRmltK6rxUDr54kKJ9J5pTYrQttOh1iKNpXcjc3Qgd3zl8y1b5RnaP9FsOXUrWZmfzdmoqi9LTyS97o5fAjkj4KBHWx0GJBiE6tCiAP83jCAmTd0B0qSEH0D/u9I1KAkFBQQGPPPIIL774ooeHUK9evZg7dy5nn322yhtcR7Gysvi7MyGIQlF0sIhDsw5xePZhnMc97T8CB41YTQs+JlL/E9ZBLDZ2MpkMLkQnBHCLYeO2yjdpfpJfHdO+wkLmHz3KO6mp7CvyUkSlAp5NwvZjPHqJhtTNdott8GeD8no3HoD/y3Z9DdM0JiSe2qgkkKxevZrbb7+dvXv3usoiIiJ49tlnueuuu1zxgbzzBhcWFmK321Xe4FqOlRGBQhFQcjblcPCFg6R/lI4s9bT1BJFLM5bQnM8IJdNjm4aTjjxFbnRPUi59lcxv8lyxhhIGJZA4MZGo7tbcNfOdThabpp9vs7MrrNPJHk7IM53546dwCosqUixmmZCQGmaMHIRhEhoUH0/3SP9HJYEmOzubBx54gDlz5niUX3XVVcyePZtWrVp5lHvnDVbUDZQiUFQL0inJ/DyTlOdTOL72RJu7PVHQ4ugrNCn5HBu+vW0EEOX4lc5TSmHJJYCR1Lxzn6rdNKWU/HD8OG+npvJRejp5zhNnoRsGBTG0USNubdKE0t8jufIbUXVeGylgfTxiZyT2zvkMio9nfpJ/o5IzwdKlS7nzzjs5fPiwqywmJoYXXniB4cOH1zh5FYHDpyIQQnwjpbxCCDFNSjnpTAqlqLs4852kvm3Y/wv3nNijRl8aTeL9icS9exfik0+wtGqsqMjIQ7xwoSUZDhQVMT81lbdTU/nT2/SDYc+/OjaWW5s0YVB8PKHmJO8Nz/uR3KxY0GLp2Sy+WdA9qmYtIktLS2PcuHEs9Lpe1157La+++ipNmzatJskU1UVlI4KmQogLgUFCiA9xjXsN1MpihT8UHyrm0CuHOPzGYUqPlXpsE0GChBsTSByfSOR5pvnkX37kFdZ1V15hXxQ4nXyakcG8I0dYnZ1dobNRUng4tzVpwi2NG9Ms9MTIpP6kOkZqZH0fjUXL1BlBSsmCBQu49957ycwsN7M1btyYV199leuuu64apVNUJ5UpgkeBR4AWgHceJbWyWGGJ3F9yOfj8QdI+TDvR/h8TRNMxTWk+tjlhLbw8f/wMUSALC/E2ZEgp+Sknh3mpqSxMSyO3AtNPtM3Gvxo35tYmTegRGVmhOSQ9Hb76ylJ2Sw9qUpSFlJQU7rjjDlasWOFRPnz4cJ5//nliY1WuqfqMT0UgpVwELBJCPCKlfPIMyqSoYVSU/EWza8T1j/NM/lJWX5dkrsjk4MyDZK85ceI1rE0YLca3oMmtTQhq4OMRtJhXuIzi0FBsuk6wppEOPLN/P2+nprK7gt5YAH9v2JBbmzRhcHw8dq+MWQ4HrF8PK1caf5s3GyEq/KUmRFnQdZ033niDSZMmkZub6ypv2bIls2fPpm/fvtUonaKmYMV99EkhxCDgErNojVuyGkUdx1fyF71A90z+Mj8J6ZCkzk/l4AsHKdxVgf3/omha3N+C+EHxlQd+y8mByEjLisApBJ/37MkLW7YQoWl8Dch9+06o195u59YmTfh348a0CPMcgfz1V3nH/803hgingqZBIKMsSClJTk6u1I1zz549jBo1irVr17r2E0Jw991388wzzxBZA72YFNWDlcQ0zwI9gPfNonuFEBdKKf8TUMkU1Y7l5C9LMtjUbRPFR4pxHvMyv9ig0ZBGtBjfgqgeFgzmKSlGD1qW59cCRSEhTB8yhI0V9N5RNhs3NmrEbU2a0DOqPOx0fj58953R8X/5Jeza5bt9mw169oROneDdd4256aoIC4NARVmoKmXk8uXLadeuHTt37vTIGtahQwfmzp1L7969AyOYotZixX20P9BNSqkDCCHeAX4BlCKo41hO/lKoU/C759u7LcpGs9HNaH5Pc8Ja+l7568HmzTBwIBw54ioqtdkIqsC2X0Z+aChLevdmY1KSq0wAVzRsyG1NmvCP+HjCbTakNHLWl3X8339v5LL3RcuW0Lev8XfFFRATY5iHcnNhyZLK7f92OwwaVGGCs1PGSsrIgoICtm7d6iqz2WxMmjSJRx55hLAwi/dCUa+wuo4gBsgyP0dbbVwIcTXwEsaSzzlSyv9WUOcG4HGMCeitUsqhVttXBJaTSf4S1iqMFve1oMmIJgRF+rFMZckSGDq03BwUHAyvvcYnH3zANevWYS8uxuZmqHcKQVFICEt692b45MlgvukHC8G7UnJj165kZsKyRUbHv2oVuLnLnyh3GPTpU975JyW5mnQhBMyfD8OGwbJlhjJw9yLSNKOdQYOMeoFww/c3ZWT79u1ZuHAh3bp1O/3CKOoMVn6pzwK/CCG+xXjZugR4qKqdhBA24FXgKuAgsFEIsVRK+btbnXbAZKC3lPKYEKLRSZyDIkD4nfwlVNBjdw+0ID+Cq0kJL70E99/vmpGVMTHsfPoTHv3yMhZ9P5zuJZuZoM2gv1iBXRZSGBrK5716MfOGG9jkNhLAKSjdEcny5FienwQbN1Y+ydu5c3nHf/HF1iZ3g4NhwQKj7RkzYMUKQyHY7YZFy0eq49OGPykjhRB07dpVKQFFlViZLP5ACLEGKHu8J0kpUy203QPYI6XcC2CuRRgM/O5W53bgVSnlMfNYKtR1DcLv5C8O6Z8SKC2F++6DV18tb6N1ayZ2XMHrDyQZtng9iI1cwE36xyB0CJVwYQZM3glBEtJCYWMsJMfCzzHIvGDe9XG4hg3hyivLO/8WLXxUrAIhoEcPqI4oC/6kjJRSnuAuqlBUhKWxu5TyCLDUz7abAylu3w8CF3jVaQ8ghFiHYT56XEr5pXdDQojRwGgwFr+sWbPGT1EM8vLyTnrf2sopnXMIboHHrdW3eixbQQGdpk4lbsMGV9nxTp25LXYhK75pR3FFx5UaFAHfJ8DuBsb49ECEz2NomiQpKYfu3Y/Ro0cWHTrkUOYpumeP8Vfb8DcFZEFBQZ195tXv+fRR3bGGgoB2QB+MhWtrhRBdpJQezudSytnAbIDzzz9f9unT56QOtmbNGk5239rKqZzz9kHbjUQwVnzoNSPQm5UYPxw8CAMGgNuEJjfcwB93vc2q/vaKlYA7Dg1SKlYACc10zu96lNtua8oVVwhiY6MxprVaWTiJmk9YWJhfyiA8PLzOPvPq93z6CKQiOAS4x91tYZa5cxDYIKV0APuEELswFMPGAMqlsICUEluUzXJKSMvJX375xVAC7jO3kyfDU08x4ybN/9W4wTp0zSaoxzGu6gufD2jD2rV/0KdP3YuX8+mnn1o2C4FKGamwjmVFIIQIA24B7MACKWVmFbtsBNoJIVpjKICbAG+PoM+AfwHzhBDxGKaivSiqFb1Y549Rf3D0PWu+/JaTv3z+Odx0k+HEDxAUBG+8ASNGAH7G8gEI1hFLf8AejivCp6bVvYiZqamp3HPPPSxatMiv/VTKSIVV/Mmd9xJQAhzD6MArRUpZCowFVgI7gI+klNuFEFPNlcqY2zKFEL8D3wIPWFAwigDiyHKw9e9bPZRAcJNgtHDtxKdFAy1cI36wheQvs2bB4MHlSiA62vDrNJUAnERsnlLBkMQ41nTrxgedOhFcS1JBWkVKyfz58+nUqZOHEggLCyMkJKTSfVXKSIU/+PzlCCE+EEK0dSuKBT4GFgMNrTQupVwhpWwvpWwrpXzaLHtUSrnU/CyllPdLKTtJKbtIKT88+VNRnCoFewr4udfPHvkBmt7elJ77e9Lt224kXJeAFmEoBC1CI+H6BLqt6UanDzqhBft4lJxOGDcO7r23/HW/VSv48UdjpRbGqt7rr/c/nk9EuGBh5841Lszz6WD//v3069eP4cOHc+zYMVf5iBEj2L9/P//85z+JiIhA81J+mqYRHh7O4MGDVcpIhWUqMw1NAZ4SQhwBngRmAJ8CYRgLwBR1iOPrjrPtH9twZDhcZW2mtSHxgUSEEET1iKLzRxYmgt3Jy4N//cswCZVxwQXG4rHGjUlLg6lTDetQaanvZioi0LF8qgtd13nttdd46KGHyMvLc5W3atWKN998kyuvvBI4MWVkQUEB4eHhKmWk4qSoLProXmCoEOIiYCGwHOgvpfS93l9RK0lbmMaO4TuQxcYruRamkfRuEo2ur2J9n5SQnFzxyqphw+CRR2DLlvL6118P8+eTr9t5/kmYPt3QFR5oOuhVm3gCGcunuvjjjz8YOXIk69atc5UJIRg3bhxPPfUUDRo08Ch3TxlZHz1oFKePyjKUNcSY3HUAQzAWg60UQrwkpVx2huRTBBApJQeePcC+KeWROoMTgjln6TlE96wikojDYXT2S5caUdjKzD4FBbB4MSxa5GnrmTSJ0qnPMO8djcce8wgnZNA1G8b8CYtaEPxjAo4i38ogkLF8qgOHw8GMGTN44oknPILEdezYkblz59KrV69qlE5RH6jMNPQZhu9+OPCulHKwEGIR8IAQYrSUcuAZkVAREHSHzq47dpH6Vvki8fCkcLos74K9TRWxFqQsVwIVxbzxcv2Rr7/B581GM6kb7NjhWTW0dQHFt/8JPTMRAl59y8nah7Rqi+Vzpvnll18YOXIkv/zyi6ssKCiIyZMnM2XKFEIryJSmUJxuKlMEccAiDHfRMQBSykJgqhCi7jlp1yMc2Q62X7+d7G/K1+3FXBZD58WdCW4YXHUDyclG1DULgc/0kDDufL0bs7d4ljdqIhEj9nH08hSwSTTgraQkhjdpwh3VGMvnTFFUVMTUqVOZPn06Trfoqueddx5z586la9eu1Sidor5RVarKLwEnXkHmzJATilpI4V+F/HbNbxTsKO/EGw9vTIfZHdBCLLpfzpxp2ddTlpRw2ZaZzMZIlB4ZCaPvd7Do0l/YLwwZbMB7HTtyU+PGQPXG8jkT/PDDD4wcOZJdbkkQwsLCmDp1KuPHjycoqLoX/CvqG5VNFn8CfHIGZVEEmJzkHH4b+BuOtHLPoFZPtuKsKWdZcjMsmxvu+slywiyu/LKhM4DlBAXBHXfALRMKuOHIVg6YtvBgIVjYqRPXJiSc3EnVInJzc5k8eTKvugXZA7jkkkt48803ad++fTVJpqjvqFePekL6J+nsuGWHK6KoCBEkzUui8dDGlvZ3nxvOdfq38iucQn7/HZzN8rli61YOmxlhQoVg8Tnn0D8uzr+TqYWsXLmS0aNHc+DAAVdZZGQk06dPZ/To0SesB1AoziTq6asjSCnJ2ZDD9iHbWRuxljXaGtZGrIXHYfe9u9l+3XaXEgiKDaLr110tKwH3ueHYghR0Px8bLcJOcdM8+mzZ4lICYZrG0i5darUSkFKyYcMGhgwZ4lrcFRERwQ033EBycjJSSrKyshg+fDhXX321hxLo168f27dv54477lBKQFHtqBFBHaCyBPN8B4e+K4/1Zz/bTpcVXQhvF265/eRk+HppAQ8UTOdBphOEH0tJNI2svn3ps2ULmeaqsQhN4/MuXejT0NIC9RpJVXmDV6xYQbdu3di1axfp6emu/eLi4njppZcYOnSoWvWrqDFYSV7fHngNaCylPEcIcS4wSEr5VMClU1RJlQnm3QiKD6Lbj90ITfDDJVFKNoxbwM8FD5HIQb/lc4SGcv3f/+5SApE2G1+cey69oy1nPK1xWMkbnJ+f77EwDODGG29k1qxZNGqkEvEpahZWxqRvYqSTdABIKX/FiCSqqAFYTTAPxgiheJ8fmWY2bIALL2Rc8i0eSuAXuvI1l5NP5esN8kND+bhXL741J0FjgoL4umvXWq0EwP+8wXFxcXz22Wd8+OGHSgkoaiRWFEG4lDLZq8zPyDCKQOFPgnm9SCdlZkrVFQ8dgn//G3r2hPXrXcVHacRI5nA+m+nHlyxhMHlE4PR6jJxo5IeGeiSWDxGCb849lx51IECcP3mDwfAKGjx4cAAlUihODStzBBlmFFIJIIS4HlDrCGoIfiWY1836vigoMFZxTZvmsVismBBe5D6eZgq5RJlN2biZBXRnIxOYQX9WYKeQQux8rl3DzBcv90gsbxOizrw9+JM3GGDVqlUBlEahOHWsKIK7MUJNJAkhDgH7MBLUKGoA/iaYr7C+lLBwITz4IKR4jhh2d7mWfr89x5+0PXE/BBvpwU24rfwSOlyaAUm/e9Qs1nVmpqSwsLOfEUxrIP7mDfa3vkJxpqlSEZhRSK8UQkQAmpQyN/BiKayi2TVL8wPu9T3YuBHuu8/ID+CGo9O5TAl/kec2XeafQCEShpxoftKB5Zl1I+eQ3W63PD9QVl+hqMlY8Rp61Os7AFLKqQGSSeEHDc5rQM73OdYqaxDX3/TbP3zYyBU8f75nnYQEfr3xKf7+4UiOZthcxQ0bGlEliooqaT/UCb0zIKnid4VCv/JQ1kw2b95McLCFeEwmKm+wojZgZbI43+3PCfQDWgVQJoVFMpZkkPOTRSWAmWD+7kbw9NPQvr2nEggOpvS+iTx47W66vjLaQwmUWYz+8Q+IiDCigHog9HIlMHkn+HCPt9fihVOFhYVMmjSJHj16cPz48ap3MFF5gxW1ASumoZnu34UQMzByDSuqkbSP09gxdEe5/5bAnM6vGM2uEd8tn8h/d4cD+z03Dh7Mrtuf47qH2rFtW3lx06aGrjCTYrFgAfyw3sk9Txex9ZswKNYgVIdemXBDis+RABhvHLV1FfHatWsZNWoUu3fvdpVpmobNZsPhcPjcT+UNVtQWTuYVLRxocboFUVgn9b1Ufr/pd2Sp0fOHtgklbmCcK5+wBwK0MIiP2ELSjwMR7krgnHOQX33NK1d+xrnXeSqBwYPh11/LlUCprjMv9Qg3k8zWiRvhi+9h9XfG/0d/r1QJgBFSYkJi4mk4+zNHTk4Od911F5deeqmHEujTpw/btm3juuuuU3mDFXUCK3MEv1H+rmkDEgA1P1BNHJ5zmF2jd7nuSHhSOF2/6UpI0xByN+aSMiOFzBWZ6IU6WqggIvp32qXOIqpoZ3kj8fHw1FOkDxrJiNFBHimF7XZ4/nkYM8YIBy2l5JOMDB7et4+dXhOkiSEhNAsN5df8/Ert/3ZNY1B8PN0jI0/npQgoK1as4I477iDFzYsqKiqK5557jlGjRqFp2gl5gwsLC7Hb7SpvsKLWYcV9dIDb51LgqJSyrriE1yoOvXqI3WPL30wjukTQ9euuhDQKAShPMF9UBC+8AM88A6luSYGDgmDcOHjkEVYlxzD8/yC1PEEZXbsa5p9OnQwF8FXWMf6zbx+bcj3f9hOCg3n4rLMY06wZGjBs506WZWRQqOseSxo0jJHAoPh45icl1Yo344yMDMaPH897773nUT5gwABee+01WrQoHwx75w1WKGorleUsjjU/eo/5o4QQSCmzAieWwpuUmSn8OfFP1/cG/9eArqu6Ehzn5sEipZEv+IEH4K+/PBsYOBBmzKD4rPb85z/GW78748fDs89CrZNPogAAIABJREFUaChsyMlh8t69fJud7VEnymZjYmIi97VoQaRb8pQFHTuyMTeXGSkprMjMpFDXsWsa/ePimJiYSPdasJpYSsnHH3/M2LFjPYLExcfHM2vWLG666aZaocgUipOhshHBZgwDREVPvwTaBEQixQnsf3o/+x4uTzAfeUEk5355LsExbkrgl1+M9QBr13rsm9+qFRGzZ8NVV7FjBwztCVvc0kY2bgxvvw1XXw3b8/OZsmsvS7z8/cM0jbHNm/NQy5bEVeA6KYSgR1QUH9XSxWKHDx/mrrvuYsmSJR7lQ4cO5cUXXyShHiTNUdRvKstQ1vpMCqI4Eanr/DXqR/bPK7fERWvb6NL0J4J23Wsk7z16FKZMgXnzjBFBGXFxMHUqmzp04JLLr2D2G8Zbv/si12uuMXYriCxk+I6/ePfoUQ/HIxswomlTHj3rLFqEhQX8fM80UkreeustJkyY4OES2rx5c15//XUGDBhQyd4KRd3BUj4CIURDoB3g6g2klGt976E4VWRJCXu7vkbKzvIk5g3ZxDn6I9iWlsCqz6BdO/jzT8jzmgcYOxYefRQaNiR7yQ/885/w2WflVUJD4bnnYMjoEp48sJ83dhzGIT19T29MSGBq69a0D7eet6A2sXfvXm6//XZWr17tUT5mzBimTZtGdC2PkKpQ+IMVr6FRwL0YLqNbgJ7AT8DlgRWt/iKdOnvOmc2h3eVKIJb1dOZRbDiMeA0FBbB1q+eO/fsbQePMYG+rV8OoUd3JyCiv0rkzvDHfwRcxKZy94SD5Xt4+/WJjebp1a/5Wizx8/MHpdDJr1iwefvhhjzARbdu2Zc6cOfTp06f6hFMoqgkrI4J7ge7AeinlZUKIJOCZwIpVf5G6ZNc/13Fk9zmusni+pxNPouFj8VKrVvD669C3LwAlJcaAYPp0kLI8Cc0dd+u0GHeIgWn7OZbj6fjVOyrq/9k77/AoijeOf+ZSSCH0KgQINYUUSKFJr4oEkCpIUQSpFooiiAKKioINsCAIFqQISBEUFBMRQRIQFAi9SP1hCCYkJIHkbn5/3GW5Sy65PdKT/TzPPsnuzc6+s8ntuzPzzvflzfr1aVuhQp63qahw7NgxRo0axf79+5VjOp2OyZMnM2fOHNxKaO9HQ8MWahxBqpQyVQiBEKKMlPKEEKJJvltWCjGkGzj55Emub7mXCrIqv+DDG+iySw8phHGuwOQETp2CIUPg4MF7RapUkQxccJPvGp3k2tW7FqcHuLvzRv36PFypUrGNipFSEhUVlW08f2BgIPPnz+f111+3WAns7+/P8uXLtXh/jVKPGkdwWQhRAdgE/CSE+A/4x8Y5GnZiSDNwfOhxYr+9F7pYnR148zYip4QDUsL27UhpnPh95hm4ffvex/VDbqJ/9TwflU0EMx9Q38WF17y8GFytGrpi6gDAdu7grVu3UqZMGYvJYCcnJ2bNmsWLL76Is7NzYZmuoVFkUKM11Nf062whRARQHvgxX60qZRjuGDg26Bhxm++FbdbkexrzLiInAaGM85OTqftQApd33JvgdHSSVBt/iXPh5yxkJ2o6O/NK3bqMqlkTp2IsAgfqcgenpqaSaiaZ2qJFC5YvX45fMQ111dDID9RMFn8IrJFS7pVS/mpP5UKIHsAHGCMRl0kp38qmXD9gPRAqpTxgzzWKA1JKEqMyyT+46qjcszK1Jtbinzf+4b8d/ynlazluoWH6e9mJeGYhWbpaOAHXeimkzDjG1Ub3ookqOjryYp06TKpVCzcHB2vVFDvszR383HPPsWDBAhxKSPs1NPIKNUNDB4GXTfMC32F0CjYf1kIIB2AJ0BW4DEQLIbZIKWMylfPAOCG9P2stxR9DmoETw09wY8sNDKkGJa2kIdlA7IZYYjfEWqSa9BxTjvprVyBUKh3r0fG9uQpIr6ukjD8DLsZKXYDJdeowzdOTCnbo6BcH7MkdrNPpuHr1quYENDSsYHNsQEr5hZTyYYyRQyeB+UKI0zZOAwgDzkgpz0kp7wJrAGsZvF8D5gM5pTwplkgp7zmBZEPW3MIGLI7VGXSH+ms7IxLiUUsqLrzLFPBIg7lHYfIpcDHgAEysVYtVwLz69UucEwD7cgcbDAa2bduWzxZpaBRPVC0oM9EQ8AbqAsdVlK8FmOcsvAy0MC8ghGgOeEoptwkhpmVXkRBiDDAGoHr16kRGRtph9j2SkpLu+9z7IgbjFLsaFyf0VFn7HAKjEzAgSMcR5+xCRoHbuLKZcKJFCLx0FFrdk38KBfpduVLwbS5A7M0FnJycXGLvRUn+O2eH1ua8Q80cwdtAX+Asxrf616SU6l9Zs69XB7wLjLRVVkq5FFgKEBISIu930U9kZGSBLhg69tExYu/G2i4IIOESA/DjNfD05JUGq/GLXEwvtuJKCg5mXQc9OlJxYTPhjMCUZeynGhaO4IhOR4d27Qq8zQWFlBInJyfu3r1ru7AJNze3EnkvoOD/t4sCWpvzDjVhI2eBVlLKHlLKlXY4gSuAeSaS2qZjGXgATYFIIcQFjCuWtwghQlTWX+SJ2xaXdTgoWxyIo5VxPcCff/JeVBuG8A2d+IX19CMJd/ToSMKdb+lPByIZymrScQKpg32W2b9KQn7g7Lh8+TLh4eF2OQEtd7CGRvaoCR/99D7rjgYaCSG8MDqAwcAQs3oTgCoZ+0KISGBqSYoaMqTY9zA2CBfYvh10OpM4nCCaMAajQu/+jqVPL875gbPDYDCwbNkypk2bxq1b6nM1g5Y7WEMjJ/LtaWFKXjMRY37j48A6KeUxIcRcIUR4fl23KKFzte/26twclMzwrq52XqzMPadTnPMDZ8eZM2fo3LkzTz/9tIUTaNSoEa42bpaWO1hDI2fy9bVRSrldStlYStlASjnPdOwVKeUWK2U7lKTeAEDlnpXV32GdqbyJnj0Vn2AbYUogb6I45gfOjvT0dBYsWIC/v7/FJFmjRo3YvXs3x44do3fv3lruYA2NXKAmQ5lVtAxlmZASoqKM6p/bt0NKCp7OQcSJ+RiwHbqpc9HhOeXew3vKFNi61Zh10ibOEgYYA7SKY37g7Dhy5AijRo0iOjpaOebg4MC0adN45ZVXlJ5A5tzBycnJuLm5MWDAAJ555hlcXFw4c+ZMYTWjQChfvjzHj6sJ5is5aG22jouLC7Vr18bJjpBxLUNZXpCWBsOHw5Ytxie3aaLW/c7f6EjCQMUcT9e56qgSXgWP0HsP7+bNwcVFhSMoo4c2NxDeiYoTKC75gbPjzp07vPHGG7zxxhukp99TSQ0MDGT58uUEBwdblM+cOzgjsuL8+fN4eHhQuXLlYn0/1JCYmIhHCXD+9qC1OStSSuLi4rh8+TJeXupzi2U7+CCl9JJS1jf9zLxpTiADKe85geRkxQkAnGMs6YoTkGQJIdKBzk1Hld5V8P7S8uH9wQdwL2WwNA7/WJwrwcXoBNxmnmJAtapEBgWx2te3WGsI7d+/n+DgYObOnas4AWdnZ+bNm0d0dHQWJ5ATqampqpyAlJL9+/czYMAAZYjJ3d2dgQMHEhUVhZS29Z40NIoCQggqV65soa+lBi1DWW6JijKO4WTSu7lOJ67QX9l/gE2kUZE4lw4Y7qJoDXlO9aRcqGVy97NnjfkEFHpfhXgn2F8ZcUeHm5ugZ0/B1KkOhIZWB6rnYwMLhtu3bzNr1izef/99iwdv69atWb58Od6mZDv2YssJ2FIv3b59O7169eLLL7+0q6utoVFY3E/vV8tQllsWLrRMBAwk4cVJpir7VdhNIz5E6HQQfhzWrs22Oinh6afvVenU6DZpE8+Ao+ThSpX43t+fkjbKsWvXLkaPHs358+eVY+7u7rz55ptMmDAhyyRwXqFGvfT27dts3ryZ4cOH880335T4ISaN0omab1hGhrJ/pJQdgWZArlcWlxi2bbMYDkrDnaO8hgHjRKYrF/FmvnGixWAwls+BL7+EXbuMvwudJG3KCXCUVHR05LMmTUrUgyg+Pp7Ro0fTpUsXCyfQtWtXjh49yqRJk/LNCYB69dKUlBS2bt1qMWmtFgcHB4KCgmjatCm9evUiPj5vvjoXLlygadOmtgtqaKhAzbcsVUqZCigZygAtQ1kGZr0BieAEM0ilFgA6UmjKKziSbLV8Zq5fh+efv7cv+12GJokALGnUiAfKlMnmzOLH5s2b8fX1ZdmyZcqxihUrsnLlSnbs2EG9evXy3QZ71EtTUlJYuHCh3ddwdXXl8OHDHD16lEqVKrFkyRK769DQyG/UOILMGco2o2Uou4fZYqZ/eJw4Wiv73szHPfOtymHx03PPwX+mtAQONVPhCeNb8oCqVRlcrVre2VyI/PvvvwwePJg+ffpw7do15Xi/fv2IiYlhxIgR+dLrMaVatdi+/fZbu9RL161bZ7UetbRq1YorV4wqK0lJSXTu3JnmzZvj7+/P5s2bAeObvo+PD6NHj8bPz49u3bopzurgwYMEBgYSGBho4VBSU1MZN24c/v7+NGvWjIiICABWrlxJnz596Nq1K/Xq1WPx4sW8++67NGvWjJYtW3LzphYBrmFEjQx1XyllvJRyNjALWI51OenSiWnlVxxhXDDTz6vNWqqRKY+PTmcsb4Vt22DNmnv7+udPgquBak5OfNSoUbEYEsop+mb//v189dVX+Pj4sNZsjqR69eqsX7+e9evXU6NGjUK0Pn/R6/Xs2rWL8HDjonoXFxe+++47/vzzTyIiIpgyZYoySX769GkmTJjAsWPHqFChAhs2bADgiSeeYNGiRfz1118WdS9ZsgQhBEeOHGH16tWMGDFCiRo5evQoGzduJDo6mpkzZ+Lm5sahQ4do1aoVX375ZQHeAY2ijJrJ4q+klMMAMjKUCSG+Aobls23FgylTSNm0n+OGmWT41Qocor5RLNUSFxfjSrFMJCbCuHFmB7r9D0KNXYPPmjShSjHIq2sr+mbjxo3o9XqLc0aOHMnChQupVCnHtYvFmpSUFIKCgrhy5Qo+Pj507doVMDrNGTNmsHv3bnQ6HVeuXOH69esAeHl5ERQUBEBwcDAXLlwgPj6e+Ph42rVrB8CwYcP44YcfANizZw+jRo0CwNvbm7p163Lq1CkAOnbsiIeHBx4eHpQvX55evXoB4O/vz99//11wN0KjSKNmaMgiuasp85j6YO4Sjj4hlWNpL5OOMQTUmVh8mYsu85oBV1cIDwcrejczZ8IlU+YGUT4Nxp8FYGSNGoRXqZKlfFEjc/RN5uEWg8Fg4QTq1KnDjh07WLFiRYE5ASlllm3AgAGqJ6N1Oh0DBw60Wk9OZMwR/PPPP0gplSGdVatWERsby8GDBzl8+DDVq1dX3uLLmM0FOTg4WCyqsxfzunQ6nbKv0+lyVa9GySLbb4EQ4iUhRCIQIIS4ZdoSgX+BzQVmYRFGXrvGqT6/kkQjAARp+Ik5OJsHVel04OYGvXsbQ4IyDfHs2weLF5vVOfE0lE/Ds0wZ3m/YsCCakWvsyR3s6OjIF198Qbdu3QrAspyZMmWKTcG6DHKrXurm5saHH37IwoULSU9PJyEhgWrVquHk5ERERAT//JPztFuFChWoUKECe/bsAYyOJIO2bdsqq6pPnTrFxYsXadJEi+fQUE9OK4vflFJ6AO9IKcuZNg8pZWUp5UsFaGPRJD2dq+3f5XpKO+VQw3F6yvf3BXd3owNwd4f+/SEyElavhkwLku7ehdGjjWsHAGgRB53/BeDzJk0o72hPArnCw57oG4PBwMcff5zPFqkjLCyMXr16FZh6abNmzQgICGD16tUMHTqUAwcO4O/vz5dffqlqwdyKFSuYMGECQUFBFj2R8ePHYzAY8Pf3Z9CgQaxcudKiJ6ChYRNrXV0rXd9aQGugXcam5rz82IKDg+X9EhERcd/nZiZ+2Jsykp0ygggZQYQ83m2XNBgMdtUxd66URjcgJa7pktV7JRERcsLJk3lmZ162OTvc3NwkRg0NVZu7u3u+2pPR5piYGJtl7969KwcPHizd3d2lTqezsFOn00k3Nzc5ePBgeffu3Xy1ObfcunWrsE0ocLQ2Z4+1/33ggMzmuapmsvgtjEllYoCMgV4JlFqJiTtfbOXYVw2QJlXRsjUTabTpYbsie44fh9dfNzvw5DmocYeGrq7Mb9Agjy3OX+zNHWxv+fzEyckpi3ppSkoKrq6u9OzZk6lTp2p5DDRKPGrGHvoCTaSUd/LbmOKA4eRZYkb9w12MqzodnVLw29MZB1cH9XUYjENCSqZF71vQ9wo64Atvb9wd1NdV2Ozdu9fuc9SOyxcUmdVLNTRKG2pCJs6BCkH90kBKCufafkWCPmNpvwHfb3xwre9mVzVLl8Lvv5t2HAww7SQ4wFRPT1qXL5+nJucXSUlJPPvsszz44IN2qXNquYM1NIoeanoEycBhIcQuQOkVSCmfyTeriij/9lzA5dgOyr7X2DJU6l/PrjquXIEXXjA78NglqH8bPzc35hSArEJe8NNPPzFmzBguXLhg97lFMXewlJKoxEQWXLrE9rg4UgwGXHU6elauzFRPT0I9PIrFgj4NjftFjSPYYtpKNbdf/5oTESHKfuWAROosecSuOqSE8eONC8gA8EyGYf/gKARf+vjgUsSHhP777z+mTJnCihUrLI53796dMmXK8NNPP+U4/l8UcwenGQwMP3GCLTdukGowKKs/kg0GNsTGsj0ujl6mZD/FOc+DhkZO2HQEUsovhBCuQB0p5ckCsKnIkf7bIY6+wj1FUY8EfH59GKGz7y1xwwZj/hqFKSfB2cCsuvVoXsQzLW3cuJEJEybwv//9TzlWqVIl3n//fR5//HHS09MZPnw4W7duJSUlxWJRmU6nw8XFhfDw8CKVO1hKqTiBZCuaQwbgtsHA5hs3GH7iBN/4+BQZ2zU08hKbrzhCiF4Y8xD8aNoPEkKUmh6CvPkfx3tEkiJrA6ATd/D7uTWOFeybNvnvP5g0yexAr6sQmECIhwcv1amThxbnLf/73//o378//fr1s3ACAwcOJCYmhmHDhiGEUKJvfvnlF/r162ehNdS/f38iIyNZvXp1kUruEpWYyNZsnIA5KQYDW2/cIFrpyqlHrQz17NmzWbBggd31FwfKli1b2CbcN2+88YaqcvXq1ePGjRtZjiclJTFu3DgaNGhA8+bNCQ4O5rPPPrNZX+vWrW2WyUvU9HVnA2GYchBIKQ9TWvIVS8nFBz8iLrmZcsh7YXXKhlW1u6oXXgDlOVr5Dow5Sxkh+KKIDjlIKfniiy/w9fVVRM8AatSowXfffcfatWupXt0yM5p59E1SUhJ6vZ6kpCTWrl1bpIaDMlh46RIpKtVHUwwGFmbogNhBQctQ54VsRGZNqKJAYclhqHUE2fHUU09RsWJFTp8+zZ9//smPP/6oSvX1fqLxcoOaJ1CalDIh0zF1355igpSSW/tvcWzAMXa77yZSF8lu990cqr+V88dbKeVq90yh2vNBdtcfEQFmsvvw7Gkoq2de/fr4urvnQQvyln/++YeHHnqIkSNH8l+GLjYwatQoYmJi6NOnTyFad3+IyMgs27exsar/kQ3AuthYq/WoxVyGOifOnj1Ljx49CA4Opm3btpw4cQKArVu30qJFC5o1a0aXLl0UkbrZs2czevRo2rRpw7Bhw1i5ciWPPvooPXr0oFGjRrxgFp2wc+dOWrVqRfPmzRkwYABJSUmA8Y32xRdfpHnz5nz77bcW9ly4cIFOnToREBBA586duXjxImAUDXzmmWdo3bo19evXZ/369Tm2KzIykg4dOtC/f3+8vb0ZOnSoEnEWHR1N69atCQwMJCwsjMTERFauXEl4eDidOnWic+fOALzzzjuEhoYSEBDAvHnzFPu8vb0ZOXIkjRs3ZujQofz888+0adOGRo0aERUVBRjToT755JOEhYXRrFkzRfo7u/s1ffp0RTRw6NChAPTp04fg4GD8/PxYutSKsGSmv2NUVBSvv/66omlVtWpVXnzxRSB7KXK414vKfM9GjRqVPzm0s1tplrFhlJ0eAvyNMW/xIuATW+fl15bXK4v1d/Xy2OBj8le3X2WELkJZKWzcflF+P/jAt1J/V2/3NZOTpWzY0GwFcdt/JRERsu2ff8p0O1ci3w/2rCzW6/Vy0aJF0t3d3WKFbb169eRPP/2Uf0bmMdZWFhMRkW9bTmSsok5PT5f9+/eXP/zwg9Vyr776qnznnXeklFJ26tRJnjp1Skop5R9//CE7duwopZTy5s2byur1zz77TE6ePFk5NygoSCYnJ0sppVyxYoX08vKS8fHxMiUlRdapU0devHhRxsbGyrZt28qkpCQppZRvvfWWnDNnjpRSyrp168r58+dbte2RRx6RK1eulFJKuXz5ctm7d28ppZQjRoyQ/fv3l3q9Xh47dkw2aNAgx3sQEREhy5UrJy9duiT1er1s2bKl/O233+SdO3ekl5eXjIqKklJKmZCQINPS0uSKFStkrVq1ZFxcnJRSyh07dsjRo0dLg8Eg9Xq97N69u/z111/l+fPnpYODg/z777+lXq+XzZs3l0888YQ0GAxy06ZNir0vvfSS/Oqrr6SUUv7333+yUaNGMikpKdv7ZW57Bhm2JCcnSz8/P3njxg3l/sXGxlqU3bx5s+zTp4/VeyKllGlpaTIhIUFKKWVsbKxs0KCB8vfN7p6FhobK3377Lds6M8jzlcXAJGAmxtDR1cAO4LU890iFgJSSE8NPcGPLDQzJ1t4NMyYGJU4hjRGO9k8UvvYanDlj2nFPh2dO467TsdLbG4ciNPF48uRJRo0axe/KAgfjUM+zzz7L66+/jnsR7LkUB7KToc6OpKQk9u7dy4ABA5Rjd+4Yo7YvX77MoEGDuHbtGnfv3sXLy0sp89BDD1ks1OvcuTPlTWtSfH19+eeff4iPjycmJoY2bdoAcPfuXVq1utfjHTRokFWb9u3bx8aNGwGj/LV5D6NPnz7odDp8fX2VHkpOhIWFUbu2cb4tKCiICxcuUL58eWrWrKkMH5YrV04p37VrV0WhdufOnezcuZNmzYxDtbdu3eL06dPUqVMHLy8v/P39AfDz86Nz584IIfD391fCnHfu3MmWLVuUuZjU1FSld2Ptfnl6emax/8MPP+S7774D4NKlS5w+fZrKlSvbbDfAvHnz+Pbbb/n333+5evVqtlLkmfNymN+zgIAALly4wIMPPqjqmmpREzWUjNERzMzTKxcBEqMSubE1OydgjuC/XfEkRidSLqycjbL3+OsvePttswNPn4Uqd1nYsDH1i8jq2rS0NBYsWMCcOXOUBw6Aj48Py5cvt3hQFGdkhw5Zjg08dowNKoeHdED/qlVZ6+dns6w5GXMEycnJdO/enSVLlvDMM88wc+ZMtpnyVx8+fFgpbzAYqFChgsWxDCZNmsTkyZMJDw8nMjKS2bNnK59ldtTWpKyllHTt2pXVq1dbtfV+nL35daSKIQt7JbbNbZJS8tJLL/H0008DkJiYiIeHBxcuXFAlty2lZMOGDVmUWffv36/KrsjISH7++Wf27duHm5sbHTp0UKTDreHr68tff/2FwWBAp9Mxc+ZMZs6cqQz7mEuROzk5Ua9ePav1ZW5bfsyXqIkaChFCbBRC/CmE+Dtjy3NLCoFLCy9hSFGZqjDFwKWF6icL9Xp46injTwAC4qHnNbpVrMiYmjXvw9q859ChQ4SFhTFjxgzFCTg6OjJr1iwli1VJZoqnJ64qJ+pddDqmWHlDVEtmGep58+Zx+PDhLA/8cuXK4eXlpYzTSymVjGQJCQnUqmXMh/3FF1/YbUPLli35/fffOWPqot6+fVtJYJMTrVu3Zo0pfd6qVato27at3dfOiSZNmnDt2jWio6MB4wPe2sOue/fufP7558q8xtWrV/n3339VX6d79+4sWrRIcViHDh2yeY6TkxNpaWmA8f5XrFgRNzc3Tpw4wR9//JHjuQ0bNiQkJISXX35ZmYBPTU1Vrm+vFHl+ouZbsApYCfQDepltxZ64bXHqp70NpvIq+fBDOHDAtONkgCknKe/kwPImTfI1Fl1Ky3SRnTp1UtJFRkVFIaUkNTWVl156idDQUIsHUXBwMAcOHGDu3LmlQsY4zMODXlWq2HQGrjod4VWqEJrLtR7mMtQ5sWrVKpYvX05gYCB+fn7KJOLs2bMZMGAAwcHBVLmPhEVVq1Zl5cqVPPbYYwQEBNCqVStlIjonFi1axIoVKwgICOCrr77igw8+sPvaOeHs7MzatWuZNGkSgYGBdO3a1eqbcbdu3RgyZAitWrXC39+fYcOGkWhHSO+sWbNIS0sjICAAPz8/Zs2aZfOcMWPGEBAQwNChQ+nRowfp6en4+Pgwffp0WrZsafP8ZcuWERcXpziFrl278rZpmOB+pMjzC2GrOyeE2COlzNsBqVwQEhIiDyhPWPvImIFHSoiKIrJlMvfmAVSggw76DjaLnT8PTZuCkqdl1Dl4/CJfeXvzeD7m5c0uXSQYu5Surq60bNmSixcvcvr0aeUzFxcX5s6dy/PPP49jMcmBkBMZf+fjx4/j4+OTY9mMlcVbb9wgxWxlMRjfklxMTqCoryzOGCYpTWhtzh5r//tCiINSyhBr5dV8618VQiwDMmsNbVRxbtEjLQ2GD4ctW9CxAQMuqk/Vudp+EEgJY8eaOYH6STDoEn2rVGFoprj7vERKy3SRmTEYDNy+fZtdu3ZZHG/Xrh3Lli2jUaNG+WZbUcZJp+MbHx+ic9IaKqd+XkhDoziixhE8AXhjVCDNeGGSgE1HIIToAXwAOADLpJRvZfp8MvAUkA7EAk9KKfNvoExKxQmQnExl9hFLO5N5NtBB5Z62owO+/hp27jTtCAlTT1LVzZFPGjfO1yEhe9JFgnHMeuHChYwZM0Z13t6SihCCsHLlWGfnRLCGRklBjSMIlVLanQDVlOR+CdAVuAxECyG2SCljzIodAkKklMlCiHHA24D1GLY8wOP4cdi6VXld9+S+gihpAAAgAElEQVRb4mipaAjlhM5Fh+eUnCcLY2Ph+efNDjx6BXwS+aSxH9WcnXNjuk3sSRcJ0KlTJ8aOHZuPFmloaBQX1LwK7hVC+N5H3WHAGSnlOSnlXWAN0Nu8gJQywhSeCvAHUPs+rqMaz3XrwOxh6cFxqrAXHdmHgIFxSKhKeBU8QnMem3v+eYjLmE+ungqjzvN49eo8WtV+SQp72bZtm8WcgC0iIiLy0ZrihZSwfz8MGGCZbnrgQIiKMsspraFRQlHTI2iJMR/BeYxzBAKQUsoAG+fVAszjLS8DLXIoPwr4wdoHQogxwBiA6tWrE2nHsn5zHvzjD2N6sIx6AW/e5AQvEUtbJJnf2vVQxgFDKwP/jvqXf3/NPlRt//5KrFpldkueP0UVVz0Dr18nUsVCm9xib/rH5OTk+76PRZ2kpCQiIyMpX768zaiStDR4+mkXtm93JDUVDAbj8F1yMmzYINm2DR5+OJ1PP02lCOnlZUGv19sVQVMS0NqcPampqXZ9v9U4gh6qa7tPhBCPAyFAe2ufSymXAkvBGDXUwcriIDVIJTfkPXTo8eF10nmdm7TJKImOVCrzB56/TaFcaM6ThUlJMHKk2YEu16HFTb4OCKC7aVVkfuPq6qp6fgBQFsSURMyjhnKKsJAShgyB7dvNJvfNMBgEycmwbZsTEyY48c03UIQWg1ugRdCUDtS22cXFRVmBrQabQ0OmyVtPoJPp92Q15wFXTOdlUNt0zAIhRBeMq5bDZT7nRTZkM04vgFRqKftBPEs7HsbPfaFNJwAwaxYoa0HKpcGEMzxds2aBOYHz58/bJfWrpYs0EhVlMWWULSkpxnKm9U52kSFD7efnR2BgIAsXLrRrCC8zHTp0ICN8+uGHHyY+Pp74+HhV0sbmXLhwAVdXV4KCgvD19WX48OHKwqnMjBw50qagnEbxRs3K4leBF4GXTIecgK9V1B0NNBJCeAkhnIHBZMp0JoRoBnyK0QmoXyJ4n8S1bGkcAM5EGh4kU89oE+l4cNJYTsXDcv9++OADs0HkCWfwquHAggYN8srsbNHr9Xz44Yc0bdrUrhWWRTFdZGGwcKHFlFGOpKQYy9tLhsTEsWPH+Omnn/jhhx+YM2eO/RVZYfv27VSoUIH4+HiWWcjbqqNBgwYcPnyYI0eOcPnyZdatW5cndmVHSZXILgmoebPvC4QDtwGklFcBm30TKWU6MBGjSN1xYJ2U8pgQYq4QItxU7B2gLPCtEOJwfie8uTRwIFjR+LnFvYUXZTmNA3fBxQVsPCzT0mD0aJDSNF4QchO6Xmeltzdl83lh1vHjx2nbti3PPvusxZCQrQVhRTFdZEEgRNbt228tpoxyxGCAdeus16OWatWqsXTpUhYvXoyUkpUrVzJx4kTl80ceeUQZ1x03bhwhISH4+fnx6quvWq0vIxnK9OnTOX/+PEFBQUybNo3hw4ezadMmpdzQoUMtJI4z4+DgQFhYmCqJ7IMHD9K+fXuCg4Pp3r07165dA+Czzz4jNDSUwMBA+vXrp/xPjhw5krFjx9KiRQteeOEFZs+ezZNPPkmHDh2oX78+H374oVL3119/TVhYGEFBQTz99NPKQ79s2bJMmTKFwMBA9u3bZ9NGDftR4wjumiRMJYAQQrUylZRyu5SysZSygZRynunYK1LKLabfu0gpq0spg0xbeM415o5EHx/o1SuLM7jFvfjxcsQYPw8PBxsPy3fegSNHTDsueph8ismetWlXoUJem66QlpbGvHnzCAoKsvhS+Pn5sWfPHvr3769kBzNHp9Ph5uZG7969i1S6yNJG/fr10ev1Nntw8+bN48CBA/z999/8+uuv/P139vJeb731Fl5eXhw+fJh33nmHUaNGsXLlSsCoZ7N3794chwJTU1PZv38/PXrkPB2YlpbGpEmTWL9+PQcPHuTJJ59k5kyjFuWjjz5KdHQ0f/31lyJYmMHly5fZu3cv7777LgAnTpxgx44dREVFMWfOHNLS0jh+/Dhr167l999/5/Dhwzg4OLBq1SrAqInUokUL/vrrrzxX3dQwoua1dZ0Q4lOgghBiNPAkYN+AZFFBCPjyS+Oisg0bjK/0QIKZIyjvfBp69zaWy+FhefIkzJ0rUSQqnjiPTwMd88ykgfOajC+f+UPBycmJGTNmMGPGDJydnWndujXR0dEsWLCA7du3k5ycjJubGz179mTq1KmlridQXFm3bh1Lly4lPT2da9euERMTQ0CArUA9I+3bt2f8+PHExsayYcMG+vXrZ7WnePbsWYKCgjh//jw9e/a0Wf/Jkyc5evSoIqWt1+upaRJQPHr0KC+//DLx8fEkJSXRvXt35bwBAwbg4HBv0WbPnj0pU6YMZcqUoVq1aly/fp1du3Zx8OBB5f8zJSWFatWqAcYeS79+/VS1XeP+UCNDvUAI0RW4BTQBXpFS/pTvluUXTk7wzTfQowfs3IlER6LZ0FC59XOgV05RrsZhgjFj4M4dkxNocgtdvyt86d0MFwcVq5TtJCUlRclpaz7RGBoayvLlyxUddrBMFwlm+kqlHGtrAQYONL4PqBke0umgf39YuzZ3dpw7dw4HBweqVauGo6Ojxd8zQ2jt/PnzLFiwgOjoaCpWrMjIkSNzlDu2xvDhw/n6669Zs2YNK1assFomY47gxo0btGnThi1bthAeHs4TTzzBoUOHeOCBB9i+fbtSXkqJn5+f1eGZkSNHsmnTJgIDA1m5cqVF6KJaiewRI0bw5ptvZqnbxcXFwpFo5D05Dg0JIRyEEBFSyp+klNOklFOLtRPIQAgwJRG/jRd63ABwruVMmUfCbJ6+bBns3m3a0RllJF6uX4eQfNCk2b17N4GBgbz99tvKQ8PV1ZWFCxeyb98+CyegYR9TplidMrKKiikjm8TGxjJ27FgmTpyIEIJ69epx+PBhDAYDly5dUlIq3rp1C3d3d8qXL8/169f54Qery2sUPDw8FGnmDEaOHMn7778PGHXxc6JKlSq89dZbykN4xYoVHD582MIJgFEuOjY2VnEEaWlpHDt2DDCGNdasWZO0tDRlSMceOnfuzPr165Uhs5s3bxaqLHNpI0dHIKXUAwYhRPkCsqfgMKlvWgwLtSpvc+z86lV44QWz18vBF2kWJJhZt26emnfr1i3Gjx9P+/btLZRCO3bsyJEjR5g8ebL2lpRLwsKsThllQeWUkVUyMpT5+fnRpUsXunXrpkz+tmnTBi8vL3x9fXnmmWdo3rw5AIGBgTRr1gxvb2+GDBmiZBTLjsqVK9OiRQuaNm3KtGnTAOPCSx8fH5544glVdvbp04fk5GR+++23bMs4Ozuzfv16XnzxRQIDAwkKClKSrL/22mu0aNGCNm3a3Jecsq+vL6+//jrdunUjICCArl27KhPRGgVAdjksMzZgM3ARY+7iDzM2W+fl15YnOYvj4pQkwjEOLyt5iS++e9FmHY8+apZ/uNZt6bRjtzySmHjfNllj27Zt0tPT0yJvcLly5eTSpUuVnKZqsSdncUnBWs7i7Lh7V8rBg6V0d5dSpzP722Lcd3Mzfn73bj4bnUtu3bplsX/79m1Zv359GR8fX0gW5T+Z21waUNtme3MWq4ka2gjMAnYDB8224ouSRBgSHO5NkJVrlfPQznffwUZzzdUpp3jduy5N7VjMlRM3btxg2LBh9OzZk0uX7qlz9OrVi5iYGEaPHq1F++QxGVNGv/wC/fpZag317w+RkbB6NUVaXiIzP//8Mz4+PkyaNEnJw6uhkRNqoobWA6nSOEyUoSpavNNXmRzBXSqQetcoCCfKCDyaZb88Ij4eJkwwixLqeZVW7Q25Sl+YgZSSdevWMWnSJGJjY5XjVapUYdGiRQwaNEhzAPmIEMZhonxeT1VgdOnSRRtf17ALNT2CXWCh0+wK/Jw/5hQQJkdgvn7AI9gDXZnsb8f06XDtmulhXPEuruMu8IW3Nw65fEBfvXqVPn36MHjwYAsnMHToUI4fP87gwYM1J6ChoZGvqHEELlJKJSTB9Ltb/plUAJgcgcVEcevsu9C7d8Onn5odePY07wTVpZFb9rdBZsodrNPpLHIHGwwGli1bhq+vL1u23FtQXbt2bb7//nu+/vrr+8pLq3EfaDrUGqUcNUNDt4UQzaWUfwIIIYIB+zSPixqmKJxb3AurK9fa+vxAaio8NdpsSKjNDTqFpzHugQeyrT673MHJycls2LCB77//Hg8PjyyrS8eOHcv8+fMpp6VGLDjMUpeadKiNx4061EZp0l69jAsMi9NEgYaGHahxBM9h1AK6ivFpWIN8zCJWIJw5gwFHErkX5pbdRPG8eXD6lMkJuKVTdvJZVvgEostmuEaqyB2ckpJikT+gYcOGLFu2jPbtrapwa+QXmVKXZsFggNu3YfNmY7mirEOtoZEL1MhQR2PMWTwOGAv4SCmLb9RQfDzcuEESDTCY5rxdvFwoUyPr/PeRI/DmW2bDAmPOsahVHeq4ZJ/w3t7cwY8//jh//fWX5gQKg3zWoY6LiyMoKIigoCBq1KhBrVq1lP27VnJjqEVKyZw5c2jYsCGNGzemY8eOxMTE2D7RTm7evMknn3yi7F+6dIlBg4zvgD///DN9+vRRXdeZM2cU2WsfHx9GjhyZKzXS2rVrE29aFJqBXq+nbdu2912nGs6dO8eaNWtyLJOQkEDNmjV57rnnlGPR0dE0bdqUhg0b8rxFPtt7SCkZP348DRs2JCAggMOHDwNGgcng4GACAwMVCfK0tDQ6d+5sd0Kq7FCbtTwUCACaA48JIYbnydULg7NnAbhFU+WQtd6AXg9PjJLo001vgE0TeGTkHUbUqJFj9fbkDhZCcPfuXdxymGvQyEfyWYe6cuXKHD58mMOHDzN27Fief/55Zd85FzmsP/jgA6Kjozly5AinTp3ihRdeYNCgQXn2UMggsyPw9PRkbS40Npo0aaLIXp8/f54NGzbkhZkKDg4OOS6IywvUOIIZM2bQsWNHi2Njx45lxYoVnD59WpEkz8zWrVu5dOkSZ86c4aOPPmLChAkAfPzxxyxZsoTNmzezePFiABYvXswTTzyBq9ql8TZQk4/gK2AB8CBGhxCKMZtY8USZKL43P2BtonjxYjgYbXICTgbKv3iGz7wb24zgsSd3sJSSbdu2qTRcI1cUBR1qM95++22aNm1K06ZNWbRoEWB8a/bz82Pw4MH4+PgwcOBAqw/3+fPns2TJEuUh8NBDDxESEsLq1atJT0+ngpn67Zo1a3jqqacA2Lx5My1atKBZs2Z069ZNmaN6+eWXGTVqFO3bt6d+/fosWbIEgOnTp3Py5EmCgoKYPn06Z86cISgoKIs9SUlJjBw5krCwMJo1a8bWrVtzbLujoyOhoaGK7PXZs2dp27YtzZo1Izg4mP379wPGXkfnzp159NFHadKkCcOHZ33/TE5Oplu3bnz++ecWbc/p3C1bttCkSROCg4OZNGmS1Z5NdjZNnz6diIgIgoKCLCS0M4iKiiI+Pp5OnTopxy5dukRqaiqhoaEIIRg2bJiFTHgGmzdvVux88MEH+d///kdsbCxOTk4kJyeTnJyMo6MjN2/e5Mcff2To0KE53md7UDNHEAL4mlamFX+shI5m7hH88w9Mn2E2QTz0Hz7r5kmNMraXT9j7VpbXb3EaRZ/9+/ezatUqoqOjSU9PJywsjA4dOuDq6kpMTAzLly+nZcuWDB8+nE8//dRiiOHmzZukp6dTN5OkSfPmzW0OD7Vr147w8HCEEHzyyScsXLiQ+fPnA3Dq1Cl27dpFfHw8Pj4+jB07lrfeeoszZ84oQxRnzBZimjN37lx69OjBypUr+e+//2jRogVdu3bFJZsh1JSUFKKjo/noo48AqFmzJj/99BMuLi6cOHGCESNGKA/eP//8k2PHjlG9enVatmzJH3/8QcuWLQGjAxoxYgRPPfUUQ4YMyTLUZO3cgIAAxo8fz++//06dOnUYOHCgVRuzs+mtt95i8eLFVh/ker2eqVOnsmbNGgudpitXruBptt6odu3aVnM/ZFdu0qRJjBgxgrS0NN577z3mzJnDrFmz8jSsXM3Q0FGME8Qlg9OnSaUKd6gOgM5Nh3vAPXVEKeGpsQZSk003ud5tBj6bwgCTJK4t7O3y51XXTqP4sGfPHvr164erqyseHh706dNHGdLw8vJSHnSPP/44e/bsybPrXrx4kW7duuHv78+7776rCMaBMSmOs7Mz1apVo1KlShZrWmyxc+dOJUdGx44dSU1N5eLFi1nKZfQuqlevTt26dfHzM76M3blzh1GjRtG0aVMGDx5s4dBatmzJAw88oKT8vHDhgvLZwIEDefrppxkyZIhVu6ydGxMTQ5MmTahbty5CCB577DGr5+ZkU3YsWrSIPn368EAOEYX3Q7169fj111/Zu3cvTk5OxMbG0qBBAx5//HEGDRqUrYO2BzWOoAoQI4TYIYTYkrHl+sqFxZkzlr2BsHLoHO/dhtWr4ecfTftCUumls3zs18hmtQkJCTz99NPcuaM+7bKWO7gAsZQRMm4DBlhNXWoVnc64rsBaPXlI5re8zPuVKlXC0dExy4P20KFDhISEoNPpMO+8m8tXT5gwgeeff54jR47w0UcfWXxmTRpaLVJKNm3apMx/XLx4kcaNG2cplzFHcPbsWfbu3au8NS9cuBBPT0+OHDlCVFSUxXcoJ7tatGjBDz/8QHaDFblpU042Zccff/zB+++/T7169Zg+fTqff/45M2fOpFatWhaSMZcvX6ZWrVpZzldTbu7cubz++uu8//77jBs3jjfeeIPXXntNdbuyQ823YDbQB3gDWGi2FU8yOwKz9QM3bsDYZ8zGjPtc4at+tahkI378+++/x8/Pj6VLl9plipY7uJApaB1qE23btuW7774jJSWFpKQkNm/erES7nD9/nmhTdNI333xjNSPXtGnTmDRpkvIg37FjB2fPnqVv377odDoqVqzI6dOnMRgMfPfdd8p5CQkJ1KpVCyklX3zxhU07PTw8SExMtFmue/fuyjwHGJ1STlStWpU333xTkb3OiLIRQvDFF19k+2DPzKuvvoqbmxvPPPOMqvJgVDk9efIkly5dQkqZ7eR3djbldE/WrFnDxYsXuXDhAm+99RZPPvkk8+bNw9PTkzJlyhAdHY2Ukq+++orevXtnOT88PJwvv/wSMPYaq1evTtWqVZXPd+3aRd26dalfvz7JycnodDp0Op3qCMWcUBM++qu1LddXLgQckpPh+nWLFcXm8wPjn9OTGGe6JVVTGT4zmYcrV862vtjYWIYMGUKvXr0sxvxq1aqV7fhoBqU1d3CRoiB0qK1eNozHHnuM0NBQWrZsybhx45S8Ej4+Prz77rv4+PiQnJzMmDFjspz/3HPPERQURNOmTalXrx6jRo1i06ZNyhvw/Pnz6d69O61bt6Z27drKebNnz6Zv376EhoZSvXp1m3ZWr16d4OBg/P39mT59erblXn31VW7fvo2/vz9+fn7Mnj3bZt39+/fn5s2b/PHHH0ycOJFly5YRGBjI+fPnLd7kbbFkyRLi4+OZMWOGqvJubm4sXryYLl26EBISQoUKFawK82VnU7NmzdDr9QQGBlqdLM6Ojz/+mJEjR9KwYUN8fHzo1q2bYv+yZcsAo7hkrVq1aNCgAePGjVMm7cG4/uiNN95g6tSpgDEKafz48fTu3ZvJkyertiNbspMlBRIxZiXLvCUCt7I7L7+33MhQR3/2mUzHSUayU5GevhN7R0op5Y8/Giz6+1XfiZEJaWlW6zEYDHLVqlWycuXKFlLR1apVk+vWrZN37tyRgwcPlu7u7lKn01mU0el00s3NTQ4ePFjeLQBtY02G2gZFSIf69OnTMjAw0K5zbt26JTt27ChfeOGFfLKq6HK/MtSJJtl4g8EgR48eLT/88MO8NCtfKXAZaimlh5SynJXNQ0pZLDUQXK9cIYkmSIxDPa6NXXGu4szt2/D4aP29gp2us3ZUDcpZyfN6+fJlwsPDGTp0KHFxccrx4cOHExMTw4ABA3B2duabb77hl19+oV+/fhZaQ/379ycyMpLVq1fjpEkWFD7FXIfaw8ODX375hZdffrmwTSk2fPzxxwQFBeHr60tKSgqjR48ubJMKHTXhoyUG1ytXrArNPTczjRuXTF90jzSeev02HStadp0NBgOfffYZ06ZNsxgj9PT05NNPP+Whhx6yKJ85d7BGEaaI6FA3bNhQCdXUyD+mTZumZHLTMKJ2ZXGJwPXyZUuhuVbliIqWLFt0zx9Wf/YiH4RZxmifOXOGzp07M3bsWAsnMGHCBI4dO5bFCWhoaGgUJ0pVj8Dl8hUSzKQl3ELL8ejjaWAwxf43/49NU6viZsoFnJ6ezvvvv8+sWbMsQu0aN27MsmXL8l3XRKNgkFKSGJXIpQWXiNsehyHFgM5VR+WelfGc6olHqIeWE0KjRFOqHIHucjppVALAoazg9S1OXIkxOYEyesYtSKRl+ToAHDlyhFGjRimhfGCMRZ42bRqvvvqqzaggjeKBIc3AieEnuLHlBoZUA5iihw3JBmI3xBK3PY4qvarg/aU3OqdS1YHWKEWUnv/s27dJ/e/eij+HgPK8++a9CcAaY67yXvva3Llzh1dffZXmzZtbOIGgoCCioqJ48803NSdQQpBS3nMCyfecgIIBDLcN3Nh8gxPDT6iOb9fQKG6UHkdw7pzFRPG3F8si75ia3yiR7+dW5FBUFM2bN2fu3LnKKkRnZ2fmzZtHlOkzjZJDYlQiN7aanEAOGFIM3Nh6g8Ro24urMpMhb+Dn50dgYCALFy5URAkPHDhg12KonFi1ahVXr161+tnIkSPx8vIiKCiIwMBAdu3add/XWblyJRMnTsxy/JNPPlEWQ+WWDh06UKdOHQvH26dPH8qWLWtXPSNHjmT9+vW5LlMaKD1DQ2fOWEwU77lsHCJCJxnz9n+smvs+77//vsU/X+vWrVm+fDne3t6Za9MoAVxaeAlDijr1UUOKgUsLL+G31s92YTNcXV2VSKB///2XIUOGcOvWLebMmUNISAghIVmFfNPT03G0ErqcE6tWrSIkJCRbnZt33nmH/v37ExERwZgxYzhtytKXV4wdOzZP66tQoQK///47Dz74IPHx8Vy7di1P69ewpET3CNLT0lkxYh07nD9h96OuJJGhGSRpyEnAQKUBl9g5tRPvvfee4gTc3d1ZtGgRv/32m+YESgiRIjLLFvttbNbhoOwwQOy6WKv1qKVatWosXbqUxYsXI6UkMjKSRx55BDCu+h02bBht2rRh2LBh6PV6pk2bRmhoKAEBAXxqljR7/vz5+Pv7ExgYyPTp01m/fj2HDh1i6NChBAUF5aho26pVK4tV8HPnziU0NJSmTZsyZswY5TvQoUMHXnzxRcLCwmjcuLFVnf9t27bRqlUrbty4wezZs1mwYEGO5yYnJzNw4EB8fX3p27cvLVq0UBKtZGbw4MGK7v/GjRt59NFHlc+klEybNo0WLVrg7++vyERIKZk4cSJNmjShS5cuFqlgDx48SPv27QkODqZ79+6aY8lEie0RxP97i32eq2hw1wsDlTHgYPH5OBIYxnIe3bOIm1fOKse7devGp59+Sr169QrYYo3SQP369dHr9VnyVQPExMSwZ88eXF1dWbp0KeXLlyc6Opo7d+7Qpk0bunXrxokTJ9i8eTP79+/Hzc2NmzdvUqlSJT744APee+89qz0Mc3788UcL/f2JEyfyyiuvADBs2DC+//57evXqBRh7JlFRUWzfvp05c+bw888/K+d99913vPvuu2zfvp2KFStmuY61cz/66CMqVqxITEwMR48etZrbIIPOnTszevRo9Ho9a9asYenSpYq42saNGzl8+DB79+7lzp07hIaG0q5dO/bt28fJkyeJiYnh+vXr+Pr68uSTT5KWlsakSZPYvHkzVatWZe3atcycOZPPP/88x3tVmiiRjiA9LZ19nqtwu+uFAWsTuwIDLrjjycbrY+nJBCpWrMh7773H8OHDtVBBjUIhPDxckSXfuXMnf//9tzJ+nZCQwOnTp/n555954oknlKx2lSpVUlX3tGnTmDFjBpcvX2bfvn3K8YiICN5++22Sk5O5efMmfn5+iiPIeAsPDg62kH/+5ZdfOHDgADt37qRcOesiA9bO3bNnD88++ywATZs2JSAgIFt7HRwcePDBB1mzZg0pKSkWL2Z79uzhsccew8HBgerVq9O+fXuio6PZvXu3cvyBBx5QksOcPHmSo0eP0rVrV8CYN6BmzZqq7ltpIV8dgRCiB/AB4AAsk1K+lenzMsCXQDAQBwySUl7I7XW/emqjqSeQc3SPxIWy6fWZ4DeNl3+eTA0baSg1ii8dZIcsx44NPEbsBpXDQzqo2r+q3XMEmTl37hwODg5Uq1aN48ePW3zm7m6eF0OyaNEiunfvblFmx44d93XdjDmCRYsW8eSTT3Lw4EFSU1MZP348Bw4cwNPTk9mzZ1uVps4s4dygQQPOnTvHqVOnsu2BZHeuPQwePJi+ffuqErHLCSklfn5+Fg5Qw5J8myMQQjgAS4CHAF+MuY59MxUbBfwnpWwIvAfMz4trP7D6JgbUacMYcOKRU16aEyiFeE7xROeq7iugc9HhOcXTdsEciI2NZezYsUycONFmr7N79+58/PHHpKWlAcYMYrdv36Zr166sWLFCkR6+efMmAGXLllUlGT1x4kQMBgM7duxQHvpVqlQhKSlJdfRM3bp12bBhA8OHD7dIbmOLNm3aKJIrMTExHDlyJMfybdu25aWXXsqSPKZt27asXbsWvV5PbGwsu3fvJiwsjHbt2inHr127RkREBGDMgxAbG6s4grS0NLvsLg3kZ48gDDgjpTwHIIRYA/QGzFP99MaY7wBgPbBYCCFkLgO2XdPqZZkTyB4H3NK8cnM5jWKKR5gHVXpV4cbmGzlGD+lcdVQJr4JHqIfd10hJSSEoKIi0tDQcHR0ZNr/TsUMAAA0dSURBVGyYKtngp556igsXLtC8eXOklFStWpVNmzbRo0cPDh8+TEhICM7Ozjz88MO88cYbDB06lLFjx+Lq6sq+ffuyzXwnhODll1/m7bffZteuXYwePZqmTZtSo0YNuyTRvb29WbVqFQMGDLCZoziD8ePHM2LECHx9ffH29sbPz8+qBLS5rRmyy+b07duXffv20bp1axwcHHj77bepUaMGffv25ZdffsHX15c6derQqlUrwBgCvn79ep555hkSEhJIT0/nueeeUzKkaYDIr0UyQoj+QA8p5VOm/WFACynlRLMyR01lLpv2z5rK3MhU1xhgDED16tWDM6IJsqWjAfs6OwaIKJkBVElJSXbHXxd3Mtpcvnx5GjZsmGNZmSY5//R5ErYnWKwsBkBn7AmUf7g8Xp96IZyK7tyRXq/HwUHty0/hoNfrSUtLw8XFhXPnztG7d28OHjxod3pX8/qKepvzGrVtPnPmDAkJCRbHOnbseFBKaXUsr1hMFksplwJLAUJCQmSHDh1yLL+bH23OD5ij4y7tOvTIjYlFlsjISGzdr5JGRpuPHz+Oh4ftt/iAdQEkRmevNVQutOirricmJqpqa2GSmJhIly5dSEtLQ0rJxx9/TOUcEj+pqa+otzmvUdtmFxcXmjVrprre/HQEVwDzQdXapmPWylwWQjgC5TFOGueKFKcLlElrBKqGh/QkO53P7SU1ijFCCMqFlcNvnTZUkJ94eHhku25Ao3DJz/GQaKCREMJLCOEMDAYyJ73fAoww/d4f+CW38wMAVx+rhI40VWV1pPG/oVVye0mNIoqmD6RR2rif//l8cwRSynRgIrADOA6sk1IeE0LMFUKEm4otByoLIc4Ak4HsE6PawbBlj3Lb+TyC1BzLCVK57Xyex5f2zYvLahQxXFxciIuL05yBRqlBSklcXJzdwpj5OkcgpdwObM907BWz31OBAXl9XUcnR1pdGso+z1W43/UyhZKaDxPp0ZHGbefztLo0FEenYjFVomEntWvX5vLly8TGxha2KflOampqqVPF1dpsHRcXF2rXrm1XvSX2CVihWjm6Jo3m6zHfUXNVnCmk1Bkdd0l2Os/1YVUZsXxcYZupkY84OTnh5VU6QoMjIyPtmhwsCWhtzjtKrCMAY89g5IoBsMK4HxkZWWKjgzQ0NDTul5IZPK+hoaGhoRrNEWhoaGiUcvJtZXF+IYSIBf65z9OrADdslipZaG0uHWhtLh3kps11pZRVrX1Q7BxBbhBCHMhuiXVJRWtz6UBrc+kgv9qsDQ1paGholHI0R6ChoaFRyiltjmBpYRtQCGhtLh1obS4d5EubS9UcgYaGhoZGVkpbj0BDQ0NDIxOaI9DQ0NAo5ZRIRyCE6CGEOCmEOCOEyKJoKoQoI4RYa/p8vxCiXsFbmbeoaPNkIUSMEOJvIcQuIUTdwrAzL7HVZrNy/YQQUghR7EMN1bRZCDHQ9Lc+JoT4pqBtzGtU/G/XEUJECCEOmf6/Hy4MO/MKIcTnQoh/TRkcrX0uhBAfmu7H30KI5rm+qJSyRG0YZUbPAvUBZ+AvwDdTmfHAJ6bfBwNrC9vuAmhzR8DN9Pu40tBmUzkPYDfwBxBS2HYXwN+5EXAIqGjar1bYdhdAm5cC40y/+wIXCtvuXLa5HdAcOJrN5w8DPwACaAnsz+01S2KPIAw4I6U8J6W8C6wBemcq0xv4wvT7eqCzEKLoJqS1jc02SykjpJTJpt0/MGaMK86o+TsDvAbMBxvJKYoHato8GlgipfwPQEr5bwHbmNeoabMEMvKJlgeuFqB9eY6UcjdwM4civYEvpZE/gApCiJq5uWZJdAS1gEtm+5dNx6yWkcYEOgnA/SdPLXzUtNmcURjfKIozNtts6jJ7Sim3FaRh+Yiav3NjoLEQ4nchxB9CiOIut6umzbOBx4UQlzHmP5lUMKYVGvZ+321SomWoNbIihHgcCAHaF7Yt+YkQQge8C4wsZFMKGkeMw0MdMPb6dgsh/KWU8YVqVf7yGLBSSrlQCNEK+EoI0VRKaShsw4oLJbFHcAXwNNuvbTpmtYwQwhFjdzKuQKzLH9S0GSFEF2AmEC6lvFNAtuUXttrsATQFIoUQFzCOpW4p5hPGav7Ol4EtUso0KeV54BRGx1BcUdPmUcA6ACnlPsAFozhbSUXV990eSqIjiAYaCSG8hBDOGCeDt2QqswUYYfq9P/CLNM3CFFNstlkI0Qz4FKMTKO7jxmCjzVLKBCllFSllPSllPYzzIuFSygOFY26eoOZ/exPG3gBCiCoYh4rOFaSReYyaNl8EOgMIIXwwOoKSnJ90CzDcFD3UEkiQUl7LTYUlbmhISpkuhJgI7MAYcfC5lPKYEGIucEBKuQVYjrH7eAbjpMzgwrM496hs8ztAWeBb07z4RSlleKEZnUtUtrlEobLNO4BuQogYQA9Mk1IW296uyjZPAT4TQjyPceJ4ZHF+sRNCrMbozKuY5j1eBZwApJSfYJwHeRg4AyQDT+T6msX4fmloaGho5AElcWhIQ0NDQ8MONEegoaGhUcrRHIGGhoZGKUdzBBoaGhqlHM0RaGhoaJRyNEegoSCESCpsG+4XIcQMleUumOLr8/r69YQQQ7L5rIkQ4qBJKbKV6ZijEOJnIYSbndfxFkIcNiltNsgL221cL0QI8WF+X0ejcNEcgUaeYlqpXRiocgT5SD3AqiMAngaexRj7PdV0bBzwtZkQoFr68P/2zi3EyiqK47+/Jox3026SldIFXzIltJvmFGYFpZkPIlmJD5GQolEvYaRJZkYlGFFRkpX0kKnURGppY2oOY5nOZKbSeEGKLiCaGTk6q4e9jvN5muOc0fFCZ/3gY/bZs9dee+/vnG/tb3/n/DcsMrMBZvbTyTS0JZjZN2Y2+XT7Cc4uEQiC/yCpXFKlpEWSfpS0MKfOKmmgpK8lbZZULamzpPGSPpa0Cljp5Z6UtMFnwTM8r7fX946k7V7vMBdI2yFpkJfr6Jrs1T7zHen54yUtlrTMy8/x/NlAe58pL/S8pT4L3yLpkSL6fJekjd6vXB+6ez01LuDWz/OHuq/czLwzMBsY4nlT86qvBzr4US+pG3Av8O4J2tPffdZIWiLpfCWd/SnARElfNmFzUNKL3ucvJA3y81gnaUTmHKzxvm6UdLPnj1Lap0KSevr5ucTfCxVeZrqkBW6/W9L9kuZIqvVz0s7LHbvr8juKypbYB2eBs629Hce5cwAH/W85SZG1F2mysB4YTNKDrwMGerkupF+njydp3HT3/OEkjXi5fQVJY703cAS41vO/BeZ7uZHAUrefBYzzdDeSXk5H91NH0oYqA3aT1EWPtT3Tl1xb2gPfAz389S7ggryyF5LUHPvk2c4DnvH07cAmT38C3OLpTj4G5UBFgXG9HKj0cewHvASUN3MuaoChnn4WmOvp6cATBWwMuNvTS4AVpF+kXpdpewegzNNXk36dm7N/H3jMz9fYzHuhIuN7babOQ3n+7ssfY5LAYWVL7OM488f/TmIiaDWqzWwvgKRNpIv4fuAXM9sAYGYH/P8An5tZTkN9uB/f+etOpIvOHmCnmdW63RZgpZmZpFr3kbMfISm3jFJGupji5fe7/Q/AFRwvyZtjsqRRnr7M/ReSWrgR+MqSSBuZfgwGRnveKkk9JHUB1gEv+93HYjPbqxNsZ2Fme2jU/7mKFGC3SnqPFFyfNrPtufKSugLdzGy1Zy0APizooJHDwDJP1wL/mFl93ti2A16V1J8kQXFNxn4SKWhWmdkHBXx8lqmzbZ6/3gVsWtM+OA1EIAgKkVUnPUrz75W/MmkBz5vZG9kCSluCZuttyLxuyPgQMNrMtuXZ31BMuySVA8OAm8zskC9NlDXT/qIxs9mSPiWt+a+TdGcLzJ8DpgGTgbdIs+dZwAOt0LR68+k1mbE1swY1PruZCvxKmpG34fgNe3q53cWS2ljTMs7ZOvP95XwcoXHZOX/ci7EPzjDxjCBoCduAnpIGAig9H2jqw7scmCCpk5e7VNJFLfCzHJgkHXsuMaAIm/rMGnNXYJ8Hgb6kGf+JqAJuldTH/XX3/DX4BdqDyx9mdkDSlWZWa2YvkNQx+wJ/kqSvCyJpKPCzme0gLdE0+HHcN4f8jmefpCGe9SCwmtahK+mursHrbettO4+0TDcW2Ao8fgo+dgHXe3r0KdQTnCEiAgdFY2aHJY0B5klqD/xNmnnnl1uhJAe83q/lB4FxpBl8McwE5gI1ShvM7ATuacbmTS+/EZgAPCppKyl4VTXTr9/9gfJi9/cbcAdpTXu+pBrSenZOunyKpNtIF/EtpN3eGoCjkjaTNkl5JevDg9o0YEymvQtJn8GJTTTrYeB1pa+X1tEKCpPOa8BHkh4iLcvk7uSeAtaY2Vrvwwa/6zkZZgBvS5pJejYSnOOE+mgQBEGJE0tDQRAEJU4EgiAIghInAkEQBEGJE4EgCIKgxIlAEARBUOJEIAiCIChxIhAEQRCUOP8C7grteeOqeNAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### code implements ranking model for treatment effect \n",
    "### for optimizing with respect to direct marketplace objectives \n",
    "### using tensorflow \n",
    "\n",
    "import numpy as np, tensorflow as tf, pandas as pd, pickle as pkl \n",
    "sys.path.append('../')  \n",
    "from ModelDefinitions import * \n",
    "from DataProcFunctions import * \n",
    "\n",
    "### RxGy TQR setting: \n",
    "p_quantile = 0.4 ## percentage of quantile to aim for \n",
    "num_optimize_iterations = 2000 ## number of optimization iterations \n",
    "num_modeling_inits = 2 ## number of random initializations \n",
    "num_hidden = 0 ## number of hidden units in DNN \n",
    "use_schedule = True ## option to use a constraint annealing schedule \n",
    "temp = 0.5 ## initial temperature for constraints \n",
    "inc_temp = 0.1 ## increment of temperature per 100 iterations \n",
    "save_cf_data = False ### whether to save data for causal forest training \n",
    "\n",
    "## set a random seed to reproduce results \n",
    "seed = 1234; tf.compat.v2.random.set_seed(seed); np.random.seed(seed) \n",
    "\n",
    "sample_frac = 1.0 ## option to sample data by a fraction \\in (0, 1) \n",
    "data_filename =  '../data/rt_ma_training_data_v5_2019_07_08_vc_tr_featuremod3_rider' \n",
    "prefix = 'rt_v5_07_08_featuremod3_tr_iter100_run4_rider' \n",
    "\n",
    "D_tre, D_unt, Dv_tre, Dv_unt, Dt_tre, Dt_unt, o_tre, o_unt, ov_tre, ov_unt, ot_tre, ot_unt, c_tre, c_unt, cv_tre, cv_unt, ct_tre, ct_unt, D, w, o, c, Dv, wv, ov, cv, Dt, wt, ot, ct = LoadDataFromPkl(data_filename, frac = sample_frac, use_python3=use_python3, save_cf_data=save_cf_data) \n",
    "\n",
    "print('### ----- start the training of deep learning models ------ ') \n",
    "gs_tqr = [] \n",
    "gs_drm = [] \n",
    "for i in range(num_modeling_inits): \n",
    "    gs_tqr.append(tf.Graph()) \n",
    "for i in range(num_modeling_inits): \n",
    "    gs_drm.append(tf.Graph()) \n",
    "\n",
    "print('------> Training TQR ranking model .... ') \n",
    "val_results = [] \n",
    "sess_list = [] \n",
    "for i in range(num_modeling_inits): \n",
    "    print('---> running cross validation, iteration: ' + str(i)) \n",
    "    obj, opt, dumh, dumhu, vtemp, p_quantile = TunableTQRankingModelDNN(gs_tqr[i], D_tre, D_unt, o_tre, o_unt, c_tre, c_unt, 'train-first', temp, p_quantile, num_hidden, use_schedule) \n",
    "    ### session definitions and variable initialization \n",
    "    sess = tf.Session(graph = gs_tqr[i]) \n",
    "    sess_list.append(sess) \n",
    "    \n",
    "    ### initialize variables and run optimization \n",
    "    with gs_tqr[i].as_default() as g: \n",
    "        init = tf.global_variables_initializer() \n",
    "    sess.run(init) \n",
    "    cur_temp = temp \n",
    "    for step in range(num_optimize_iterations): \n",
    "        _, objres = sess.run([opt, obj]) \n",
    "        if step % 100 == 0: \n",
    "            cur_temp = cur_temp + inc_temp \n",
    "            print('opt. step : ' + str(step) + ' obj: ' + str(objres)) \n",
    "            if use_schedule: \n",
    "                sess.run(vtemp.assign(cur_temp))\n",
    "                print('setting temperature to :' + str(sess.run(vtemp))) \n",
    "    \n",
    "    print('---> optimization finished ... ') \n",
    "    tempvalue = sess.run(vtemp)\n",
    "    p_quantilevalue = p_quantile\n",
    "    print('temp:') \n",
    "    print(tempvalue)\n",
    "    print('p_quantile:')\n",
    "    print(p_quantilevalue) \n",
    "    \n",
    "    ### evaluate CPIT metric on validation set \n",
    "    objv, dumo, dumh, dumhu, dvtemp, dp_quantile = TunableTQRankingModelDNN(gs_tqr[i], Dv_tre, Dv_unt, ov_tre, ov_unt, cv_tre, cv_unt, 'eval', temp, p_quantile, num_hidden, use_schedule) \n",
    "    \n",
    "    val_result = sess.run(objv) \n",
    "    print('validation CPIT:') \n",
    "    print(val_result) \n",
    "    val_results.append(val_result) \n",
    "\n",
    "from operator import itemgetter \n",
    "best_index = min(enumerate(val_results), key=itemgetter(1))[0] \n",
    "\n",
    "print('best performing model: iteration ' + str(best_index)) \n",
    "\n",
    "### run scoring on whole test set \n",
    "with gs_tqr[best_index].as_default() as g: \n",
    "    if num_hidden > 0: \n",
    "        with tf.variable_scope(\"tqrhidden\") as scope: \n",
    "            h1_test = tf.contrib.layers.fully_connected(Dt, num_hidden, activation_fn=tf.nn.tanh, reuse=tf.AUTO_REUSE, scope=scope, weights_initializer=tf.contrib.layers.xavier_initializer()) \n",
    "        with tf.variable_scope(\"tqranker\") as scope: \n",
    "            h_test = tf.contrib.layers.fully_connected(h1_test, 1, activation_fn=None, reuse=tf.AUTO_REUSE, scope=scope) \n",
    "    else: \n",
    "        with tf.variable_scope(\"tqranker\") as scope: \n",
    "            h_test = tf.contrib.layers.fully_connected(Dt, 1, activation_fn=None, reuse=tf.AUTO_REUSE, scope=scope) \n",
    "    tqrscore = sess_list[best_index].run(h_test) \n",
    "\n",
    "print('------> Training DRM ranking model .... ') \n",
    "sess_list = [] \n",
    "val_results = [] \n",
    "for i in range(num_modeling_inits): \n",
    "    print('---> running cross validation, iteration: ' + str(i)) \n",
    "    ### ---- train cpit ranking model for comparison --- \n",
    "    dobjc, doptc, ddumh, ddumu = DirectRankingModelDNN(gs_drm[i], D_tre, D_unt, o_tre, o_unt, c_tre, c_unt, 'train-first-drm', num_hidden) \n",
    "    \n",
    "    dsess = tf.Session(graph = gs_drm[i]) \n",
    "    sess_list.append(dsess) \n",
    "    \n",
    "    ### initialize variables and run optimization \n",
    "    with gs_drm[i].as_default() as g: \n",
    "        dinit = tf.global_variables_initializer() \n",
    "    dsess.run(dinit) \n",
    "    for step in range(num_optimize_iterations): \n",
    "        _, dobjres = dsess.run([doptc, dobjc]) \n",
    "        if step % 100 == 0: \n",
    "            print('opt. step : ' + str(step) + ' obj: ' + str(dobjres)) \n",
    "    \n",
    "    print('---> optimization finished ... ') \n",
    "    \n",
    "    ### evaluate CPIT metric on validation set \n",
    "    dobjv, ddumo, dumh, dumhu = DirectRankingModelDNN(gs_drm[i], Dv_tre, Dv_unt, ov_tre, ov_unt, cv_tre, cv_unt, 'eval', num_hidden)\n",
    "    val_result = dsess.run(dobjv) \n",
    "    print('validation CPIT:') \n",
    "    print(val_result) \n",
    "    val_results.append(val_result) \n",
    "\n",
    "best_index = min(enumerate(val_results), key=itemgetter(1))[0] \n",
    "\n",
    "print('best performing model: iteration ' + str(best_index)) \n",
    "\n",
    "### run scoring on whole test set \n",
    "with gs_drm[best_index].as_default() as g: \n",
    "    if num_hidden > 0: \n",
    "        with tf.variable_scope(\"drmhidden\") as scope: \n",
    "            h1_test = tf.contrib.layers.fully_connected(Dt, num_hidden, activation_fn=tf.nn.tanh, reuse=tf.AUTO_REUSE, scope=scope, weights_initializer=tf.contrib.layers.xavier_initializer()) \n",
    "        with tf.variable_scope(\"drmranker\") as scope: \n",
    "            h_test = tf.contrib.layers.fully_connected(h1_test, 1, activation_fn=tf.nn.tanh, reuse=tf.AUTO_REUSE, scope=scope) \n",
    "    else: \n",
    "        with tf.variable_scope(\"drmranker\") as scope: \n",
    "            h_test = tf.contrib.layers.fully_connected(Dt, 1, activation_fn=tf.nn.tanh, reuse=tf.AUTO_REUSE, scope=scope) \n",
    "    drmscore = sess_list[best_index].run(h_test) \n",
    "\n",
    "### ---- train hte model for comparison ---- \n",
    "### we could utimize the original HTE functions \n",
    "from LinearHTEModels import * \n",
    "from PromotionModels import PromotionModels \n",
    "\n",
    "pmodels = PromotionModels() \n",
    "\n",
    "## set-up RLearner \n",
    "rl_ridge_model_O, rl_ridge_model_C = pmodels.fit_rlearner(D, o, c, w) \n",
    "\n",
    "## one model for order lift and one model for cost drop \n",
    "pred_values_va_rlearner_O = rl_ridge_model_O.predict(Dt) \n",
    "pred_values_va_rlearner_C = rl_ridge_model_C.predict(Dt) \n",
    "\n",
    "#plt.imagesc(np.concatneate(rl_ridge_model_O.params, ...params), axis=1) \n",
    "\n",
    "#if ranking_model == 'effectiveness-ratio': ## if we use the effectiveness ratio model, compute effectiveness ratio \n",
    "pred_values_va_rlearner = np.divide(np.maximum(pred_values_va_rlearner_O, 0), pred_values_va_rlearner_C + 1e-7) \n",
    "\n",
    "lhmodels = LinearHTEModels() \n",
    "lambds = [0.1] \n",
    "rlearnerscores = [] \n",
    "rl_ridge_model_L_list = [] \n",
    "## set-up lagrangian rlearner \n",
    "for i in range(len(lambds)): \n",
    "    lambd = lambds[i] \n",
    "    rl_ridge_model_L = lhmodels.fit_rlearner_lagrangian(D, o, c, w, lambd) \n",
    "    rl_ridge_model_L_list.append(rl_ridge_model_L) \n",
    "    rlearnerscores.append(rl_ridge_model_L.predict(Dt)) \n",
    "\n",
    "\"\"\" \n",
    "### this section is to load the results trained by grf R code \n",
    "### \n",
    "\n",
    "ot_cf = pd.read_csv('../results/causal_forest_grf_test_set_results_O_finalsize_numtrees1002.csv') \n",
    "ct_cf = pd.read_csv('../results/causal_forest_grf_test_set_results_C_finalsize_numtrees1002.csv') \n",
    "\n",
    "ot_cf = ot_cf.values() \n",
    "Ocfscores = ot_cf[0] \n",
    "\n",
    "ct_cf = ct_cf.values() \n",
    "Ccfscores = ct_cf[0] \n",
    "\n",
    "cfscore = np.divide(Ocfscores, Ccfscores) \n",
    "\"\"\" \n",
    "\n",
    "### ---- experimentation and plotting cost-curves ----- \n",
    "from experimentation import * \n",
    "exp = Experimentation() \n",
    "ranscore = np.random.rand(ot.shape[0], ) \n",
    "colors = ['b', 'c', 'g', 'y'] \n",
    "plt.figure() \n",
    "rlearnerauccs = [] \n",
    "ranaucc = exp.AUC_cpit_cost_curve_deciles_cohort(ranscore, ot, wt, -1.0 * ct, 'k', plot_random=True) \n",
    "quasiaucc = exp.AUC_cpit_cost_curve_deciles_cohort(pred_values_va_rlearner_O, ot, wt, -1.0 * ct, 'c') \n",
    "for i in range(len(lambds)): \n",
    "    rlearnerauccs.append(exp.AUC_cpit_cost_curve_deciles_cohort(rlearnerscores[i], ot, wt, -1.0 * ct, colors[i] )) \n",
    "#cfaucc = exp.AUC_cpit_cost_curve_deciles_cohort(cfscore, ot, wt, -1.0 * ct, 'g') # causal forest aucc and plotting \n",
    "tqraucc = exp.AUC_cpit_cost_curve_deciles_cohort(tqrscore, ot, wt, -1.0 * ct, 'r' ) \n",
    "drmaucc = exp.AUC_cpit_cost_curve_deciles_cohort(drmscore, ot, wt, -1.0 * ct, 'm' ) \n",
    "plt.title('Causal learning cost curves using targeting models') \n",
    "\n",
    "print('temp:') \n",
    "print(tempvalue) \n",
    "print('p_quantile:') \n",
    "print(p_quantilevalue) \n",
    "\n",
    "### --- add legeneds to plot ---- \n",
    "leg_str = ['Random'] \n",
    "leg_str.append('R-learner on Incremental Gain') \n",
    "for i in range(len(lambds)): \n",
    "    leg_str.append('Duality R-learner') \n",
    "#leg_str.append('Causal Forest') # causal forest result \n",
    "leg_str.append('Top Quantile Ranking at ' + str(p_quantile*100) + '%') \n",
    "leg_str.append('Direct Ranking Model') \n",
    "plt.legend(leg_str) \n",
    "\n",
    "### --- print out aucc results for different models --- \n",
    "print('AUCC results: ') \n",
    "print('random: ' + str(ranaucc)) \n",
    "print('rlearner: ' + str(quasiaucc)) \n",
    "i = 0\n",
    "for rlearneraucc in rlearnerauccs: \n",
    "    print('duality rlearner ' + str(i + 1) + ' with lambda = ' + str(lambds[i]) + ':' + str(rlearneraucc)) \n",
    "    i = i + 1\n",
    "print('drm: ' + str(drmaucc)) \n",
    "print('tqr: ' + str(tqraucc)) \n",
    "\n",
    "plt.show() \n",
    "\n",
    "### --- saving data to results folder ---- \n",
    "save_filename = '../results/benchmarkwithcv_tqr_drm_hte_'+prefix+'_main_results.pkl' \n",
    "saveD = {'tqrscore':tqrscore, 'drmscore':drmscore, 'quasiscore':pred_values_va_rlearner, 'quasiscore_O':pred_values_va_rlearner_O, 'rlearnerscore':rlearnerscores, 'ot':ot, 'wt':wt, 'ct':ct, 'tempvalue':tempvalue, 'p_quantilevalue':p_quantilevalue, \n",
    "         'tqraucc':tqraucc, 'drmaucc':drmaucc, 'rlearnerauccs':rlearnerauccs, 'ranaucc':ranaucc, 'quasiaucc':quasiaucc} \n",
    "#'cfscore':cfscore, causal forest scores \n",
    "pkl.dump(saveD, open(save_filename, 'wb')) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
