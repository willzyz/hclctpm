{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scaffold for Michelangelo customers \n",
    "## authors: will.zou@uber.com dmantar@uber.com \n",
    "## Causal Models for real-time incentives \n",
    "## import libraries and modules \n",
    "\n",
    "import sys, os, pandas as pd, numpy as np, pickle as pkl, tensorflow as tf \n",
    "sys.path.append('../dataprep/') \n",
    "from QueryFunctions import * \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2714: DtypeWarning: Columns (7,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "### pull data either using queryrunner or using csv \n",
    "use_query = 0 ### turn this switch on (to 1.0/True vs 0.0/False) to run query using QueryRunner \n",
    "use_python3 = True \n",
    "\n",
    "if use_query: \n",
    "    from queryrunner_client import Client \n",
    "    qr = Client(user_email='will.zou@uber.com') \n",
    "    ##label_dates_weekly = \"'2019-07-14', '2019-07-21', '2019-07-28', '2019-08-04'\" \n",
    "    ##city_ids = '1,5,6,8,10,12,20,23,198' \n",
    "    #feature_dates=\"'2019-06-30'\" \n",
    "    #proposal_start_date = '2019-07-08' \n",
    "    \n",
    "    predFrame2 = qr.execute('presto', rt_data_presto_first()) \n",
    "    predFrame2 = pd.DataFrame(predFrame2.load_data()) \n",
    "else: \n",
    "    predFrame2 = pd.read_csv('../data/rt_query_result.csv') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of dataset:\n",
      "728056\n",
      "size of control cohort:\n",
      "588443\n",
      "size of treatment cohort:\n",
      "139613\n"
     ]
    }
   ],
   "source": [
    "### Cross check on treatment and control cohort sizes \n",
    "cohort_column_name = 'treatment' \n",
    "treatment_indicator_value = True \n",
    "control_indicator_value = False \n",
    "print('size of dataset:') \n",
    "print(len(predFrame2)) \n",
    "print('size of control cohort:') \n",
    "print(sum(predFrame2[cohort_column_name] == control_indicator_value)) \n",
    "print('size of treatment cohort:') \n",
    "print(sum(predFrame2[cohort_column_name] == treatment_indicator_value)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### we should process the data such that route level cost and gains are per-session \n",
    "### so it's possible to rank the routes separately and it should be able to compare with results for \n",
    "### using rider information only \n",
    "\n",
    "### three data tables: \n",
    "### 1. with rider + route features and per route metrics \n",
    "### 2. with rider features and per rider metrics \n",
    "### 3. with route features and per route metrics \n",
    "\n",
    "### for table 1, we can have two algorithms \n",
    "### a. train a model on Table 2, score the riders as a feature for route-level model, then use route level model to evaluate \n",
    "### b. train a combined model on table 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nans: 98294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:90: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nans: 7933\n",
      "number of nans: 7933\n",
      "number of nans: 7945\n",
      "number of nans: 7945\n",
      "number of nans: 7933\n",
      "number of nans: 7933\n",
      "number of nans: 7933\n",
      "number of nans: 11614\n",
      "number of nans: 11614\n",
      "number of nans: 7933\n",
      "number of nans: 403240\n",
      "number of nans: 7933\n",
      "number of nans: 7933\n",
      "number of nans: 7984\n",
      "number of nans: 8080\n",
      "number of nans: 7933\n",
      "number of nans: 11614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:94: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rpu_treated : 137.95879171\n",
      "nipu_treated : -8.51501036608\n",
      "rpu_untreated : 116.767786782\n",
      "nipu_untreated : 12.1527682452\n",
      "cpit : 0.975309037102\n"
     ]
    }
   ],
   "source": [
    "### preprocess the data \n",
    "### -- sample treatment to match control cohort \n",
    "### -- eliminate nulls, standard normalization \n",
    "\n",
    "D = predFrame2 \n",
    "D = D.sample(frac=1.0) \n",
    "\n",
    "\"\"\"\n",
    "feature_list = [ \n",
    "    'rating_2driver_min_avg_84d'\n",
    "    , 'trip_incomplete_total_84d'\n",
    "    , 'days_active_84d'\n",
    "    , 'days_since_trip_first_lifetime'\n",
    "    , 'days_since_last_hard_churn_lifetime'\n",
    "    , 'days_since_last_soft_churn_lifetime'\n",
    "    , 'fare_max_sd_84d'\n",
    "    , 'churns_hard_lifetime'\n",
    "    , 'trips_lifetime'\n",
    "    , 'fare_max_p50_84d'\n",
    "    , 'duration_session_pre_request_max_p50_84d'\n",
    "    , 'trip_pool_per_x_84d'\n",
    "    , 'fare_total_win7d_sd_84d'\n",
    "    , 'trip_complete_win7d_sd_84d'\n",
    "    , 'session_per_days_active_84d'\n",
    "    , 'churns_soft_lifetime'\n",
    "    , 'trip_complete_per_days_active_84d'\n",
    "    , 'trip_pool_prc_84d'\n",
    "    , 'session_background_pre_request_prc_84d'\n",
    "    , 'session_lt_1m_prc_84d'\n",
    "    , 'session_request_prc_84d'\n",
    "    , 'duration_session_outside_total_prc_84d'\n",
    "    , 'trip_x_prc_84d'\n",
    "    , 'days_since_trip_last_lifetime'\n",
    "    , 'promo_used_84d'\n",
    "    , 'has_session_request_84d'\n",
    "    , 'has_session_without_request_84d' \n",
    "    , 'fare_promo_total_avg_84d', \n",
    "    'fare_total_avg_84d', \n",
    "    'surge_trip_avg_84d', \n",
    "    'fare_total_win7d_potential_84d', \n",
    "    'fare_total_win28d_potential_84d', \n",
    "    'fare_lifetime', \n",
    "    'time_to_first_message_minutes_mean_lifetime', \n",
    "    'ata_trip_max_avg_84d', \n",
    "    'eta_trip_max_avg_84d', \n",
    "    'trip_pool_matched_avg_84d', \n",
    "    'payment_cash_trip_total_84d', \n",
    "    'duration_trip_total_p50_84d'\n",
    "] \n",
    "\"\"\"\n",
    "feature_list = [ \n",
    "    'rating_2driver_min_avg_84d'\n",
    "    , 'days_active_84d'\n",
    "    , 'days_since_trip_first_lifetime'\n",
    "    , 'days_since_last_soft_churn_lifetime'\n",
    "    , 'churns_hard_lifetime'\n",
    "    , 'fare_max_p50_84d'\n",
    "    , 'fare_total_win7d_sd_84d'\n",
    "    , 'trip_complete_win7d_sd_84d'\n",
    "    , 'trip_pool_prc_84d'\n",
    "    , 'session_request_prc_84d'\n",
    "    , 'days_since_trip_last_lifetime'\n",
    "    , 'fare_promo_total_avg_84d'\n",
    "    , 'fare_total_avg_84d'\n",
    "    , 'surge_trip_avg_84d'\n",
    "    , 'fare_total_win28d_potential_84d'\n",
    "    , 'ata_trip_max_avg_84d'\n",
    "    , 'duration_trip_total_p50_84d'\n",
    "    , 'promo_used_84d'\n",
    "    #, 'estimate_fare_distance_in_miles' \n",
    "    #, 'estimate_fare_duration_in_minutes' \n",
    "    #, 'origin_destination_haversine_miles' \n",
    "    #, 'origin_lat' \n",
    "    #, 'origin_lng'\n",
    "    #, 'destination_lat'\n",
    "    #, 'destination_lng'  \n",
    "] \n",
    "\n",
    "label_list = [ \n",
    "    'gross_bookings_usd', \n",
    "    'variable_contribution_usd', \n",
    "    'num_sessions' \n",
    "] \n",
    "\n",
    "for l in feature_list: \n",
    "    print('number of nans: ' + str(sum(D[l] == '\\\\N'))) \n",
    "    D[l] = pd.to_numeric(D[l], errors='coerce') \n",
    "    D[l] = D[l] - D[l].mean() \n",
    "    D[l] = D[l] / D[l].std() \n",
    "    D[l][pd.isnull(D[l])] = 0.0 ## at zero mean due to standard normalization \n",
    "\n",
    "for l in label_list: \n",
    "    D[l] = pd.to_numeric(D[l], errors='coerce') \n",
    "    D[l][pd.isnull(D[l])] = 0.0 ## for zero gain/cost for financial data \n",
    "\n",
    "### -- compute simple statistics \n",
    "### compute cpit \n",
    "treated_entries = D[D[cohort_column_name] == treatment_indicator_value] \n",
    "untreated_entries = D[D[cohort_column_name] == control_indicator_value] \n",
    "\n",
    "rpu_treated = float(treated_entries[label_list[0]].sum()) / len(treated_entries) \n",
    "nipu_treated = float(treated_entries[label_list[1]].sum()) / len(treated_entries) \n",
    "\n",
    "rpu_untreated = float(untreated_entries[label_list[0]].sum()) / len(untreated_entries) \n",
    "nipu_untreated = float(untreated_entries[label_list[1]].sum()) / len(untreated_entries) \n",
    "\n",
    "cpit = -1.0 * (nipu_treated - nipu_untreated) / (rpu_treated - rpu_untreated) \n",
    "\n",
    "print('rpu_treated : ' + str(rpu_treated)) \n",
    "print('nipu_treated : ' + str(nipu_treated)) \n",
    "print('rpu_untreated : ' + str(rpu_untreated)) \n",
    "print('nipu_untreated : ' + str(nipu_untreated)) \n",
    "print('cpit : ' + str(cpit)) \n",
    "\n",
    "### split the data into 3/1/1 train/val/test \n",
    "len_tr = int(len(D) / 5 * 3) \n",
    "len_va = int(len(D) / 5) \n",
    "\n",
    "nX = D[feature_list].values \n",
    "w = D[cohort_column_name].apply(lambda x: 1.0 if x == treatment_indicator_value else 0.0) \n",
    "w = w.values \n",
    "values = D[label_list[0]] \n",
    "values = values.values \n",
    "negcost = D[label_list[1]] \n",
    "negcost = negcost.values * 1.0 \n",
    "num_sessions = D[label_list[2]].values \n",
    "values = np.divide(values, num_sessions) \n",
    "negcost = np.divide(negcost, num_sessions) \n",
    "\n",
    "## split train/val/test sets \n",
    "\n",
    "nX_tr = nX[0:len_tr, :] \n",
    "nX_va = nX[len_tr:len_tr + len_va, :] \n",
    "nX_te = nX[len_tr + len_va:, :] \n",
    "\n",
    "w_tr = w[0:len_tr]\n",
    "w_va = w[len_tr:len_tr + len_va] \n",
    "w_te = w[len_tr + len_va:] \n",
    "\n",
    "values_tr = values[0:len_tr] \n",
    "values_va = values[len_tr:len_tr + len_va] \n",
    "values_te = values[len_tr + len_va:] \n",
    "\n",
    "negcost_tr = negcost[0:len_tr] \n",
    "\n",
    "negcost_va = negcost[len_tr:len_tr + len_va] \n",
    "\n",
    "negcost_te = negcost[len_tr + len_va:] \n",
    "\n",
    "## saving data using cPickel and naming the dictionaries \n",
    "saveD = {'nX_tr':nX_tr, \n",
    "         'w_tr':w_tr, \n",
    "         'values_tr':values_tr, \n",
    "         'nX_va':nX_va, \n",
    "         'w_va':w_va, \n",
    "         'values_va':values_va, \n",
    "         'nX_te':nX_te, \n",
    "         'w_te':w_te, \n",
    "         'values_te':values_te, \n",
    "         'feature_list':feature_list, \n",
    "         #'avg_ni_usd_tr':avg_ni_usd_tr, \n",
    "         'negcost_tr': negcost_tr, \n",
    "         #'avg_ni_usd_va':avg_ni_usd_va, \n",
    "         'negcost_va': negcost_va, \n",
    "         #'avg_ni_usd_te':avg_ni_usd_te, \n",
    "         'negcost_te': negcost_te \n",
    "         } \n",
    "\n",
    "pkl.dump(saveD, open('../data/rxgy_ma_training_data_v5_2019_07_08_vc_tr_featuremod3_ood_rider', 'wb')) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        , 12.9366015 , -3.613147  , ...,  0.23448788,\n",
       "        0.77251816,  2.43400317])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negcost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "load() got an unexpected keyword argument 'encoding'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-deaa5f594b0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'rxgy_v5_07_08_featuremod3_tr_iter100_run4'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mD_tre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD_unt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDv_tre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDv_unt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDt_tre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDt_unt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo_tre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo_unt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mov_tre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mov_unt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mot_tre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mot_unt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_tre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_unt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_tre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_unt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mct_tre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mct_unt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoadDataFromPkl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_frac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_python3\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_python3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_cf_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_cf_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'### ----- start the training of deep learning models ------ '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/will.zou/code/deeplearning_hscls/DataProcFunctions.pyc\u001b[0m in \u001b[0;36mLoadDataFromPkl\u001b[0;34m(filename, frac, use_python3, save_cf_data)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_python3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mDd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"latin1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mDd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: load() got an unexpected keyword argument 'encoding'"
     ]
    }
   ],
   "source": [
    "### code implements ranking model for treatment effect \n",
    "### for optimizing with respect to direct marketplace objectives \n",
    "### using tensorflow \n",
    "\n",
    "import numpy as np, tensorflow as tf, pandas as pd, pickle as pkl \n",
    "sys.path.append('../')  \n",
    "from ModelDefinitions import * \n",
    "from DataProcFunctions import * \n",
    "\n",
    "### RxGy TQR setting: \n",
    "p_quantile = 0.4 ## percentage of quantile to aim for \n",
    "num_optimize_iterations = 2500 ## number of optimization iterations \n",
    "num_modeling_inits = 4 ## number of random initializations \n",
    "num_hidden = 0 ## number of hidden units in DNN \n",
    "use_schedule = True ## option to use a constraint annealing schedule \n",
    "temp = 0.5 ## initial temperature for constraints \n",
    "inc_temp = 0.1 ## increment of temperature per 100 iterations \n",
    "save_cf_data = False ### whether to save data for causal forest training \n",
    "\n",
    "## set a random seed to reproduce results \n",
    "seed = 1234; tf.compat.v2.random.set_seed(seed); np.random.seed(seed) \n",
    "\n",
    "sample_frac = 1.0 ## option to sample data by a fraction \\in (0, 1) \n",
    "data_filename =  '../data/rxgy_ma_training_data_v5_2019_07_08_vc_tr_featuremod3_ood_rider' \n",
    "prefix = 'rxgy_v5_07_08_featuremod3_tr_iter100_run4' \n",
    "\n",
    "D_tre, D_unt, Dv_tre, Dv_unt, Dt_tre, Dt_unt, o_tre, o_unt, ov_tre, ov_unt, ot_tre, ot_unt, c_tre, c_unt, cv_tre, cv_unt, ct_tre, ct_unt, D, w, o, c, Dv, wv, ov, cv, Dt, wt, ot, ct = LoadDataFromPkl(data_filename, frac = sample_frac, use_python3=use_python3, save_cf_data=save_cf_data) \n",
    "\n",
    "print('### ----- start the training of deep learning models ------ ') \n",
    "gs_tqr = [] \n",
    "gs_drm = [] \n",
    "for i in range(num_modeling_inits): \n",
    "    gs_tqr.append(tf.Graph()) \n",
    "for i in range(num_modeling_inits): \n",
    "    gs_drm.append(tf.Graph()) \n",
    "\n",
    "print('------> Training TQR ranking model .... ') \n",
    "val_results = [] \n",
    "sess_list = [] \n",
    "for i in range(num_modeling_inits): \n",
    "    print('---> running cross validation, iteration: ' + str(i)) \n",
    "    obj, opt, dumh, dumhu, vtemp, p_quantile = TunableTQRankingModelDNN(gs_tqr[i], D_tre, D_unt, o_tre, o_unt, c_tre, c_unt, 'train-first', temp, p_quantile, num_hidden, use_schedule) \n",
    "    ### session definitions and variable initialization \n",
    "    sess = tf.Session(graph = gs_tqr[i]) \n",
    "    sess_list.append(sess) \n",
    "    \n",
    "    ### initialize variables and run optimization \n",
    "    with gs_tqr[i].as_default() as g: \n",
    "        init = tf.global_variables_initializer() \n",
    "    sess.run(init) \n",
    "    cur_temp = temp \n",
    "    for step in range(num_optimize_iterations): \n",
    "        _, objres = sess.run([opt, obj]) \n",
    "        if step % 100 == 0: \n",
    "            cur_temp = cur_temp + inc_temp \n",
    "            print('opt. step : ' + str(step) + ' obj: ' + str(objres)) \n",
    "            if use_schedule: \n",
    "                sess.run(vtemp.assign(cur_temp))\n",
    "                print('setting temperature to :' + str(sess.run(vtemp))) \n",
    "    \n",
    "    print('---> optimization finished ... ') \n",
    "    tempvalue = sess.run(vtemp)\n",
    "    p_quantilevalue = p_quantile\n",
    "    print('temp:') \n",
    "    print(tempvalue)\n",
    "    print('p_quantile:')\n",
    "    print(p_quantilevalue) \n",
    "    \n",
    "    ### evaluate CPIT metric on validation set \n",
    "    objv, dumo, dumh, dumhu, dvtemp, dp_quantile = TunableTQRankingModelDNN(gs_tqr[i], Dv_tre, Dv_unt, ov_tre, ov_unt, cv_tre, cv_unt, 'eval', temp, p_quantile, num_hidden, use_schedule) \n",
    "    \n",
    "    val_result = sess.run(objv) \n",
    "    print('validation CPIT:') \n",
    "    print(val_result) \n",
    "    val_results.append(val_result) \n",
    "\n",
    "from operator import itemgetter \n",
    "best_index = min(enumerate(val_results), key=itemgetter(1))[0] \n",
    "\n",
    "print('best performing model: iteration ' + str(best_index)) \n",
    "\n",
    "### run scoring on whole test set \n",
    "with gs_tqr[best_index].as_default() as g: \n",
    "    if num_hidden > 0: \n",
    "        with tf.variable_scope(\"tqrhidden\") as scope: \n",
    "            h1_test = tf.contrib.layers.fully_connected(Dt, num_hidden, activation_fn=tf.nn.tanh, reuse=tf.AUTO_REUSE, scope=scope, weights_initializer=tf.contrib.layers.xavier_initializer()) \n",
    "        with tf.variable_scope(\"tqranker\") as scope: \n",
    "            h_test = tf.contrib.layers.fully_connected(h1_test, 1, activation_fn=None, reuse=tf.AUTO_REUSE, scope=scope) \n",
    "    else: \n",
    "        with tf.variable_scope(\"tqranker\") as scope: \n",
    "            h_test = tf.contrib.layers.fully_connected(Dt, 1, activation_fn=None, reuse=tf.AUTO_REUSE, scope=scope) \n",
    "    tqrscore = sess_list[best_index].run(h_test) \n",
    "\n",
    "print('------> Training DRM ranking model .... ') \n",
    "sess_list = [] \n",
    "val_results = [] \n",
    "for i in range(num_modeling_inits): \n",
    "    print('---> running cross validation, iteration: ' + str(i)) \n",
    "    ### ---- train cpit ranking model for comparison --- \n",
    "    dobjc, doptc, ddumh, ddumu = DirectRankingModelDNN(gs_drm[i], D_tre, D_unt, o_tre, o_unt, c_tre, c_unt, 'train-first-drm', num_hidden) \n",
    "    \n",
    "    dsess = tf.Session(graph = gs_drm[i]) \n",
    "    sess_list.append(dsess) \n",
    "    \n",
    "    ### initialize variables and run optimization \n",
    "    with gs_drm[i].as_default() as g: \n",
    "        dinit = tf.global_variables_initializer() \n",
    "    dsess.run(dinit) \n",
    "    for step in range(num_optimize_iterations): \n",
    "        _, dobjres = dsess.run([doptc, dobjc]) \n",
    "        if step % 100 == 0: \n",
    "            print('opt. step : ' + str(step) + ' obj: ' + str(dobjres)) \n",
    "    \n",
    "    print('---> optimization finished ... ') \n",
    "    \n",
    "    ### evaluate CPIT metric on validation set \n",
    "    dobjv, ddumo, dumh, dumhu = DirectRankingModelDNN(gs_drm[i], Dv_tre, Dv_unt, ov_tre, ov_unt, cv_tre, cv_unt, 'eval', num_hidden)\n",
    "    val_result = dsess.run(dobjv) \n",
    "    print('validation CPIT:') \n",
    "    print(val_result) \n",
    "    val_results.append(val_result) \n",
    "\n",
    "best_index = min(enumerate(val_results), key=itemgetter(1))[0] \n",
    "\n",
    "print('best performing model: iteration ' + str(best_index)) \n",
    "\n",
    "### run scoring on whole test set \n",
    "with gs_drm[best_index].as_default() as g: \n",
    "    if num_hidden > 0: \n",
    "        with tf.variable_scope(\"drmhidden\") as scope: \n",
    "            h1_test = tf.contrib.layers.fully_connected(Dt, num_hidden, activation_fn=tf.nn.tanh, reuse=tf.AUTO_REUSE, scope=scope, weights_initializer=tf.contrib.layers.xavier_initializer()) \n",
    "        with tf.variable_scope(\"drmranker\") as scope: \n",
    "            h_test = tf.contrib.layers.fully_connected(h1_test, 1, activation_fn=tf.nn.tanh, reuse=tf.AUTO_REUSE, scope=scope) \n",
    "    else: \n",
    "        with tf.variable_scope(\"drmranker\") as scope: \n",
    "            h_test = tf.contrib.layers.fully_connected(Dt, 1, activation_fn=tf.nn.tanh, reuse=tf.AUTO_REUSE, scope=scope) \n",
    "    drmscore = sess_list[best_index].run(h_test) \n",
    "\n",
    "### ---- train hte model for comparison ---- \n",
    "### we could utimize the original HTE functions \n",
    "from LinearHTEModels import * \n",
    "from PromotionModels import PromotionModels \n",
    "\n",
    "pmodels = PromotionModels() \n",
    "\n",
    "## set-up RLearner \n",
    "rl_ridge_model_O, rl_ridge_model_C = pmodels.fit_rlearner(D, o, c, w) \n",
    "\n",
    "## one model for order lift and one model for cost drop \n",
    "pred_values_va_rlearner_O = rl_ridge_model_O.predict(Dt) \n",
    "pred_values_va_rlearner_C = rl_ridge_model_C.predict(Dt) \n",
    "\n",
    "#plt.imagesc(np.concatneate(rl_ridge_model_O.params, ...params), axis=1) \n",
    "\n",
    "#if ranking_model == 'effectiveness-ratio': ## if we use the effectiveness ratio model, compute effectiveness ratio \n",
    "pred_values_va_rlearner = np.divide(np.maximum(pred_values_va_rlearner_O, 0), pred_values_va_rlearner_C + 1e-7) \n",
    "\n",
    "lhmodels = LinearHTEModels() \n",
    "lambds = [0.1] \n",
    "rlearnerscores = [] \n",
    "rl_ridge_model_L_list = [] \n",
    "## set-up lagrangian rlearner \n",
    "for i in range(len(lambds)): \n",
    "    lambd = lambds[i] \n",
    "    rl_ridge_model_L = lhmodels.fit_rlearner_lagrangian(D, o, c, w, lambd) \n",
    "    rl_ridge_model_L_list.append(rl_ridge_model_L) \n",
    "    rlearnerscores.append(rl_ridge_model_L.predict(Dt)) \n",
    "\n",
    "\"\"\" \n",
    "### this section is to load the results trained by grf R code \n",
    "### \n",
    "\n",
    "ot_cf = pd.read_csv('../results/causal_forest_grf_test_set_results_O_finalsize_numtrees1002.csv') \n",
    "ct_cf = pd.read_csv('../results/causal_forest_grf_test_set_results_C_finalsize_numtrees1002.csv') \n",
    "\n",
    "ot_cf = ot_cf.values() \n",
    "Ocfscores = ot_cf[0] \n",
    "\n",
    "ct_cf = ct_cf.values() \n",
    "Ccfscores = ct_cf[0] \n",
    "\n",
    "cfscore = np.divide(Ocfscores, Ccfscores) \n",
    "\"\"\" \n",
    "\n",
    "### ---- experimentation and plotting cost-curves ----- \n",
    "from experimentation import * \n",
    "exp = Experimentation() \n",
    "ranscore = np.random.rand(ot.shape[0], ) \n",
    "colors = ['b', 'c', 'g', 'y'] \n",
    "plt.figure() \n",
    "rlearnerauccs = [] \n",
    "ranaucc = exp.AUC_cpit_cost_curve_deciles_cohort(ranscore, ot, wt, -1.0 * ct, 'k', plot_random=True) \n",
    "quasiaucc = exp.AUC_cpit_cost_curve_deciles_cohort(pred_values_va_rlearner_O, ot, wt, -1.0 * ct, 'c') \n",
    "for i in range(len(lambds)): \n",
    "    rlearnerauccs.append(exp.AUC_cpit_cost_curve_deciles_cohort(rlearnerscores[i], ot, wt, -1.0 * ct, colors[i] )) \n",
    "#cfaucc = exp.AUC_cpit_cost_curve_deciles_cohort(cfscore, ot, wt, -1.0 * ct, 'g') # causal forest aucc and plotting \n",
    "tqraucc = exp.AUC_cpit_cost_curve_deciles_cohort(tqrscore, ot, wt, -1.0 * ct, 'r' ) \n",
    "drmaucc = exp.AUC_cpit_cost_curve_deciles_cohort(drmscore, ot, wt, -1.0 * ct, 'm' ) \n",
    "plt.title('Causal learning cost curves using targeting models') \n",
    "\n",
    "print('temp:') \n",
    "print(tempvalue) \n",
    "print('p_quantile:') \n",
    "print(p_quantilevalue) \n",
    "\n",
    "### --- add legeneds to plot ---- \n",
    "leg_str = ['Random'] \n",
    "leg_str.append('R-learner on Incremental Gain') \n",
    "for i in range(len(lambds)): \n",
    "    leg_str.append('Duality R-learner') \n",
    "#leg_str.append('Causal Forest') # causal forest result \n",
    "leg_str.append('Top Quantile Ranking at ' + str(p_quantile*100) + '%') \n",
    "leg_str.append('Direct Ranking Model') \n",
    "plt.legend(leg_str) \n",
    "\n",
    "### --- print out aucc results for different models --- \n",
    "print('AUCC results: ') \n",
    "print('random: ' + str(ranaucc)) \n",
    "print('rlearner: ' + str(quasiaucc)) \n",
    "i = 0\n",
    "for rlearneraucc in rlearnerauccs: \n",
    "    print('duality rlearner ' + str(i + 1) + ' with lambda = ' + str(lambds[i]) + ':' + str(rlearneraucc)) \n",
    "    i = i + 1\n",
    "print('drm: ' + str(drmaucc)) \n",
    "print('tqr: ' + str(tqraucc)) \n",
    "\n",
    "plt.show() \n",
    "\n",
    "### --- saving data to results folder ---- \n",
    "save_filename = '../results/benchmarkwithcv_tqr_drm_hte_'+prefix+'_main_results.pkl' \n",
    "saveD = {'tqrscore':tqrscore, 'drmscore':drmscore, 'quasiscore':pred_values_va_rlearner, 'quasiscore_O':pred_values_va_rlearner_O, 'rlearnerscore':rlearnerscores, 'ot':ot, 'wt':wt, 'ct':ct, 'tempvalue':tempvalue, 'p_quantilevalue':p_quantilevalue, \n",
    "         'tqraucc':tqraucc, 'drmaucc':drmaucc, 'rlearnerauccs':rlearnerauccs, 'ranaucc':ranaucc, 'quasiaucc':quasiaucc} \n",
    "#'cfscore':cfscore, causal forest scores \n",
    "pkl.dump(saveD, open(save_filename, 'wb')) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ---- experimentation and plotting cost-curves ----- \n",
    "from experimentation import * \n",
    "exp = Experimentation() \n",
    "ranscore = np.random.rand(ot.shape[0], ) \n",
    "colors = ['b', 'c', 'g', 'y'] \n",
    "plt.figure() \n",
    "rlearnerauccs = [] \n",
    "ranaucc = exp.AUC_cpit_cost_curve_deciles_cohort(ranscore, ot, wt, -1.0 * ct, 'k', plot_random=True) \n",
    "quasiaucc = exp.AUC_cpit_cost_curve_deciles_cohort(pred_values_va_rlearner_O, ot, wt, -1.0 * ct, 'c') \n",
    "for i in range(len(lambds)): \n",
    "    rlearnerauccs.append(exp.AUC_cpit_cost_curve_deciles_cohort(rlearnerscores[i], ot, wt, -1.0 * ct, colors[i] )) \n",
    "#cfaucc = exp.AUC_cpit_cost_curve_deciles_cohort(cfscore, ot, wt, -1.0 * ct, 'g') # causal forest aucc and plotting \n",
    "tqraucc = exp.AUC_cpit_cost_curve_deciles_cohort(tqrscore, ot, wt, -1.0 * ct, 'r' ) \n",
    "drmaucc = exp.AUC_cpit_cost_curve_deciles_cohort(drmscore, ot, wt, -1.0 * ct, 'm' ) \n",
    "plt.title('Causal learning cost curves using targeting models') \n",
    "\n",
    "print('temp:') \n",
    "print(tempvalue) \n",
    "print('p_quantile:') \n",
    "print(p_quantilevalue) \n",
    "\n",
    "### --- add legeneds to plot ---- \n",
    "leg_str = ['Random'] \n",
    "leg_str.append('R-learner on Incremental Gain') \n",
    "for i in range(len(lambds)): \n",
    "    leg_str.append('Duality R-learner') \n",
    "#leg_str.append('Causal Forest') # causal forest result \n",
    "leg_str.append('Top Quantile Ranking at ' + str(p_quantile*100) + '%') \n",
    "leg_str.append('Direct Ranking Model') \n",
    "plt.legend(leg_str) \n",
    "\n",
    "### --- print out aucc results for different models --- \n",
    "print('AUCC results: ') \n",
    "print('random: ' + str(ranaucc)) \n",
    "print('rlearner: ' + str(quasiaucc)) \n",
    "i = 0\n",
    "for rlearneraucc in rlearnerauccs: \n",
    "    print('duality rlearner ' + str(i + 1) + ' with lambda = ' + str(lambds[i]) + ':' + str(rlearneraucc)) \n",
    "    i = i + 1\n",
    "print('drm: ' + str(drmaucc)) \n",
    "print('tqr: ' + str(tqraucc)) \n",
    "\n",
    "plt.show() \n",
    "\n",
    "### --- saving data to results folder ---- \n",
    "save_filename = '../results/benchmarkwithcv_tqr_drm_hte_'+prefix+'_main_results.pkl' \n",
    "saveD = {'tqrscore':tqrscore, 'drmscore':drmscore, 'quasiscore':pred_values_va_rlearner, 'quasiscore_O':pred_values_va_rlearner_O, 'rlearnerscore':rlearnerscores, 'ot':ot, 'wt':wt, 'ct':ct, 'tempvalue':tempvalue, 'p_quantilevalue':p_quantilevalue, \n",
    "         'tqraucc':tqraucc, 'drmaucc':drmaucc, 'rlearnerauccs':rlearnerauccs, 'ranaucc':ranaucc, 'quasiaucc':quasiaucc} \n",
    "#'cfscore':cfscore, causal forest scores \n",
    "pkl.dump(saveD, open(save_filename, 'wb')) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
