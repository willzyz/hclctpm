{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, cPickle as pkl \n",
    "import sys, os \n",
    "sys.path.append('../dataprep/') \n",
    "sys.path.append('../models/') \n",
    "from QueryFunctions import * \n",
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2714: DtypeWarning: Columns (9,10,11,12,14,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nlabel_dates_weekly = \"\\'2019-10-06\\', \\'2019-10-13\\', \\'2019-10-20\\', \\'2019-10-27\\'\" \\ncity_ids = \\'1,5,6,8,10,12,20,23,198\\' \\nfeature_dates=\"\\'2019-09-22\\'\" \\nproposal_start_date = \\'2019-09-30\\' \\n\\npredFrame4 = qr.execute(\\'presto\\', rxgy_data_sapphire_presto_featuremod2(label_dates_weekly, feature_dates,  city_ids)) \\npredFrame4 = pd.DataFrame(predFrame4.load_data()) \\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_query = 0 ### turn this switch on (to 1.0/True vs 0.0/False) to run query using QueryRunner \n",
    "\n",
    "if use_query: \n",
    "    from queryrunner_client import Client \n",
    "    qr = Client(user_email='will.zou@uber.com') \n",
    "    label_dates_weekly = \"'2019-07-14', '2019-07-21', '2019-07-28', '2019-08-04'\" \n",
    "    city_ids = '1,5,6,8,10,12,20,23,198' \n",
    "    feature_dates=\"'2019-06-30'\" \n",
    "    proposal_start_date = '2019-07-08' \n",
    "\n",
    "    predFrame2 = qr.execute('presto', rxgy_data_sapphire_presto_featuremod2(label_dates_weekly, feature_dates,  city_ids)) \n",
    "    predFrame2 = pd.DataFrame(predFrame2.load_data()) \n",
    "else: \n",
    "    predFrame2 = pd.read_csv('../data/rxgy_adrm_train_multimetric_US_20190602_20190804_simulated.csv') \n",
    "\n",
    "\"\"\" \n",
    "label_dates_weekly = \"'2019-07-07','2019-06-30','2019-06-23','2019-06-16'\"\n",
    "city_ids = '1,5,6,8,10,12,20,23,198' \n",
    "feature_dates=\"'2019-06-02'\" \n",
    "proposal_start_date = '2019-06-10' \n",
    "\n",
    "predFrame = qr.execute('presto', rxgy_data_sapphire_presto_featuremod2(label_dates_weekly, feature_dates,  city_ids)) \n",
    "predFrame = pd.DataFrame(predFrame.load_data()) \n",
    "\"\"\" \n",
    "\n",
    "\"\"\" \n",
    "label_dates_weekly = \"'2019-08-11', '2019-08-18', '2019-08-25', '2019-09-01'\" \n",
    "city_ids = '1,5,6,8,10,12,20,23,198' \n",
    "feature_dates=\"'2019-07-28'\" \n",
    "proposal_start_date = '2019-08-05' \n",
    "\n",
    "predFrame3 = qr.execute('presto', rxgy_data_sapphire_presto_featuremod2(label_dates_weekly, feature_dates,  city_ids)) \n",
    "predFrame3 = pd.DataFrame(predFrame3.load_data()) \n",
    "\"\"\" \n",
    "\n",
    "\"\"\"\n",
    "label_dates_weekly = \"'2019-10-06', '2019-10-13', '2019-10-20', '2019-10-27'\" \n",
    "city_ids = '1,5,6,8,10,12,20,23,198' \n",
    "feature_dates=\"'2019-09-22'\" \n",
    "proposal_start_date = '2019-09-30' \n",
    "\n",
    "predFrame4 = qr.execute('presto', rxgy_data_sapphire_presto_featuremod2(label_dates_weekly, feature_dates,  city_ids)) \n",
    "predFrame4 = pd.DataFrame(predFrame4.load_data()) \n",
    "\"\"\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1972139\n",
      "395281\n"
     ]
    }
   ],
   "source": [
    "cohort_column_name = 'cohort' \n",
    "treatment_indicator_value = 'treatment' \n",
    "control_indicator_value = 'control' \n",
    "\n",
    "print(len(predFrame2))\n",
    "print(sum(predFrame2[cohort_column_name] == control_indicator_value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nans: 128837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/site-packages/pandas/core/ops.py:1649: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nans: 0\n",
      "number of nans: 0\n",
      "number of nans: 0\n",
      "number of nans: 45\n",
      "number of nans: 45\n",
      "number of nans: 1\n",
      "number of nans: 45\n",
      "number of nans: 0\n",
      "number of nans: 1\n",
      "number of nans: 40305\n",
      "number of nans: 56877\n",
      "number of nans: 0\n",
      "number of nans: 0\n",
      "number of nans: 15250\n",
      "number of nans: 45\n",
      "number of nans: 15250\n",
      "number of nans: 15250\n",
      "number of nans: 15250\n",
      "number of nans: 15250\n",
      "number of nans: 15250\n",
      "number of nans: 15250\n",
      "number of nans: 15250\n",
      "number of nans: 0\n",
      "number of nans: 15250\n",
      "number of nans: 15250\n",
      "number of nans: 15250\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'fare_promo_total_avg_84d'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d9fff6674067>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeature_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'number of nans: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'\\N'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'coerce'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2926\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2927\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/pandas/core/indexes/base.pyc\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2657\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2659\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'fare_promo_total_avg_84d'"
     ]
    }
   ],
   "source": [
    "### preprocess the data \n",
    "### -- sample treatment to match control cohort \n",
    "### -- eliminate nulls, standard normalization \n",
    "\n",
    "D = predFrame2 \n",
    "D = D.sample(frac=0.3) \n",
    "\n",
    "feature_list = [ \n",
    "    'rating_2driver_min_avg_84d'\n",
    "    , 'trip_incomplete_total_84d'\n",
    "    , 'days_active_84d'\n",
    "    , 'days_since_trip_first_lifetime'\n",
    "    , 'days_since_last_hard_churn_lifetime'\n",
    "    , 'days_since_last_soft_churn_lifetime'\n",
    "    , 'fare_max_sd_84d'\n",
    "    , 'churns_hard_lifetime'\n",
    "    , 'trips_lifetime'\n",
    "    , 'fare_max_p50_84d'\n",
    "    , 'duration_session_pre_request_max_p50_84d'\n",
    "    , 'trip_pool_per_x_84d'\n",
    "    , 'fare_total_win7d_sd_84d'\n",
    "    , 'trip_complete_win7d_sd_84d'\n",
    "    , 'session_per_days_active_84d'\n",
    "    , 'churns_soft_lifetime'\n",
    "    , 'trip_complete_per_days_active_84d'\n",
    "    , 'trip_pool_prc_84d'\n",
    "    , 'session_background_pre_request_prc_84d'\n",
    "    , 'session_lt_1m_prc_84d'\n",
    "    , 'session_request_prc_84d'\n",
    "    , 'duration_session_outside_total_prc_84d'\n",
    "    , 'trip_x_prc_84d'\n",
    "    , 'days_since_trip_last_lifetime'\n",
    "    , 'promo_used_84d'\n",
    "    , 'has_session_request_84d'\n",
    "    , 'has_session_without_request_84d' \n",
    "    , 'fare_promo_total_avg_84d', \n",
    "    'fare_total_avg_84d', \n",
    "    'surge_trip_avg_84d', \n",
    "    'fare_total_win7d_potential_84d', \n",
    "    'fare_total_win28d_potential_84d', \n",
    "    'fare_lifetime', \n",
    "    'time_to_first_message_minutes_mean_lifetime', \n",
    "    'ata_trip_max_avg_84d', \n",
    "    'eta_trip_max_avg_84d', \n",
    "    'trip_pool_matched_avg_84d', \n",
    "    'payment_cash_trip_total_84d', \n",
    "    'duration_trip_total_p50_84d'\n",
    "] \n",
    "\n",
    "label_list = [ \n",
    "    'label_trip_28d', \n",
    "    'label_vc_28d' \n",
    "] \n",
    "\n",
    "for l in feature_list: \n",
    "    print('number of nans: ' + str(sum(D[l] == '\\N'))) \n",
    "    D[l] = pd.to_numeric(D[l], errors='coerce') \n",
    "    D[l] = D[l] - D[l].mean() \n",
    "    D[l] = D[l] / D[l].std() \n",
    "    D[l][pd.isnull(D[l])] = 0.0 ## at zero mean due to standard normalization \n",
    "\n",
    "for l in label_list: \n",
    "    D[l] = pd.to_numeric(D[l], errors='coerce') \n",
    "    D[l][pd.isnull(D[l])] = 0.0 ## at zero mean due to standard normalization \n",
    "\n",
    "### -- compute simple statistics \n",
    "### compute cpit \n",
    "treated_entries = D[D[cohort_column_name] == treatment_indicator_value] \n",
    "untreated_entries = D[D[cohort_column_name] == control_indicator_value] \n",
    "\n",
    "rpu_treated = float(treated_entries[label_list[0]].sum()) / len(treated_entries) \n",
    "nipu_treated = float(treated_entries[label_list[1]].sum()) / len(treated_entries) \n",
    "\n",
    "rpu_untreated = float(untreated_entries[label_list[0]].sum()) / len(untreated_entries) \n",
    "nipu_untreated = float(untreated_entries[label_list[1]].sum()) / len(untreated_entries) \n",
    "\n",
    "cpit = -1.0 * (nipu_treated - nipu_untreated) / (rpu_treated - rpu_untreated) \n",
    "\n",
    "print('rpu_treated : ' + str(rpu_treated)) \n",
    "print('nipu_treated : ' + str(nipu_treated)) \n",
    "print('rpu_untreated : ' + str(rpu_untreated)) \n",
    "print('nipu_untreated : ' + str(nipu_untreated)) \n",
    "print('cpit : ' + str(cpit)) \n",
    "\n",
    "### split the data into 3/1/1 train/val/test \n",
    "len_tr = len(D) / 5 * 3 \n",
    "len_va = len(D) / 5 \n",
    "\n",
    "nX = D[feature_list].as_matrix() \n",
    "w = D[cohort_column_name].apply(lambda x: 1.0 if x == treatment_indicator_value else 0.0) \n",
    "w = w.as_matrix() \n",
    "values = D[label_list[0]] \n",
    "values = values.as_matrix() * 1.0 \n",
    "negcost = D[label_list[1]] \n",
    "negcost = negcost.as_matrix() * 1.0 \n",
    "\n",
    "## split train/val/test sets \n",
    "\n",
    "nX_tr = nX[0:len_tr, :] \n",
    "nX_va = nX[len_tr:len_tr + len_va, :] \n",
    "nX_te = nX[len_tr + len_va:, :] \n",
    "\n",
    "w_tr = w[0:len_tr]\n",
    "w_va = w[len_tr:len_tr + len_va] \n",
    "w_te = w[len_tr + len_va:] \n",
    "\n",
    "values_tr = values[0:len_tr] \n",
    "values_va = values[len_tr:len_tr + len_va] \n",
    "values_te = values[len_tr + len_va:] \n",
    "\n",
    "negcost_tr = negcost[0:len_tr] \n",
    "\n",
    "negcost_va = negcost[len_tr:len_tr + len_va] \n",
    "\n",
    "negcost_te = negcost[len_tr + len_va:] \n",
    "\n",
    "## saving data using cPickel and naming the dictionaries \n",
    "saveD = {'nX_tr':nX_tr, \n",
    "         'w_tr':w_tr, \n",
    "         'values_tr':values_tr, \n",
    "         'nX_va':nX_va, \n",
    "         'w_va':w_va, \n",
    "         'values_va':values_va, \n",
    "         'nX_te':nX_te, \n",
    "         'w_te':w_te, \n",
    "         'values_te':values_te, \n",
    "         'feature_list':feature_list, \n",
    "         #'avg_ni_usd_tr':avg_ni_usd_tr, \n",
    "         'negcost_tr': negcost_tr, \n",
    "         #'avg_ni_usd_va':avg_ni_usd_va, \n",
    "         'negcost_va': negcost_va, \n",
    "         #'avg_ni_usd_te':avg_ni_usd_te, \n",
    "         'negcost_te': negcost_te \n",
    "         } \n",
    "\n",
    "pkl.dump(saveD, open('../data/rxgy_ma_training_data_v5_2019_07_08_vc_tr_featuremod3', 'w')) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data from ../data/rxgy_ma_training_data_v5_2019_07_08_vc_tr_featuremod3\n",
      "printing averages of c_tr, c_unt, o_tre, o_unt ... :\n",
      "0.17914820257318836\n",
      "0.06158097484449673\n",
      "0.05130641330166271\n",
      "0.02673917969635169\n",
      "### ----- start the training of deep learning models ------ \n",
      "------> Training TQR ranking model .... \n",
      "---> running cross validation, iteration: 0\n",
      "WARNING:tensorflow:From ../models/ModelDefinitions.py:37: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From ../models/ModelDefinitions.py:37: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "WARNING:tensorflow:From ../models/ModelDefinitions.py:38: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15134dfd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15134dfd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15134dfd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15134dfd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1364d2810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1364d2810>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1364d2810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1364d2810>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From ../models/ModelDefinitions.py:74: The name tf.ceil is deprecated. Please use tf.math.ceil instead.\n",
      "\n",
      "WARNING:tensorflow:From ../models/ModelDefinitions.py:115: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "opt. step : 0 obj: 4.753091339673534\n",
      "setting temperature to :0.6\n",
      "opt. step : 100 obj: 4.717418246350326\n",
      "setting temperature to :0.7\n",
      "opt. step : 200 obj: 4.683181262910153\n",
      "setting temperature to :0.7999999999999999\n",
      "opt. step : 300 obj: 4.642134264259395\n",
      "setting temperature to :0.8999999999999999\n",
      "opt. step : 400 obj: 4.601696464654989\n",
      "setting temperature to :0.9999999999999999\n",
      "opt. step : 500 obj: 4.568089121231049\n",
      "setting temperature to :1.0999999999999999\n",
      "opt. step : 600 obj: 4.540149131779787\n",
      "setting temperature to :1.2\n",
      "opt. step : 700 obj: 4.51590401960824\n",
      "setting temperature to :1.3\n",
      "opt. step : 800 obj: 4.494330365475637\n",
      "setting temperature to :1.4000000000000001\n",
      "opt. step : 900 obj: 4.476940889287771\n",
      "setting temperature to :1.5000000000000002\n",
      "opt. step : 1000 obj: 4.458881788922786\n",
      "setting temperature to :1.6000000000000003\n",
      "opt. step : 1100 obj: 4.439247196672968\n",
      "setting temperature to :1.7000000000000004\n",
      "opt. step : 1200 obj: 4.421056792162329\n",
      "setting temperature to :1.8000000000000005\n",
      "opt. step : 1300 obj: 4.407455969143832\n",
      "setting temperature to :1.9000000000000006\n",
      "opt. step : 1400 obj: 4.396436077745112\n",
      "setting temperature to :2.0000000000000004\n",
      "opt. step : 1500 obj: 4.387497193870069\n",
      "setting temperature to :2.1000000000000005\n",
      "opt. step : 1600 obj: 4.379743461954853\n",
      "setting temperature to :2.2000000000000006\n",
      "opt. step : 1700 obj: 4.372392289266625\n",
      "setting temperature to :2.3000000000000007\n",
      "---> optimization finished ... \n",
      "temp:\n",
      "2.362651845854361\n",
      "p_quantile:\n",
      "0.4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1516e4f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1516e4f10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1516e4f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1516e4f10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1516e4d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1516e4d50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1516e4d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1516e4d50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "validation CPIT:\n",
      "4.881745474724322\n",
      "---> running cross validation, iteration: 1\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1517a4310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1517a4310>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1517a4310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1517a4310>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1517a4790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1517a4790>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1517a4790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1517a4790>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "opt. step : 0 obj: 4.777006033990844\n",
      "setting temperature to :0.6\n",
      "opt. step : 100 obj: 4.729566344289665\n",
      "setting temperature to :0.7\n",
      "opt. step : 200 obj: 4.692250223827163\n",
      "setting temperature to :0.7999999999999999\n",
      "opt. step : 300 obj: 4.660730084265286\n",
      "setting temperature to :0.8999999999999999\n",
      "opt. step : 400 obj: 4.631737480902887\n",
      "setting temperature to :0.9999999999999999\n",
      "opt. step : 500 obj: 4.603055479208876\n",
      "setting temperature to :1.0999999999999999\n",
      "opt. step : 600 obj: 4.570004434493083\n",
      "setting temperature to :1.2\n",
      "opt. step : 700 obj: 4.530627795136798\n",
      "setting temperature to :1.3\n",
      "opt. step : 800 obj: 4.498307968720447\n",
      "setting temperature to :1.4000000000000001\n",
      "opt. step : 900 obj: 4.474258956248882\n",
      "setting temperature to :1.5000000000000002\n",
      "opt. step : 1000 obj: 4.456635874998921\n",
      "setting temperature to :1.6000000000000003\n",
      "opt. step : 1100 obj: 4.442322313876678\n",
      "setting temperature to :1.7000000000000004\n",
      "opt. step : 1200 obj: 4.429864514267671\n",
      "setting temperature to :1.8000000000000005\n",
      "opt. step : 1300 obj: 4.41826484953039\n",
      "setting temperature to :1.9000000000000006\n",
      "opt. step : 1400 obj: 4.406630915090272\n",
      "setting temperature to :2.0000000000000004\n",
      "opt. step : 1500 obj: 4.395024963191785\n",
      "setting temperature to :2.1000000000000005\n",
      "opt. step : 1600 obj: 4.383607761918492\n",
      "setting temperature to :2.2000000000000006\n",
      "opt. step : 1700 obj: 4.3728111606061795\n",
      "setting temperature to :2.3000000000000007\n",
      "---> optimization finished ... \n",
      "temp:\n",
      "2.3651654507864928\n",
      "p_quantile:\n",
      "0.4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x153750850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x153750850>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x153750850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x153750850>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1537507d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1537507d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1537507d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1537507d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "validation CPIT:\n",
      "5.106544869496588\n",
      "best performing model: iteration 0\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15380b650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15380b650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15380b650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15380b650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "------> Training DRM ranking model .... \n",
      "---> running cross validation, iteration: 0\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15380b410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15380b410>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15380b410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15380b410>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15392ebd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15392ebd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15392ebd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15392ebd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "opt. step : 0 obj: 4.867649044989535\n",
      "opt. step : 100 obj: 4.700946381407529\n",
      "opt. step : 200 obj: 4.5698945765951695\n",
      "opt. step : 300 obj: 4.492607722388605\n",
      "opt. step : 400 obj: 4.440631561411302\n",
      "opt. step : 500 obj: 4.373943798506487\n",
      "opt. step : 600 obj: 4.326327288435995\n",
      "opt. step : 700 obj: 4.287439510081942\n",
      "opt. step : 800 obj: 4.255312156598836\n",
      "opt. step : 900 obj: 4.221192019375819\n",
      "opt. step : 1000 obj: 4.192462650577215\n",
      "opt. step : 1100 obj: 4.169030148031053\n",
      "opt. step : 1200 obj: 4.149592117920924\n",
      "opt. step : 1300 obj: 4.13316209928851\n",
      "opt. step : 1400 obj: 4.11891324092702\n",
      "opt. step : 1500 obj: 4.106321253837462\n",
      "opt. step : 1600 obj: 4.095036076305176\n",
      "opt. step : 1700 obj: 4.084804598125603\n",
      "---> optimization finished ... \n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x157303b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x157303b50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x157303b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x157303b50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15720a050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15720a050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15720a050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15720a050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "validation CPIT:\n",
      "5.4456332429454575\n",
      "---> running cross validation, iteration: 1\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x157455c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x157455c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x157455c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x157455c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15747b2d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15747b2d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15747b2d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15747b2d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "opt. step : 0 obj: 4.81216244583293\n",
      "opt. step : 100 obj: 4.64704663184805\n",
      "opt. step : 200 obj: 4.468202764974882\n",
      "opt. step : 300 obj: 4.33749157041729\n",
      "opt. step : 400 obj: 4.249294839118934\n",
      "opt. step : 500 obj: 4.202323537438153\n",
      "opt. step : 600 obj: 4.165646763440499\n",
      "opt. step : 700 obj: 4.137054158393313\n",
      "opt. step : 800 obj: 4.113647600107275\n",
      "opt. step : 900 obj: 4.093020027648886\n",
      "opt. step : 1000 obj: 4.073648508131135\n",
      "opt. step : 1100 obj: 4.054384981216349\n",
      "opt. step : 1200 obj: 4.036074063959198\n",
      "opt. step : 1300 obj: 4.019067281309364\n",
      "opt. step : 1400 obj: 4.003902887113532\n",
      "opt. step : 1500 obj: 3.9905234557505325\n",
      "opt. step : 1600 obj: 3.9785363243072243\n",
      "opt. step : 1700 obj: 3.9676174771565162\n",
      "---> optimization finished ... \n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15921fbd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15921fbd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15921fbd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15921fbd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15912b0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15912b0d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15912b0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15912b0d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "validation CPIT:\n",
      "5.235777605146764\n",
      "best performing model: iteration 1\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1592b9c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1592b9c90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1592b9c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1592b9c90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "### code implements ranking model for treatment effect \n",
    "### for optimizing with respect to direct marketplace objectives \n",
    "### using tensorflow \n",
    "\n",
    "import numpy as np, tensorflow as tf, pandas as pd, pickle as pkl \n",
    "sys.path.append('../')  \n",
    "from ModelDefinitions import * \n",
    "from DataProcFunctions import * \n",
    "\n",
    "### RxGy TQR setting: \n",
    "p_quantile = 0.4 ## percentage of quantile to aim for \n",
    "num_optimize_iterations = 1800 ## number of optimization iterations \n",
    "num_modeling_inits = 2 ## number of random initializations \n",
    "num_hidden = 0 ## number of hidden units in DNN \n",
    "use_schedule = True ## option to use a constraint annealing schedule \n",
    "temp = 0.5 ## initial temperature for constraints \n",
    "inc_temp = 0.1 ## increment of temperature per 100 iterations \n",
    "save_cf_data = False ### whether to save data for causal forest training \n",
    "\n",
    "## set a random seed to reproduce results \n",
    "seed = 1234; tf.compat.v2.random.set_seed(seed); np.random.seed(seed) \n",
    "\n",
    "sample_frac = 1.0 ## option to sample data by a fraction \\in (0, 1) \n",
    "data_filename =  '../data/rxgy_ma_training_data_v5_2019_07_08_vc_tr_featuremod3' \n",
    "prefix = 'rxgy_v5_07_08_featuremod3_tr_iter100_run4' \n",
    "\n",
    "D_tre, D_unt, Dv_tre, Dv_unt, Dt_tre, Dt_unt, o_tre, o_unt, ov_tre, ov_unt, ot_tre, ot_unt, c_tre, c_unt, cv_tre, cv_unt, ct_tre, ct_unt, D, w, o, c, Dv, wv, ov, cv, Dt, wt, ot, ct = LoadDataFromPkl(data_filename, frac = sample_frac, save_cf_data=save_cf_data) \n",
    "\n",
    "print('### ----- start the training of deep learning models ------ ') \n",
    "gs_tqr = [] \n",
    "gs_drm = [] \n",
    "for i in range(num_modeling_inits): \n",
    "    gs_tqr.append(tf.Graph()) \n",
    "for i in range(num_modeling_inits): \n",
    "    gs_drm.append(tf.Graph()) \n",
    "\n",
    "print('------> Training TQR ranking model .... ') \n",
    "val_results = [] \n",
    "sess_list = [] \n",
    "for i in range(num_modeling_inits): \n",
    "    print('---> running cross validation, iteration: ' + str(i)) \n",
    "    obj, opt, dumh, dumhu, vtemp, p_quantile = TunableTQRankingModelDNN(gs_tqr[i], D_tre, D_unt, o_tre, o_unt, c_tre, c_unt, 'train-first', temp, p_quantile, num_hidden, use_schedule) \n",
    "    ### session definitions and variable initialization \n",
    "    sess = tf.Session(graph = gs_tqr[i]) \n",
    "    sess_list.append(sess) \n",
    "    \n",
    "    ### initialize variables and run optimization \n",
    "    with gs_tqr[i].as_default() as g: \n",
    "        init = tf.global_variables_initializer() \n",
    "    sess.run(init) \n",
    "    cur_temp = temp \n",
    "    for step in range(num_optimize_iterations): \n",
    "        _, objres = sess.run([opt, obj]) \n",
    "        if step % 100 == 0: \n",
    "            cur_temp = cur_temp + inc_temp \n",
    "            print('opt. step : ' + str(step) + ' obj: ' + str(objres)) \n",
    "            if use_schedule: \n",
    "                sess.run(vtemp.assign(cur_temp))\n",
    "                print('setting temperature to :' + str(sess.run(vtemp))) \n",
    "    \n",
    "    print('---> optimization finished ... ') \n",
    "    tempvalue = sess.run(vtemp)\n",
    "    p_quantilevalue = p_quantile\n",
    "    print('temp:') \n",
    "    print(tempvalue)\n",
    "    print('p_quantile:')\n",
    "    print(p_quantilevalue) \n",
    "    \n",
    "    ### evaluate CPIT metric on validation set \n",
    "    objv, dumo, dumh, dumhu, dvtemp, dp_quantile = TunableTQRankingModelDNN(gs_tqr[i], Dv_tre, Dv_unt, ov_tre, ov_unt, cv_tre, cv_unt, 'eval', temp, p_quantile, num_hidden, use_schedule) \n",
    "    \n",
    "    val_result = sess.run(objv) \n",
    "    print('validation CPIT:') \n",
    "    print(val_result) \n",
    "    val_results.append(val_result) \n",
    "\n",
    "from operator import itemgetter \n",
    "best_index = min(enumerate(val_results), key=itemgetter(1))[0] \n",
    "\n",
    "print('best performing model: iteration ' + str(best_index)) \n",
    "\n",
    "### run scoring on whole test set \n",
    "with gs_tqr[best_index].as_default() as g: \n",
    "    if num_hidden > 0: \n",
    "        with tf.variable_scope(\"tqrhidden\") as scope: \n",
    "            h1_test = tf.contrib.layers.fully_connected(Dt, num_hidden, activation_fn=tf.nn.tanh, reuse=tf.AUTO_REUSE, scope=scope, weights_initializer=tf.contrib.layers.xavier_initializer()) \n",
    "        with tf.variable_scope(\"tqranker\") as scope: \n",
    "            h_test = tf.contrib.layers.fully_connected(h1_test, 1, activation_fn=None, reuse=tf.AUTO_REUSE, scope=scope) \n",
    "    else: \n",
    "        with tf.variable_scope(\"tqranker\") as scope: \n",
    "            h_test = tf.contrib.layers.fully_connected(Dt, 1, activation_fn=None, reuse=tf.AUTO_REUSE, scope=scope) \n",
    "    tqrscore = sess_list[best_index].run(h_test) \n",
    "\n",
    "print('------> Training DRM ranking model .... ') \n",
    "sess_list = [] \n",
    "val_results = [] \n",
    "for i in range(num_modeling_inits): \n",
    "    print('---> running cross validation, iteration: ' + str(i)) \n",
    "    ### ---- train cpit ranking model for comparison --- \n",
    "    dobjc, doptc, ddumh, ddumu = DirectRankingModelDNN(gs_drm[i], D_tre, D_unt, o_tre, o_unt, c_tre, c_unt, 'train-first-drm', num_hidden) \n",
    "    \n",
    "    dsess = tf.Session(graph = gs_drm[i]) \n",
    "    sess_list.append(dsess) \n",
    "    \n",
    "    ### initialize variables and run optimization \n",
    "    with gs_drm[i].as_default() as g: \n",
    "        dinit = tf.global_variables_initializer() \n",
    "    dsess.run(dinit) \n",
    "    for step in range(num_optimize_iterations): \n",
    "        _, dobjres = dsess.run([doptc, dobjc]) \n",
    "        if step % 100 == 0: \n",
    "            print('opt. step : ' + str(step) + ' obj: ' + str(dobjres)) \n",
    "    \n",
    "    print('---> optimization finished ... ') \n",
    "    \n",
    "    ### evaluate CPIT metric on validation set \n",
    "    dobjv, ddumo, dumh, dumhu = DirectRankingModelDNN(gs_drm[i], Dv_tre, Dv_unt, ov_tre, ov_unt, cv_tre, cv_unt, 'eval', num_hidden)\n",
    "    val_result = dsess.run(dobjv) \n",
    "    print('validation CPIT:') \n",
    "    print(val_result) \n",
    "    val_results.append(val_result) \n",
    "\n",
    "best_index = min(enumerate(val_results), key=itemgetter(1))[0] \n",
    "\n",
    "print('best performing model: iteration ' + str(best_index)) \n",
    "\n",
    "### run scoring on whole test set \n",
    "with gs_drm[best_index].as_default() as g: \n",
    "    if num_hidden > 0: \n",
    "        with tf.variable_scope(\"drmhidden\") as scope: \n",
    "            h1_test = tf.contrib.layers.fully_connected(Dt, num_hidden, activation_fn=tf.nn.tanh, reuse=tf.AUTO_REUSE, scope=scope, weights_initializer=tf.contrib.layers.xavier_initializer()) \n",
    "        with tf.variable_scope(\"drmranker\") as scope: \n",
    "            h_test = tf.contrib.layers.fully_connected(h1_test, 1, activation_fn=tf.nn.tanh, reuse=tf.AUTO_REUSE, scope=scope) \n",
    "    else: \n",
    "        with tf.variable_scope(\"drmranker\") as scope: \n",
    "            h_test = tf.contrib.layers.fully_connected(Dt, 1, activation_fn=tf.nn.tanh, reuse=tf.AUTO_REUSE, scope=scope) \n",
    "    drmscore = sess_list[best_index].run(h_test) \n",
    "\n",
    "### ---- train hte model for comparison ---- \n",
    "### we could utimize the original HTE functions \n",
    "from LinearHTEModels import * \n",
    "from PromotionModels import PromotionModels \n",
    "\n",
    "pmodels = PromotionModels() \n",
    "\n",
    "## set-up RLearner \n",
    "rl_ridge_model_O, rl_ridge_model_C = pmodels.fit_rlearner(D, o, c, w) \n",
    "\n",
    "## one model for order lift and one model for cost drop \n",
    "pred_values_va_rlearner_O = rl_ridge_model_O.predict(Dt) \n",
    "pred_values_va_rlearner_C = rl_ridge_model_C.predict(Dt) \n",
    "\n",
    "#if ranking_model == 'effectiveness-ratio': ## if we use the effectiveness ratio model, compute effectiveness ratio \n",
    "pred_values_va_rlearner = np.divide(np.maximum(pred_values_va_rlearner_O, 0), pred_values_va_rlearner_C + 1e-7) \n",
    "\n",
    "lhmodels = LinearHTEModels() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rpu_control: 0.024955679803627437\n",
      "nipu_control: -0.06613553318209264\n",
      "rpu_ft: 0.05033382262417728\n",
      "nipu_ft: -0.18239633989525222\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.10\n",
      "treated_target_rpu: 0.05\n",
      "treated_target_nipu: -0.15\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.05\n",
      "treated_nontarget_nipu: -0.19\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.07\n",
      "--- with 9.998144626374136% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 3.9784139669968948\n",
      "--> in non-targeted users: \n",
      "cpit = 4.643584935584747\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.03\n",
      "nipu_cohort: -0.07\n",
      "lift targeted cohort vs control: 0.09\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 3.96\n",
      "lift targeted-treated vs control: 0.99\n",
      "cpit cohort: 3.963470\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.20\n",
      "treated_target_rpu: 0.05\n",
      "treated_target_nipu: -0.18\n",
      "nontreated_target_rpu: 0.02\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.05\n",
      "treated_nontarget_nipu: -0.18\n",
      "nontreated_nontarget_rpu: 0.03\n",
      "nontreated_nontarget_nipu: -0.07\n",
      "--- with 19.996289252748273% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.553795422236258\n",
      "--> in non-targeted users: \n",
      "cpit = 4.59014677827382\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.03\n",
      "nipu_cohort: -0.09\n",
      "lift targeted cohort vs control: 0.22\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.55\n",
      "lift targeted-treated vs control: 1.02\n",
      "cpit cohort: 4.551145\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.30\n",
      "treated_target_rpu: 0.05\n",
      "treated_target_nipu: -0.17\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.05\n",
      "treated_nontarget_nipu: -0.19\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.07\n",
      "--- with 29.994433879122408% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.515573015334614\n",
      "--> in non-targeted users: \n",
      "cpit = 4.61635564380841\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.03\n",
      "nipu_cohort: -0.10\n",
      "lift targeted cohort vs control: 0.29\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.51\n",
      "lift targeted-treated vs control: 1.02\n",
      "cpit cohort: 4.506069\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.40\n",
      "treated_target_rpu: 0.05\n",
      "treated_target_nipu: -0.18\n",
      "nontreated_target_rpu: 0.02\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.05\n",
      "treated_nontarget_nipu: -0.19\n",
      "nontreated_nontarget_rpu: 0.03\n",
      "nontreated_nontarget_nipu: -0.07\n",
      "--- with 39.992578505496546% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.70557086817449\n",
      "--> in non-targeted users: \n",
      "cpit = 4.49886944251735\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.04\n",
      "nipu_cohort: -0.11\n",
      "lift targeted cohort vs control: 0.42\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.70\n",
      "lift targeted-treated vs control: 0.99\n",
      "cpit cohort: 4.701748\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.50\n",
      "treated_target_rpu: 0.05\n",
      "treated_target_nipu: -0.18\n",
      "nontreated_target_rpu: 0.02\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.05\n",
      "treated_nontarget_nipu: -0.18\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.07\n",
      "--- with 49.99072313187068% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.6123762637974695\n",
      "--> in non-targeted users: \n",
      "cpit = 4.555194826040126\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.04\n",
      "nipu_cohort: -0.13\n",
      "lift targeted cohort vs control: 0.53\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.61\n",
      "lift targeted-treated vs control: 1.07\n",
      "cpit cohort: 4.608251\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.60\n",
      "treated_target_rpu: 0.05\n",
      "treated_target_nipu: -0.19\n",
      "nontreated_target_rpu: 0.02\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.05\n",
      "treated_nontarget_nipu: -0.18\n",
      "nontreated_nontarget_rpu: 0.03\n",
      "nontreated_nontarget_nipu: -0.07\n",
      "--- with 59.988867758244815% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.551653718868227\n",
      "--> in non-targeted users: \n",
      "cpit = 4.641250977785974\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.04\n",
      "nipu_cohort: -0.14\n",
      "lift targeted cohort vs control: 0.65\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.55\n",
      "lift targeted-treated vs control: 1.07\n",
      "cpit cohort: 4.550116\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.70\n",
      "treated_target_rpu: 0.05\n",
      "treated_target_nipu: -0.18\n",
      "nontreated_target_rpu: 0.02\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.05\n",
      "treated_nontarget_nipu: -0.18\n",
      "nontreated_nontarget_rpu: 0.03\n",
      "nontreated_nontarget_nipu: -0.07\n",
      "--- with 69.98701238461895% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.555106161146925\n",
      "--> in non-targeted users: \n",
      "cpit = 4.660789913417077\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.04\n",
      "nipu_cohort: -0.15\n",
      "lift targeted cohort vs control: 0.74\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.55\n",
      "lift targeted-treated vs control: 1.05\n",
      "cpit cohort: 4.553374\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.80\n",
      "treated_target_rpu: 0.05\n",
      "treated_target_nipu: -0.19\n",
      "nontreated_target_rpu: 0.02\n",
      "nontreated_target_nipu: -0.07\n",
      "treated_nontarget_rpu: 0.05\n",
      "treated_nontarget_nipu: -0.17\n",
      "nontreated_nontarget_rpu: 0.03\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 79.98515701099309% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.383066288448293\n",
      "--> in non-targeted users: \n",
      "cpit = 5.621285216985178\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.05\n",
      "nipu_cohort: -0.16\n",
      "lift targeted cohort vs control: 0.86\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.39\n",
      "lift targeted-treated vs control: 1.05\n",
      "cpit cohort: 4.387470\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.90\n",
      "treated_target_rpu: 0.05\n",
      "treated_target_nipu: -0.18\n",
      "nontreated_target_rpu: 0.02\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.05\n",
      "treated_nontarget_nipu: -0.19\n",
      "nontreated_nontarget_rpu: 0.03\n",
      "nontreated_nontarget_nipu: -0.08\n",
      "--- with 89.98330163736723% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.336458054567183\n",
      "--> in non-targeted users: \n",
      "cpit = 9.243717063959485\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.05\n",
      "nipu_cohort: -0.17\n",
      "lift targeted cohort vs control: 0.97\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.34\n",
      "lift targeted-treated vs control: 1.03\n",
      "cpit cohort: 4.338600\n",
      "rpu_cohort\n",
      "0.04906650007603442\n",
      "treated_target_rpu\n",
      "0.050343357802510064\n",
      "---------------------------->>>>>>\n",
      "perc - target: 1.00\n",
      "treated_target_rpu: 0.05\n",
      "treated_target_nipu: -0.18\n",
      "nontreated_target_rpu: 0.02\n",
      "nontreated_target_nipu: -0.07\n",
      "treated_nontarget_rpu: 0.00\n",
      "treated_nontarget_nipu: 0.00\n",
      "nontreated_nontarget_rpu: 0.00\n",
      "nontreated_nontarget_nipu: 0.00\n",
      "--- with 99.98144626374136% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.58112488224986\n",
      "--> in non-targeted users: \n",
      "cpit = nan\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.05\n",
      "nipu_cohort: -0.18\n",
      "lift targeted cohort vs control: 1.02\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.58\n",
      "lift targeted-treated vs control: 1.02\n",
      "cpit cohort: 4.580780\n",
      "rpu_control: 0.024955679803627437\n",
      "nipu_control: -0.06613553318209264\n",
      "rpu_ft: 0.05033382262417728\n",
      "nipu_ft: -0.18239633989525222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../experimentation.py:154: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cpit_nontargeted = -1.0 * (treated_untarget_nipu - untreated_untarget_nipu) / (treated_untarget_rpu - untreated_untarget_rpu)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------->>>>>>\n",
      "perc - target: 0.10\n",
      "treated_target_rpu: 0.10\n",
      "treated_target_nipu: -0.34\n",
      "nontreated_target_rpu: 0.02\n",
      "nontreated_target_nipu: -0.05\n",
      "treated_nontarget_rpu: 0.05\n",
      "treated_nontarget_nipu: -0.16\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.07\n",
      "--- with 9.998144626374136% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.055389015990013\n",
      "--> in non-targeted users: \n",
      "cpit = 4.793403709923443\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.03\n",
      "nipu_cohort: -0.10\n",
      "lift targeted cohort vs control: 0.29\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.06\n",
      "lift targeted-treated vs control: 2.90\n",
      "cpit cohort: 4.055124\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.20\n",
      "treated_target_rpu: 0.08\n",
      "treated_target_nipu: -0.29\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.07\n",
      "treated_nontarget_rpu: 0.04\n",
      "treated_nontarget_nipu: -0.16\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.07\n",
      "--- with 19.996289252748273% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.493287397645291\n",
      "--> in non-targeted users: \n",
      "cpit = 4.636174637174749\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.03\n",
      "nipu_cohort: -0.11\n",
      "lift targeted cohort vs control: 0.40\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.49\n",
      "lift targeted-treated vs control: 2.17\n",
      "cpit cohort: 4.494366\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.30\n",
      "treated_target_rpu: 0.07\n",
      "treated_target_nipu: -0.25\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.07\n",
      "treated_nontarget_rpu: 0.04\n",
      "treated_nontarget_nipu: -0.15\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 29.994433879122408% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.126500246581984\n",
      "--> in non-targeted users: \n",
      "cpit = 5.0474078876922945\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.04\n",
      "nipu_cohort: -0.12\n",
      "lift targeted cohort vs control: 0.51\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.13\n",
      "lift targeted-treated vs control: 1.87\n",
      "cpit cohort: 4.125937\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.40\n",
      "treated_target_rpu: 0.07\n",
      "treated_target_nipu: -0.24\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.08\n",
      "treated_nontarget_rpu: 0.04\n",
      "treated_nontarget_nipu: -0.14\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 39.992578505496546% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.036343757333638\n",
      "--> in non-targeted users: \n",
      "cpit = 5.598592816284086\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.04\n",
      "nipu_cohort: -0.13\n",
      "lift targeted cohort vs control: 0.66\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.04\n",
      "lift targeted-treated vs control: 1.77\n",
      "cpit cohort: 4.036175\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.50\n",
      "treated_target_rpu: 0.07\n",
      "treated_target_nipu: -0.24\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.08\n",
      "treated_nontarget_rpu: 0.04\n",
      "treated_nontarget_nipu: -0.13\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.05\n",
      "--- with 49.99072313187068% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.341653681929257\n",
      "--> in non-targeted users: \n",
      "cpit = 5.217767237188109\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.04\n",
      "nipu_cohort: -0.15\n",
      "lift targeted cohort vs control: 0.73\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.34\n",
      "lift targeted-treated vs control: 1.62\n",
      "cpit cohort: 4.340776\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.60\n",
      "treated_target_rpu: 0.06\n",
      "treated_target_nipu: -0.23\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.07\n",
      "treated_nontarget_rpu: 0.03\n",
      "treated_nontarget_nipu: -0.11\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.05\n",
      "--- with 59.988867758244815% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.438899686854332\n",
      "--> in non-targeted users: \n",
      "cpit = 5.21866988382684\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.05\n",
      "nipu_cohort: -0.16\n",
      "lift targeted cohort vs control: 0.82\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.44\n",
      "lift targeted-treated vs control: 1.47\n",
      "cpit cohort: 4.437869\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.70\n",
      "treated_target_rpu: 0.06\n",
      "treated_target_nipu: -0.21\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.08\n",
      "treated_nontarget_rpu: 0.03\n",
      "treated_nontarget_nipu: -0.11\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.04\n",
      "--- with 69.98701238461895% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.472806213165054\n",
      "--> in non-targeted users: \n",
      "cpit = 5.175797790534578\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.05\n",
      "nipu_cohort: -0.16\n",
      "lift targeted cohort vs control: 0.85\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.47\n",
      "lift targeted-treated vs control: 1.30\n",
      "cpit cohort: 4.472988\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.80\n",
      "treated_target_rpu: 0.05\n",
      "treated_target_nipu: -0.20\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.07\n",
      "treated_nontarget_rpu: 0.03\n",
      "treated_nontarget_nipu: -0.10\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.04\n",
      "--- with 79.98515701099309% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.657123705837306\n",
      "--> in non-targeted users: \n",
      "cpit = 4.013044466683142\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.05\n",
      "nipu_cohort: -0.17\n",
      "lift targeted cohort vs control: 0.90\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.65\n",
      "lift targeted-treated vs control: 1.20\n",
      "cpit cohort: 4.654098\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.90\n",
      "treated_target_rpu: 0.05\n",
      "treated_target_nipu: -0.20\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.07\n",
      "treated_nontarget_rpu: 0.02\n",
      "treated_nontarget_nipu: -0.05\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.05\n",
      "--- with 89.98330163736723% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.66694564362988\n",
      "--> in non-targeted users: \n",
      "cpit = 0.7709497421680909\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.05\n",
      "nipu_cohort: -0.18\n",
      "lift targeted cohort vs control: 0.99\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.67\n",
      "lift targeted-treated vs control: 1.13\n",
      "cpit cohort: 4.665427\n",
      "rpu_cohort\n",
      "0.04970807642531934\n",
      "treated_target_rpu\n",
      "0.050343357802510064\n",
      "---------------------------->>>>>>\n",
      "perc - target: 1.00\n",
      "treated_target_rpu: 0.05\n",
      "treated_target_nipu: -0.18\n",
      "nontreated_target_rpu: 0.02\n",
      "nontreated_target_nipu: -0.07\n",
      "treated_nontarget_rpu: 0.00\n",
      "treated_nontarget_nipu: 0.00\n",
      "nontreated_nontarget_rpu: 0.00\n",
      "nontreated_nontarget_nipu: 0.00\n",
      "--- with 99.98144626374136% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.58112488224986\n",
      "--> in non-targeted users: \n",
      "cpit = nan\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.05\n",
      "nipu_cohort: -0.18\n",
      "lift targeted cohort vs control: 1.02\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.58\n",
      "lift targeted-treated vs control: 1.02\n",
      "cpit cohort: 4.580780\n",
      "rpu_control: 0.024955679803627437\n",
      "nipu_control: -0.06613553318209264\n",
      "rpu_ft: 0.05033382262417728\n",
      "nipu_ft: -0.18239633989525222\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.10\n",
      "treated_target_rpu: 0.03\n",
      "treated_target_nipu: -0.07\n",
      "nontreated_target_rpu: 0.02\n",
      "nontreated_target_nipu: -0.05\n",
      "treated_nontarget_rpu: 0.05\n",
      "treated_nontarget_nipu: -0.19\n",
      "nontreated_nontarget_rpu: 0.03\n",
      "nontreated_nontarget_nipu: -0.07\n",
      "--- with 9.998144626374136% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 2.5988411709547083\n",
      "--> in non-targeted users: \n",
      "cpit = 4.667630571260675\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.03\n",
      "nipu_cohort: -0.07\n",
      "lift targeted cohort vs control: 0.04\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 2.59\n",
      "lift targeted-treated vs control: 0.08\n",
      "cpit cohort: 2.591810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------->>>>>>\n",
      "perc - target: 0.20\n",
      "treated_target_rpu: 0.03\n",
      "treated_target_nipu: -0.08\n",
      "nontreated_target_rpu: 0.02\n",
      "nontreated_target_nipu: -0.04\n",
      "treated_nontarget_rpu: 0.05\n",
      "treated_nontarget_nipu: -0.21\n",
      "nontreated_nontarget_rpu: 0.03\n",
      "nontreated_nontarget_nipu: -0.07\n",
      "--- with 19.996289252748273% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 2.8613066067560693\n",
      "--> in non-targeted users: \n",
      "cpit = 4.81431686679357\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.03\n",
      "nipu_cohort: -0.07\n",
      "lift targeted cohort vs control: 0.12\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 2.86\n",
      "lift targeted-treated vs control: 0.25\n",
      "cpit cohort: 2.861499\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.30\n",
      "treated_target_rpu: 0.03\n",
      "treated_target_nipu: -0.11\n",
      "nontreated_target_rpu: 0.02\n",
      "nontreated_target_nipu: -0.05\n",
      "treated_nontarget_rpu: 0.06\n",
      "treated_nontarget_nipu: -0.21\n",
      "nontreated_nontarget_rpu: 0.03\n",
      "nontreated_nontarget_nipu: -0.07\n",
      "--- with 29.994433879122408% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.515589166523719\n",
      "--> in non-targeted users: \n",
      "cpit = 4.600964368420093\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.03\n",
      "nipu_cohort: -0.08\n",
      "lift targeted cohort vs control: 0.15\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.49\n",
      "lift targeted-treated vs control: 0.29\n",
      "cpit cohort: 4.490612\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.40\n",
      "treated_target_rpu: 0.04\n",
      "treated_target_nipu: -0.12\n",
      "nontreated_target_rpu: 0.02\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.06\n",
      "treated_nontarget_nipu: -0.22\n",
      "nontreated_nontarget_rpu: 0.03\n",
      "nontreated_nontarget_nipu: -0.07\n",
      "--- with 39.992578505496546% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.649742463219109\n",
      "--> in non-targeted users: \n",
      "cpit = 4.569634488522924\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.03\n",
      "nipu_cohort: -0.09\n",
      "lift targeted cohort vs control: 0.23\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.64\n",
      "lift targeted-treated vs control: 0.41\n",
      "cpit cohort: 4.635352\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.50\n",
      "treated_target_rpu: 0.04\n",
      "treated_target_nipu: -0.13\n",
      "nontreated_target_rpu: 0.02\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.06\n",
      "treated_nontarget_nipu: -0.23\n",
      "nontreated_nontarget_rpu: 0.03\n",
      "nontreated_nontarget_nipu: -0.08\n",
      "--- with 49.99072313187068% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 5.672334023539817\n",
      "--> in non-targeted users: \n",
      "cpit = 4.195162283908503\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.03\n",
      "nipu_cohort: -0.10\n",
      "lift targeted cohort vs control: 0.27\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 5.66\n",
      "lift targeted-treated vs control: 0.42\n",
      "cpit cohort: 5.663418\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.60\n",
      "treated_target_rpu: 0.04\n",
      "treated_target_nipu: -0.14\n",
      "nontreated_target_rpu: 0.02\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.07\n",
      "treated_nontarget_nipu: -0.24\n",
      "nontreated_nontarget_rpu: 0.03\n",
      "nontreated_nontarget_nipu: -0.08\n",
      "--- with 59.988867758244815% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 5.161770570754408\n",
      "--> in non-targeted users: \n",
      "cpit = 4.229165158407126\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.03\n",
      "nipu_cohort: -0.12\n",
      "lift targeted cohort vs control: 0.39\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 5.16\n",
      "lift targeted-treated vs control: 0.54\n",
      "cpit cohort: 5.160586\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.70\n",
      "treated_target_rpu: 0.04\n",
      "treated_target_nipu: -0.15\n",
      "nontreated_target_rpu: 0.02\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.07\n",
      "treated_nontarget_nipu: -0.26\n",
      "nontreated_nontarget_rpu: 0.03\n",
      "nontreated_nontarget_nipu: -0.08\n",
      "--- with 69.98701238461895% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.755770270110642\n",
      "--> in non-targeted users: \n",
      "cpit = 4.402353559953749\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.04\n",
      "nipu_cohort: -0.13\n",
      "lift targeted cohort vs control: 0.52\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.75\n",
      "lift targeted-treated vs control: 0.61\n",
      "cpit cohort: 4.754500\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.80\n",
      "treated_target_rpu: 0.04\n",
      "treated_target_nipu: -0.16\n",
      "nontreated_target_rpu: 0.02\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.08\n",
      "treated_nontarget_nipu: -0.29\n",
      "nontreated_nontarget_rpu: 0.03\n",
      "nontreated_nontarget_nipu: -0.07\n",
      "--- with 79.98515701099309% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.493894513862778\n",
      "--> in non-targeted users: \n",
      "cpit = 4.720959658060034\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.04\n",
      "nipu_cohort: -0.14\n",
      "lift targeted cohort vs control: 0.65\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.50\n",
      "lift targeted-treated vs control: 0.74\n",
      "cpit cohort: 4.498508\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.90\n",
      "treated_target_rpu: 0.05\n",
      "treated_target_nipu: -0.17\n",
      "nontreated_target_rpu: 0.02\n",
      "nontreated_target_nipu: -0.07\n",
      "treated_nontarget_rpu: 0.09\n",
      "treated_nontarget_nipu: -0.34\n",
      "nontreated_nontarget_rpu: 0.03\n",
      "nontreated_nontarget_nipu: -0.05\n",
      "--- with 89.98330163736723% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.675588753265491\n",
      "--> in non-targeted users: \n",
      "cpit = 4.315724663898128\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.04\n",
      "nipu_cohort: -0.15\n",
      "lift targeted cohort vs control: 0.75\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.68\n",
      "lift targeted-treated vs control: 0.83\n",
      "cpit cohort: 4.675329\n",
      "rpu_cohort\n",
      "0.043704929360636975\n",
      "treated_target_rpu\n",
      "0.050348126746554256\n",
      "---------------------------->>>>>>\n",
      "perc - target: 1.00\n",
      "treated_target_rpu: 0.05\n",
      "treated_target_nipu: -0.18\n",
      "nontreated_target_rpu: 0.02\n",
      "nontreated_target_nipu: -0.07\n",
      "treated_nontarget_rpu: 0.00\n",
      "treated_nontarget_nipu: 0.00\n",
      "nontreated_nontarget_rpu: 0.00\n",
      "nontreated_nontarget_nipu: 0.00\n",
      "--- with 99.98144626374136% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.580772462094338\n",
      "--> in non-targeted users: \n",
      "cpit = nan\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.05\n",
      "nipu_cohort: -0.18\n",
      "lift targeted cohort vs control: 1.02\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.58\n",
      "lift targeted-treated vs control: 1.02\n",
      "cpit cohort: 4.580600\n",
      "rpu_control: 0.024955679803627437\n",
      "nipu_control: -0.06613553318209264\n",
      "rpu_ft: 0.05033382262417728\n",
      "nipu_ft: -0.18239633989525222\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.10\n",
      "treated_target_rpu: 0.09\n",
      "treated_target_nipu: -0.34\n",
      "nontreated_target_rpu: 0.02\n",
      "nontreated_target_nipu: -0.05\n",
      "treated_nontarget_rpu: 0.05\n",
      "treated_nontarget_nipu: -0.17\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.07\n",
      "--- with 9.998144626374136% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.126602851693508\n",
      "--> in non-targeted users: \n",
      "cpit = 4.745459113182901\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.03\n",
      "nipu_cohort: -0.09\n",
      "lift targeted cohort vs control: 0.27\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.13\n",
      "lift targeted-treated vs control: 2.72\n",
      "cpit cohort: 4.127664\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.20\n",
      "treated_target_rpu: 0.08\n",
      "treated_target_nipu: -0.29\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.08\n",
      "treated_nontarget_rpu: 0.04\n",
      "treated_nontarget_nipu: -0.16\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 19.996289252748273% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.210897430160445\n",
      "--> in non-targeted users: \n",
      "cpit = 4.82751096248172\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.04\n",
      "nipu_cohort: -0.11\n",
      "lift targeted cohort vs control: 0.41\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.21\n",
      "lift targeted-treated vs control: 2.21\n",
      "cpit cohort: 4.210711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------->>>>>>\n",
      "perc - target: 0.30\n",
      "treated_target_rpu: 0.07\n",
      "treated_target_nipu: -0.25\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.07\n",
      "treated_nontarget_rpu: 0.04\n",
      "treated_nontarget_nipu: -0.15\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 29.994433879122408% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.126185481560746\n",
      "--> in non-targeted users: \n",
      "cpit = 5.084049816409579\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.04\n",
      "nipu_cohort: -0.12\n",
      "lift targeted cohort vs control: 0.53\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.12\n",
      "lift targeted-treated vs control: 1.88\n",
      "cpit cohort: 4.124651\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.40\n",
      "treated_target_rpu: 0.07\n",
      "treated_target_nipu: -0.24\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.07\n",
      "treated_nontarget_rpu: 0.04\n",
      "treated_nontarget_nipu: -0.14\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 39.992578505496546% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.0004839342664855\n",
      "--> in non-targeted users: \n",
      "cpit = 5.677076082741575\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.04\n",
      "nipu_cohort: -0.13\n",
      "lift targeted cohort vs control: 0.66\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.00\n",
      "lift targeted-treated vs control: 1.71\n",
      "cpit cohort: 4.001120\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.50\n",
      "treated_target_rpu: 0.06\n",
      "treated_target_nipu: -0.24\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.08\n",
      "treated_nontarget_rpu: 0.04\n",
      "treated_nontarget_nipu: -0.13\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.05\n",
      "--- with 49.99072313187068% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.267729294059503\n",
      "--> in non-targeted users: \n",
      "cpit = 5.376393659955047\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.04\n",
      "nipu_cohort: -0.14\n",
      "lift targeted cohort vs control: 0.73\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.27\n",
      "lift targeted-treated vs control: 1.58\n",
      "cpit cohort: 4.268043\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.60\n",
      "treated_target_rpu: 0.06\n",
      "treated_target_nipu: -0.22\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.08\n",
      "treated_nontarget_rpu: 0.03\n",
      "treated_nontarget_nipu: -0.12\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.05\n",
      "--- with 59.988867758244815% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.277256155813009\n",
      "--> in non-targeted users: \n",
      "cpit = 5.928156548482625\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.05\n",
      "nipu_cohort: -0.15\n",
      "lift targeted cohort vs control: 0.83\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.28\n",
      "lift targeted-treated vs control: 1.45\n",
      "cpit cohort: 4.278024\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.70\n",
      "treated_target_rpu: 0.06\n",
      "treated_target_nipu: -0.21\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.08\n",
      "treated_nontarget_rpu: 0.03\n",
      "treated_nontarget_nipu: -0.12\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.04\n",
      "--- with 69.98701238461895% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.427677292702189\n",
      "--> in non-targeted users: \n",
      "cpit = 5.272323205815763\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.05\n",
      "nipu_cohort: -0.16\n",
      "lift targeted cohort vs control: 0.83\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.43\n",
      "lift targeted-treated vs control: 1.28\n",
      "cpit cohort: 4.427448\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.80\n",
      "treated_target_rpu: 0.06\n",
      "treated_target_nipu: -0.20\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.07\n",
      "treated_nontarget_rpu: 0.03\n",
      "treated_nontarget_nipu: -0.10\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.03\n",
      "--- with 79.98515701099309% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.6019835812778815\n",
      "--> in non-targeted users: \n",
      "cpit = 4.444656159805293\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.05\n",
      "nipu_cohort: -0.17\n",
      "lift targeted cohort vs control: 0.89\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.60\n",
      "lift targeted-treated vs control: 1.21\n",
      "cpit cohort: 4.600796\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.90\n",
      "treated_target_rpu: 0.05\n",
      "treated_target_nipu: -0.20\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.07\n",
      "treated_nontarget_rpu: 0.02\n",
      "treated_nontarget_nipu: -0.05\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.03\n",
      "--- with 89.98330163736723% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.6062145017572576\n",
      "--> in non-targeted users: \n",
      "cpit = 3.1078245506092244\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.05\n",
      "nipu_cohort: -0.18\n",
      "lift targeted cohort vs control: 1.00\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.61\n",
      "lift targeted-treated vs control: 1.15\n",
      "cpit cohort: 4.605456\n",
      "rpu_cohort\n",
      "0.04987467996764419\n",
      "treated_target_rpu\n",
      "0.050343357802510064\n",
      "---------------------------->>>>>>\n",
      "perc - target: 1.00\n",
      "treated_target_rpu: 0.05\n",
      "treated_target_nipu: -0.18\n",
      "nontreated_target_rpu: 0.02\n",
      "nontreated_target_nipu: -0.07\n",
      "treated_nontarget_rpu: 0.00\n",
      "treated_nontarget_nipu: 0.00\n",
      "nontreated_nontarget_rpu: 0.00\n",
      "nontreated_nontarget_nipu: 0.00\n",
      "--- with 99.98144626374136% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.58112488224986\n",
      "--> in non-targeted users: \n",
      "cpit = nan\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.05\n",
      "nipu_cohort: -0.18\n",
      "lift targeted cohort vs control: 1.02\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.58\n",
      "lift targeted-treated vs control: 1.02\n",
      "cpit cohort: 4.580780\n",
      "rpu_control: 0.024955679803627437\n",
      "nipu_control: -0.06613553318209264\n",
      "rpu_ft: 0.05033382262417728\n",
      "nipu_ft: -0.18239633989525222\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.10\n",
      "treated_target_rpu: 0.10\n",
      "treated_target_nipu: -0.35\n",
      "nontreated_target_rpu: 0.02\n",
      "nontreated_target_nipu: -0.05\n",
      "treated_nontarget_rpu: 0.05\n",
      "treated_nontarget_nipu: -0.16\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.07\n",
      "--- with 9.998144626374136% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.063941124083648\n",
      "--> in non-targeted users: \n",
      "cpit = 4.791854753286991\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.03\n",
      "nipu_cohort: -0.10\n",
      "lift targeted cohort vs control: 0.29\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.06\n",
      "lift targeted-treated vs control: 2.92\n",
      "cpit cohort: 4.063572\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.20\n",
      "treated_target_rpu: 0.08\n",
      "treated_target_nipu: -0.29\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.07\n",
      "treated_nontarget_rpu: 0.04\n",
      "treated_nontarget_nipu: -0.16\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.07\n",
      "--- with 19.996289252748273% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.493800364344013\n",
      "--> in non-targeted users: \n",
      "cpit = 4.634873151848392\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.03\n",
      "nipu_cohort: -0.11\n",
      "lift targeted cohort vs control: 0.40\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.50\n",
      "lift targeted-treated vs control: 2.17\n",
      "cpit cohort: 4.495382\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.30\n",
      "treated_target_rpu: 0.07\n",
      "treated_target_nipu: -0.25\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.07\n",
      "treated_nontarget_rpu: 0.04\n",
      "treated_nontarget_nipu: -0.15\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 29.994433879122408% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.139062742957634\n",
      "--> in non-targeted users: \n",
      "cpit = 5.0379962166569\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.04\n",
      "nipu_cohort: -0.12\n",
      "lift targeted cohort vs control: 0.52\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.14\n",
      "lift targeted-treated vs control: 1.88\n",
      "cpit cohort: 4.138553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------->>>>>>\n",
      "perc - target: 0.40\n",
      "treated_target_rpu: 0.07\n",
      "treated_target_nipu: -0.25\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.08\n",
      "treated_nontarget_rpu: 0.04\n",
      "treated_nontarget_nipu: -0.14\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 39.992578505496546% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.0836705943761356\n",
      "--> in non-targeted users: \n",
      "cpit = 5.501896240396409\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.04\n",
      "nipu_cohort: -0.13\n",
      "lift targeted cohort vs control: 0.65\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.08\n",
      "lift targeted-treated vs control: 1.77\n",
      "cpit cohort: 4.083440\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.50\n",
      "treated_target_rpu: 0.07\n",
      "treated_target_nipu: -0.24\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.08\n",
      "treated_nontarget_rpu: 0.04\n",
      "treated_nontarget_nipu: -0.13\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.05\n",
      "--- with 49.99072313187068% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.33865856124426\n",
      "--> in non-targeted users: \n",
      "cpit = 5.208222730142692\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.04\n",
      "nipu_cohort: -0.14\n",
      "lift targeted cohort vs control: 0.73\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.34\n",
      "lift targeted-treated vs control: 1.61\n",
      "cpit cohort: 4.337748\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.60\n",
      "treated_target_rpu: 0.06\n",
      "treated_target_nipu: -0.23\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.08\n",
      "treated_nontarget_rpu: 0.03\n",
      "treated_nontarget_nipu: -0.12\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.05\n",
      "--- with 59.988867758244815% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.4050943896029775\n",
      "--> in non-targeted users: \n",
      "cpit = 5.349258931702903\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.05\n",
      "nipu_cohort: -0.16\n",
      "lift targeted cohort vs control: 0.82\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.40\n",
      "lift targeted-treated vs control: 1.47\n",
      "cpit cohort: 4.404320\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.70\n",
      "treated_target_rpu: 0.06\n",
      "treated_target_nipu: -0.21\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.08\n",
      "treated_nontarget_rpu: 0.03\n",
      "treated_nontarget_nipu: -0.11\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.04\n",
      "--- with 69.98701238461895% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.481807643260158\n",
      "--> in non-targeted users: \n",
      "cpit = 5.1180389189480815\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.05\n",
      "nipu_cohort: -0.16\n",
      "lift targeted cohort vs control: 0.85\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.48\n",
      "lift targeted-treated vs control: 1.30\n",
      "cpit cohort: 4.481976\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.80\n",
      "treated_target_rpu: 0.05\n",
      "treated_target_nipu: -0.20\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.07\n",
      "treated_nontarget_rpu: 0.03\n",
      "treated_nontarget_nipu: -0.10\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.04\n",
      "--- with 79.98515701099309% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.658636997785827\n",
      "--> in non-targeted users: \n",
      "cpit = 3.9903250536105963\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.05\n",
      "nipu_cohort: -0.17\n",
      "lift targeted cohort vs control: 0.90\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.66\n",
      "lift targeted-treated vs control: 1.20\n",
      "cpit cohort: 4.655977\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.90\n",
      "treated_target_rpu: 0.05\n",
      "treated_target_nipu: -0.20\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.07\n",
      "treated_nontarget_rpu: 0.02\n",
      "treated_nontarget_nipu: -0.05\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.05\n",
      "--- with 89.98330163736723% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.672820149874284\n",
      "--> in non-targeted users: \n",
      "cpit = -0.36623668447820107\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.05\n",
      "nipu_cohort: -0.18\n",
      "lift targeted cohort vs control: 1.00\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.67\n",
      "lift targeted-treated vs control: 1.14\n",
      "cpit cohort: 4.671271\n",
      "rpu_cohort\n",
      "0.04979921446490439\n",
      "treated_target_rpu\n",
      "0.050343357802510064\n",
      "---------------------------->>>>>>\n",
      "perc - target: 1.00\n",
      "treated_target_rpu: 0.05\n",
      "treated_target_nipu: -0.18\n",
      "nontreated_target_rpu: 0.02\n",
      "nontreated_target_nipu: -0.07\n",
      "treated_nontarget_rpu: 0.00\n",
      "treated_nontarget_nipu: 0.00\n",
      "nontreated_nontarget_rpu: 0.00\n",
      "nontreated_nontarget_nipu: 0.00\n",
      "--- with 99.98144626374136% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.58112488224986\n",
      "--> in non-targeted users: \n",
      "cpit = nan\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.05\n",
      "nipu_cohort: -0.18\n",
      "lift targeted cohort vs control: 1.02\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.58\n",
      "lift targeted-treated vs control: 1.02\n",
      "cpit cohort: 4.580780\n",
      "rpu_control: 0.024955679803627437\n",
      "nipu_control: -0.06613553318209264\n",
      "rpu_ft: 0.05033382262417728\n",
      "nipu_ft: -0.18239633989525222\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.10\n",
      "treated_target_rpu: 0.10\n",
      "treated_target_nipu: -0.34\n",
      "nontreated_target_rpu: 0.02\n",
      "nontreated_target_nipu: -0.05\n",
      "treated_nontarget_rpu: 0.05\n",
      "treated_nontarget_nipu: -0.16\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.07\n",
      "--- with 9.998144626374136% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.056674849523036\n",
      "--> in non-targeted users: \n",
      "cpit = 4.792872117245866\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.03\n",
      "nipu_cohort: -0.10\n",
      "lift targeted cohort vs control: 0.29\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.06\n",
      "lift targeted-treated vs control: 2.90\n",
      "cpit cohort: 4.056196\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.20\n",
      "treated_target_rpu: 0.08\n",
      "treated_target_nipu: -0.29\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.07\n",
      "treated_nontarget_rpu: 0.04\n",
      "treated_nontarget_nipu: -0.16\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.07\n",
      "--- with 19.996289252748273% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.491524532211414\n",
      "--> in non-targeted users: \n",
      "cpit = 4.636988548312226\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.03\n",
      "nipu_cohort: -0.11\n",
      "lift targeted cohort vs control: 0.40\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.49\n",
      "lift targeted-treated vs control: 2.17\n",
      "cpit cohort: 4.492891\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.30\n",
      "treated_target_rpu: 0.07\n",
      "treated_target_nipu: -0.25\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.07\n",
      "treated_nontarget_rpu: 0.04\n",
      "treated_nontarget_nipu: -0.15\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 29.994433879122408% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.126500246581984\n",
      "--> in non-targeted users: \n",
      "cpit = 5.0474078876922945\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.04\n",
      "nipu_cohort: -0.12\n",
      "lift targeted cohort vs control: 0.51\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.13\n",
      "lift targeted-treated vs control: 1.87\n",
      "cpit cohort: 4.125937\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.40\n",
      "treated_target_rpu: 0.07\n",
      "treated_target_nipu: -0.24\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.08\n",
      "treated_nontarget_rpu: 0.04\n",
      "treated_nontarget_nipu: -0.14\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 39.992578505496546% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.036144479953882\n",
      "--> in non-targeted users: \n",
      "cpit = 5.59932100138848\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.04\n",
      "nipu_cohort: -0.13\n",
      "lift targeted cohort vs control: 0.66\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.04\n",
      "lift targeted-treated vs control: 1.77\n",
      "cpit cohort: 4.035980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------->>>>>>\n",
      "perc - target: 0.50\n",
      "treated_target_rpu: 0.07\n",
      "treated_target_nipu: -0.24\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.08\n",
      "treated_nontarget_rpu: 0.04\n",
      "treated_nontarget_nipu: -0.13\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.05\n",
      "--- with 49.99072313187068% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.342355982524152\n",
      "--> in non-targeted users: \n",
      "cpit = 5.215504545247538\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.04\n",
      "nipu_cohort: -0.15\n",
      "lift targeted cohort vs control: 0.73\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.34\n",
      "lift targeted-treated vs control: 1.61\n",
      "cpit cohort: 4.341416\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.60\n",
      "treated_target_rpu: 0.06\n",
      "treated_target_nipu: -0.23\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.08\n",
      "treated_nontarget_rpu: 0.03\n",
      "treated_nontarget_nipu: -0.12\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.05\n",
      "--- with 59.988867758244815% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.422296056385127\n",
      "--> in non-targeted users: \n",
      "cpit = 5.291849091902323\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.05\n",
      "nipu_cohort: -0.16\n",
      "lift targeted cohort vs control: 0.82\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.42\n",
      "lift targeted-treated vs control: 1.47\n",
      "cpit cohort: 4.421341\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.70\n",
      "treated_target_rpu: 0.06\n",
      "treated_target_nipu: -0.21\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.08\n",
      "treated_nontarget_rpu: 0.03\n",
      "treated_nontarget_nipu: -0.11\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.04\n",
      "--- with 69.98701238461895% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.472411902980068\n",
      "--> in non-targeted users: \n",
      "cpit = 5.178631876956639\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.05\n",
      "nipu_cohort: -0.16\n",
      "lift targeted cohort vs control: 0.85\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.47\n",
      "lift targeted-treated vs control: 1.30\n",
      "cpit cohort: 4.472594\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.80\n",
      "treated_target_rpu: 0.05\n",
      "treated_target_nipu: -0.20\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.07\n",
      "treated_nontarget_rpu: 0.03\n",
      "treated_nontarget_nipu: -0.10\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.04\n",
      "--- with 79.98515701099309% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.656684594151283\n",
      "--> in non-targeted users: \n",
      "cpit = 4.014879790465632\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.05\n",
      "nipu_cohort: -0.17\n",
      "lift targeted cohort vs control: 0.90\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.65\n",
      "lift targeted-treated vs control: 1.20\n",
      "cpit cohort: 4.653722\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.90\n",
      "treated_target_rpu: 0.05\n",
      "treated_target_nipu: -0.20\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.07\n",
      "treated_nontarget_rpu: 0.02\n",
      "treated_nontarget_nipu: -0.05\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.05\n",
      "--- with 89.98330163736723% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.66694564362988\n",
      "--> in non-targeted users: \n",
      "cpit = 0.7709497421680909\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.05\n",
      "nipu_cohort: -0.18\n",
      "lift targeted cohort vs control: 0.99\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.67\n",
      "lift targeted-treated vs control: 1.13\n",
      "cpit cohort: 4.665427\n",
      "rpu_cohort\n",
      "0.04970807642531934\n",
      "treated_target_rpu\n",
      "0.050343357802510064\n",
      "---------------------------->>>>>>\n",
      "perc - target: 1.00\n",
      "treated_target_rpu: 0.05\n",
      "treated_target_nipu: -0.18\n",
      "nontreated_target_rpu: 0.02\n",
      "nontreated_target_nipu: -0.07\n",
      "treated_nontarget_rpu: 0.00\n",
      "treated_nontarget_nipu: 0.00\n",
      "nontreated_nontarget_rpu: 0.00\n",
      "nontreated_nontarget_nipu: 0.00\n",
      "--- with 99.98144626374136% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.58112488224986\n",
      "--> in non-targeted users: \n",
      "cpit = nan\n",
      "rpu_control: 0.02\n",
      "nipu_control: -0.07\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.05\n",
      "nipu_cohort: -0.18\n",
      "lift targeted cohort vs control: 1.02\n",
      "lift random vs control: 1.02\n",
      "cpit cohort vs control: 4.58\n",
      "lift targeted-treated vs control: 1.02\n",
      "cpit cohort: 4.580780\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ea9524f17969>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mquasiaucc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUC_cpit_cost_curve_deciles_cohort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_values_va_rlearner_O\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mrlearnerauccs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUC_cpit_cost_curve_deciles_cohort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrlearnerscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;31m#cfaucc = exp.AUC_cpit_cost_curve_deciles_cohort(cfscore, ot, wt, -1.0 * ct, 'g') # causal forest aucc and plotting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mtqraucc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUC_cpit_cost_curve_deciles_cohort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqrscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lhmodels = LinearHTEModels() \n",
    "lambds = [1.0, 0.1, 0.01, 0.001, 0.0001] \n",
    "rlearnerscores = [] \n",
    "rl_ridge_model_L_list = [] \n",
    "## set-up lagrangian rlearner \n",
    "for i in range(len(lambds)): \n",
    "    lambd = lambds[i] \n",
    "    rl_ridge_model_L = lhmodels.fit_rlearner_lagrangian(D, o, c, w, lambd) \n",
    "    rl_ridge_model_L_list.append(rl_ridge_model_L) \n",
    "    rlearnerscores.append(rl_ridge_model_L.predict(Dt)) \n",
    "\n",
    "\"\"\" \n",
    "### this section is to load the results trained by grf R code \n",
    "### \n",
    "\n",
    "ot_cf = pd.read_csv('../results/causal_forest_grf_test_set_results_O_finalsize_numtrees1002.csv') \n",
    "ct_cf = pd.read_csv('../results/causal_forest_grf_test_set_results_C_finalsize_numtrees1002.csv') \n",
    "\n",
    "ot_cf = ot_cf.as_matrix() \n",
    "Ocfscores = ot_cf[0] \n",
    "\n",
    "ct_cf = ct_cf.as_matrix() \n",
    "Ccfscores = ct_cf[0] \n",
    "\n",
    "cfscore = np.divide(Ocfscores, Ccfscores) \n",
    "\"\"\" \n",
    "\n",
    "### ---- experimentation and plotting cost-curves ----- \n",
    "from experimentation import * \n",
    "exp = Experimentation() \n",
    "ranscore = np.random.rand(ot.shape[0], ) \n",
    "colors = ['b', 'c', 'g', 'y', 'b', 'c', 'g', 'y', 'b', 'c', 'g', 'y', 'b', 'c', 'g', 'y'] \n",
    "plt.figure() \n",
    "rlearnerauccs = [] \n",
    "ranaucc = exp.AUC_cpit_cost_curve_deciles_cohort(ranscore, ot, wt, -1.0 * ct, 'k', plot_random=True) \n",
    "quasiaucc = exp.AUC_cpit_cost_curve_deciles_cohort(pred_values_va_rlearner_O, ot, wt, -1.0 * ct, 'c') \n",
    "for i in range(len(lambds)): \n",
    "    rlearnerauccs.append(exp.AUC_cpit_cost_curve_deciles_cohort(rlearnerscores[i], ot, wt, -1.0 * ct, colors[i] )) \n",
    "#cfaucc = exp.AUC_cpit_cost_curve_deciles_cohort(cfscore, ot, wt, -1.0 * ct, 'g') # causal forest aucc and plotting \n",
    "tqraucc = exp.AUC_cpit_cost_curve_deciles_cohort(tqrscore, ot, wt, -1.0 * ct, 'r' ) \n",
    "drmaucc = exp.AUC_cpit_cost_curve_deciles_cohort(drmscore, ot, wt, -1.0 * ct, 'm' ) \n",
    "plt.title('Causal learning cost curves using targeting models') \n",
    "\n",
    "### --- saving data to results folder ---- \n",
    "save_filename = '../results/benchmarkwithcv_tqr_drm_hte_'+prefix+'_main_results.pkl' \n",
    "saveD = {'tqrscore':tqrscore, 'drmscore':drmscore, 'quasiscore':pred_values_va_rlearner, 'quasiscore_O':pred_values_va_rlearner_O, 'rlearnerscore':rlearnerscores, 'ot':ot, 'wt':wt, 'ct':ct, 'tempvalue':tempvalue, 'p_quantilevalue':p_quantilevalue, \n",
    "         'tqraucc':tqraucc, 'drmaucc':drmaucc, 'rlearnerauccs':rlearnerauccs, 'ranaucc':ranaucc, 'quasiaucc':quasiaucc} \n",
    "#'cfscore':cfscore, causal forest scores \n",
    "pkl.dump(saveD, open(save_filename, 'w')) \n",
    "\n",
    "print('temp:') \n",
    "print(tempvalue) \n",
    "print('p_quantile:') \n",
    "print(p_quantilevalue) \n",
    "\n",
    "### --- add legeneds to plot ---- \n",
    "leg_str = ['Random'] \n",
    "leg_str.append('R-learner on Incremental Gain') \n",
    "for i in range(len(lambds)): \n",
    "    leg_str.append('Duality R-learner') \n",
    "leg_str.append('Causal Forest') # causal forest result \n",
    "leg_str.append('Top Quantile Ranking at ' + str(p_quantile*100) + '%') \n",
    "leg_str.append('Direct Ranking Model') \n",
    "plt.legend(leg_str) \n",
    "\n",
    "### --- print out aucc results for different models --- \n",
    "print('AUCC results: ') \n",
    "print('random: ' + str(ranaucc)) \n",
    "print('rlearner: ' + str(quasiaucc)) \n",
    "i = 0\n",
    "for rlearneraucc in rlearnerauccs: \n",
    "    print('duality rlearner ' + str(i + 1) + ' with lambda = ' + str(lambds[i]) + ':' + str(rlearneraucc)) \n",
    "    i = i + 1\n",
    "print('drm: ' + str(drmaucc)) \n",
    "print('tqr: ' + str(tqraucc)) \n",
    "\n",
    "plt.show() \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
