{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, cPickle as pkl \n",
    "import sys, os \n",
    "sys.path.append('../dataprep/') \n",
    "sys.path.append('../models/') \n",
    "from QueryFunctions import * \n",
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nlabel_dates_weekly = \"\\'2019-10-06\\', \\'2019-10-13\\', \\'2019-10-20\\', \\'2019-10-27\\'\" \\ncity_ids = \\'1,5,6,8,10,12,20,23,198\\' \\nfeature_dates=\"\\'2019-09-22\\'\" \\nproposal_start_date = \\'2019-09-30\\' \\n\\npredFrame4 = qr.execute(\\'presto\\', rxgy_data_sapphire_presto_featuremod2(label_dates_weekly, feature_dates,  city_ids)) \\npredFrame4 = pd.DataFrame(predFrame4.load_data()) \\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_query = 0 ### turn this switch on (to 1.0/True vs 0.0/False) to run query using QueryRunner \n",
    "\n",
    "if use_query: \n",
    "    from queryrunner_client import Client \n",
    "    qr = Client(user_email='will.zou@uber.com') \n",
    "    label_dates_weekly = \"'2019-07-14', '2019-07-21', '2019-07-28', '2019-08-04'\" \n",
    "    city_ids = '1,5,6,8,10,12,20,23,198' \n",
    "    feature_dates=\"'2019-06-30'\" \n",
    "    proposal_start_date = '2019-07-08' \n",
    "\n",
    "    predFrame2 = qr.execute('presto', rxgy_data_sapphire_presto_featuremod2(label_dates_weekly, feature_dates,  city_ids)) \n",
    "    predFrame2 = pd.DataFrame(predFrame2.load_data()) \n",
    "else: \n",
    "    predFrame2 = pd.read_csv('../data/r2e_data_marketing_kdd_paper_data.csv') \n",
    "\n",
    "\"\"\" \n",
    "label_dates_weekly = \"'2019-07-07','2019-06-30','2019-06-23','2019-06-16'\"\n",
    "city_ids = '1,5,6,8,10,12,20,23,198' \n",
    "feature_dates=\"'2019-06-02'\" \n",
    "proposal_start_date = '2019-06-10' \n",
    "\n",
    "predFrame = qr.execute('presto', rxgy_data_sapphire_presto_featuremod2(label_dates_weekly, feature_dates,  city_ids)) \n",
    "predFrame = pd.DataFrame(predFrame.load_data()) \n",
    "\"\"\" \n",
    "\n",
    "\"\"\" \n",
    "label_dates_weekly = \"'2019-08-11', '2019-08-18', '2019-08-25', '2019-09-01'\" \n",
    "city_ids = '1,5,6,8,10,12,20,23,198' \n",
    "feature_dates=\"'2019-07-28'\" \n",
    "proposal_start_date = '2019-08-05' \n",
    "\n",
    "predFrame3 = qr.execute('presto', rxgy_data_sapphire_presto_featuremod2(label_dates_weekly, feature_dates,  city_ids)) \n",
    "predFrame3 = pd.DataFrame(predFrame3.load_data()) \n",
    "\"\"\" \n",
    "\n",
    "\"\"\"\n",
    "label_dates_weekly = \"'2019-10-06', '2019-10-13', '2019-10-20', '2019-10-27'\" \n",
    "city_ids = '1,5,6,8,10,12,20,23,198' \n",
    "feature_dates=\"'2019-09-22'\" \n",
    "proposal_start_date = '2019-09-30' \n",
    "\n",
    "predFrame4 = qr.execute('presto', rxgy_data_sapphire_presto_featuremod2(label_dates_weekly, feature_dates,  city_ids)) \n",
    "predFrame4 = pd.DataFrame(predFrame4.load_data()) \n",
    "\"\"\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "718594\n",
      "368375\n"
     ]
    }
   ],
   "source": [
    "cohort_column_name = 'cohort' \n",
    "treatment_indicator_value = 'treatment_a' \n",
    "control_indicator_value = 'control' \n",
    "\n",
    "print(len(predFrame2))\n",
    "print(sum(predFrame2[cohort_column_name] == control_indicator_value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nans: 152786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nans: 17650\n",
      "number of nans: 17650\n",
      "number of nans: 17650\n",
      "number of nans: 18276\n",
      "number of nans: 18276\n",
      "number of nans: 17650\n",
      "number of nans: 18276\n",
      "number of nans: 17650\n",
      "number of nans: 17650\n",
      "number of nans: 37981\n",
      "number of nans: 33642\n",
      "number of nans: 17650\n",
      "number of nans: 17650\n",
      "number of nans: 29629\n",
      "number of nans: 18276\n",
      "number of nans: 29629\n",
      "number of nans: 29629\n",
      "number of nans: 29629\n",
      "number of nans: 29629\n",
      "number of nans: 29629\n",
      "number of nans: 29629\n",
      "number of nans: 29629\n",
      "number of nans: 17650\n",
      "number of nans: 29629\n",
      "number of nans: 29629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rpu_treated : 0.0519217975038\n",
      "nipu_treated : -0.184914530792\n",
      "rpu_untreated : 0.0260576857822\n",
      "nipu_untreated : -0.0599831417965\n",
      "cpit : 4.83029884574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:76: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:78: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:80: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:82: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "### preprocess the data \n",
    "### -- sample treatment to match control cohort \n",
    "### -- eliminate nulls, standard normalization \n",
    "\n",
    "D = predFrame2 \n",
    "D = D.sample(frac=1.0) \n",
    "\n",
    "feature_list = [ \n",
    "    'rating_2driver_min_avg_84d'\n",
    "    , 'trip_incomplete_total_84d'\n",
    "    , 'days_active_84d'\n",
    "    , 'days_since_trip_first_lifetime'\n",
    "    , 'days_since_last_hard_churn_lifetime'\n",
    "    , 'days_since_last_soft_churn_lifetime'\n",
    "    , 'fare_max_sd_84d'\n",
    "    , 'churns_hard_lifetime'\n",
    "    , 'trips_lifetime'\n",
    "    , 'fare_max_p50_84d'\n",
    "    , 'duration_session_pre_request_max_p50_84d'\n",
    "    , 'trip_pool_per_x_84d'\n",
    "    , 'fare_total_win7d_sd_84d'\n",
    "    , 'trip_complete_win7d_sd_84d'\n",
    "    , 'session_per_days_active_84d'\n",
    "    , 'churns_soft_lifetime'\n",
    "    , 'trip_complete_per_days_active_84d'\n",
    "    , 'trip_pool_prc_84d'\n",
    "    , 'session_background_pre_request_prc_84d'\n",
    "    , 'session_lt_1m_prc_84d'\n",
    "    , 'session_request_prc_84d'\n",
    "    , 'duration_session_outside_total_prc_84d'\n",
    "    , 'trip_x_prc_84d'\n",
    "    , 'days_since_trip_last_lifetime'\n",
    "    , 'has_session_request_84d'\n",
    "    , 'has_session_without_request_84d'\n",
    "] \n",
    "\n",
    "label_list = [ \n",
    "    'manual_apply_orders', \n",
    "    'manual_apply_ni' \n",
    "] \n",
    "\n",
    "for l in feature_list: \n",
    "    print('number of nans: ' + str(sum(D[l] == '\\N'))) \n",
    "    D[l] = pd.to_numeric(D[l], errors='coerce') \n",
    "    D[l] = D[l] - D[l].mean() \n",
    "    D[l] = D[l] / D[l].std() \n",
    "    D[l][pd.isnull(D[l])] = 0.0 ## at zero mean due to standard normalization \n",
    "\n",
    "for l in label_list: \n",
    "    D[l] = pd.to_numeric(D[l], errors='coerce') \n",
    "    D[l][pd.isnull(D[l])] = 0.0 ## at zero mean due to standard normalization \n",
    "\n",
    "### -- compute simple statistics \n",
    "### compute cpit \n",
    "treated_entries = D[D[cohort_column_name] == treatment_indicator_value] \n",
    "untreated_entries = D[D[cohort_column_name] == control_indicator_value] \n",
    "\n",
    "rpu_treated = float(treated_entries[label_list[0]].sum()) / len(treated_entries) \n",
    "nipu_treated = float(treated_entries[label_list[1]].sum()) / len(treated_entries) \n",
    "\n",
    "rpu_untreated = float(untreated_entries[label_list[0]].sum()) / len(untreated_entries) \n",
    "nipu_untreated = float(untreated_entries[label_list[1]].sum()) / len(untreated_entries) \n",
    "\n",
    "cpit = -1.0 * (nipu_treated - nipu_untreated) / (rpu_treated - rpu_untreated) \n",
    "\n",
    "print('rpu_treated : ' + str(rpu_treated)) \n",
    "print('nipu_treated : ' + str(nipu_treated)) \n",
    "print('rpu_untreated : ' + str(rpu_untreated)) \n",
    "print('nipu_untreated : ' + str(nipu_untreated)) \n",
    "print('cpit : ' + str(cpit)) \n",
    "\n",
    "### split the data into 3/1/1 train/val/test \n",
    "len_tr = len(D) / 5 * 4 \n",
    "len_va = len(D) / 10 \n",
    "\n",
    "nX = D[feature_list].as_matrix() \n",
    "w = D[cohort_column_name].apply(lambda x: 1.0 if x == treatment_indicator_value else 0.0) \n",
    "w = w.as_matrix() \n",
    "values = D[label_list[0]] \n",
    "values = values.as_matrix() \n",
    "negcost = D[label_list[1]] \n",
    "negcost = negcost.as_matrix() * 1.0 \n",
    "\n",
    "## split train/val/test sets \n",
    "\n",
    "nX_tr = nX[0:len_tr, :] \n",
    "nX_va = nX[len_tr:len_tr + len_va, :] \n",
    "nX_te = nX[len_tr + len_va:, :] \n",
    "\n",
    "w_tr = w[0:len_tr]\n",
    "w_va = w[len_tr:len_tr + len_va] \n",
    "w_te = w[len_tr + len_va:] \n",
    "\n",
    "values_tr = values[0:len_tr] \n",
    "values_va = values[len_tr:len_tr + len_va] \n",
    "values_te = values[len_tr + len_va:] \n",
    "\n",
    "negcost_tr = negcost[0:len_tr] \n",
    "\n",
    "negcost_va = negcost[len_tr:len_tr + len_va] \n",
    "\n",
    "negcost_te = negcost[len_tr + len_va:] \n",
    "\n",
    "## saving data using cPickel and naming the dictionaries \n",
    "saveD = {'nX_tr':nX_tr, \n",
    "         'w_tr':w_tr, \n",
    "         'values_tr':values_tr, \n",
    "         'nX_va':nX_va, \n",
    "         'w_va':w_va, \n",
    "         'values_va':values_va, \n",
    "         'nX_te':nX_te, \n",
    "         'w_te':w_te, \n",
    "         'values_te':values_te, \n",
    "         'feature_list':feature_list, \n",
    "         #'avg_ni_usd_tr':avg_ni_usd_tr, \n",
    "         'negcost_tr': negcost_tr, \n",
    "         #'avg_ni_usd_va':avg_ni_usd_va, \n",
    "         'negcost_va': negcost_va, \n",
    "         #'avg_ni_usd_te':avg_ni_usd_te, \n",
    "         'negcost_te': negcost_te \n",
    "         } \n",
    "\n",
    "pkl.dump(saveD, open('../data/r2e_ma_training_data_v5_2019_07_08_vc_tr_featuremod3', 'w')) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "718594"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(predFrame2['manual_apply_orders'] > 0) \n",
    "len(predFrame2) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data from ../data/r2e_ma_training_data_v5_2019_07_08_vc_tr_featuremod3\n",
      "printing averages of c_tr, c_unt, o_tre, o_unt ... :\n",
      "0.18551641021002363\n",
      "0.06002637103202763\n",
      "0.0521284071816129\n",
      "0.025921336298358483\n",
      "### ----- start the training of deep learning models ------ \n",
      "------> Training TQR ranking model .... \n",
      "---> running cross validation, iteration: 0\n",
      "WARNING:tensorflow:From ../models/ModelDefinitions.py:37: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From ../models/ModelDefinitions.py:37: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "WARNING:tensorflow:From ../models/ModelDefinitions.py:38: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x158cbb610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x158cbb610>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x158cbb610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x158cbb610>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x158cbb490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x158cbb490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x158cbb490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x158cbb490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From ../models/ModelDefinitions.py:74: The name tf.ceil is deprecated. Please use tf.math.ceil instead.\n",
      "\n",
      "WARNING:tensorflow:From ../models/ModelDefinitions.py:115: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "opt. step : 0 obj: 4.787124087392014\n",
      "setting temperature to :0.6\n",
      "opt. step : 100 obj: 4.757016238970885\n",
      "setting temperature to :0.7\n",
      "opt. step : 200 obj: 4.716475798384767\n",
      "setting temperature to :0.7999999999999999\n",
      "opt. step : 300 obj: 4.677037527328961\n",
      "setting temperature to :0.8999999999999999\n",
      "opt. step : 400 obj: 4.648963906297238\n",
      "setting temperature to :0.9999999999999999\n",
      "opt. step : 500 obj: 4.628572143087152\n",
      "setting temperature to :1.0999999999999999\n",
      "opt. step : 600 obj: 4.612385831596892\n",
      "setting temperature to :1.2\n",
      "opt. step : 700 obj: 4.598514570106528\n",
      "setting temperature to :1.3\n",
      "opt. step : 800 obj: 4.585615187740378\n",
      "setting temperature to :1.4000000000000001\n",
      "opt. step : 900 obj: 4.573547339376735\n",
      "setting temperature to :1.5000000000000002\n",
      "opt. step : 1000 obj: 4.56253837978279\n",
      "setting temperature to :1.6000000000000003\n",
      "opt. step : 1100 obj: 4.552908051853304\n",
      "setting temperature to :1.7000000000000004\n",
      "opt. step : 1200 obj: 4.544689121382083\n",
      "setting temperature to :1.8000000000000005\n",
      "opt. step : 1300 obj: 4.537551946656556\n",
      "setting temperature to :1.9000000000000006\n",
      "opt. step : 1400 obj: 4.531050575847828\n",
      "setting temperature to :2.0000000000000004\n",
      "opt. step : 1500 obj: 4.524857583611103\n",
      "setting temperature to :2.1000000000000005\n",
      "opt. step : 1600 obj: 4.519315250809602\n",
      "setting temperature to :2.2000000000000006\n",
      "opt. step : 1700 obj: 4.514551837528695\n",
      "setting temperature to :2.3000000000000007\n",
      "opt. step : 1800 obj: 4.510620160074693\n",
      "setting temperature to :2.400000000000001\n",
      "opt. step : 1900 obj: 4.507504340717208\n",
      "setting temperature to :2.500000000000001\n",
      "---> optimization finished ... \n",
      "temp:\n",
      "2.553404854109812\n",
      "p_quantile:\n",
      "0.4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15c7bd750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15c7bd750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15c7bd750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15c7bd750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15c7bd690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15c7bd690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15c7bd690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15c7bd690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "validation CPIT:\n",
      "4.926700240347063\n",
      "best performing model: iteration 0\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15c879b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15c879b10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15c879b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15c879b10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "------> Training DRM ranking model .... \n",
      "---> running cross validation, iteration: 0\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15c879e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15c879e50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15c879e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15c879e50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15c879a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15c879a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15c879a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15c879a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "opt. step : 0 obj: 4.803536185513243\n",
      "opt. step : 100 obj: 4.66315443828416\n",
      "opt. step : 200 obj: 4.563652664171363\n",
      "opt. step : 300 obj: 4.498019426592082\n",
      "opt. step : 400 obj: 4.435705410341387\n",
      "opt. step : 500 obj: 4.4005278717978555\n",
      "opt. step : 600 obj: 4.371536667311181\n",
      "opt. step : 700 obj: 4.3515329702932855\n",
      "opt. step : 800 obj: 4.3365896588679975\n",
      "opt. step : 900 obj: 4.32385725808383\n",
      "opt. step : 1000 obj: 4.312521290656954\n",
      "opt. step : 1100 obj: 4.300864351597067\n",
      "opt. step : 1200 obj: 4.2894354279381925\n",
      "opt. step : 1300 obj: 4.279178804723712\n",
      "opt. step : 1400 obj: 4.269613830709713\n",
      "opt. step : 1500 obj: 4.260891626914869\n",
      "opt. step : 1600 obj: 4.252936389894658\n",
      "opt. step : 1700 obj: 4.245641969269877\n",
      "opt. step : 1800 obj: 4.23877057299033\n",
      "opt. step : 1900 obj: 4.2318346610096285\n",
      "---> optimization finished ... \n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15e7495d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15e7495d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15e7495d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15e7495d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15e749210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15e749210>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15e749210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15e749210>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "validation CPIT:\n",
      "5.0061325812115625\n",
      "best performing model: iteration 0\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15e8f2890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15e8f2890>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15e8f2890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x15e8f2890>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" \\n### this section is to load the results trained by grf R code \\n### \\n\\not_cf = pd.read_csv('../results/causal_forest_grf_test_set_results_O_finalsize_numtrees1002.csv') \\nct_cf = pd.read_csv('../results/causal_forest_grf_test_set_results_C_finalsize_numtrees1002.csv') \\n\\not_cf = ot_cf.as_matrix() \\nOcfscores = ot_cf[0] \\n\\nct_cf = ct_cf.as_matrix() \\nCcfscores = ct_cf[0] \\n\\ncfscore = np.divide(Ocfscores, Ccfscores) \\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### code implements ranking model for treatment effect \n",
    "### for optimizing with respect to direct marketplace objectives \n",
    "### using tensorflow \n",
    "\n",
    "import numpy as np, tensorflow as tf, pandas as pd, pickle as pkl \n",
    "sys.path.append('../')  \n",
    "from ModelDefinitions import * \n",
    "from DataProcFunctions import * \n",
    "\n",
    "### RxGy TQR setting: \n",
    "p_quantile = 0.4 ## percentage of quantile to aim for \n",
    "num_optimize_iterations = 2000 ## number of optimization iterations \n",
    "num_modeling_inits = 1 ## number of random initializations \n",
    "num_hidden = 0 ## number of hidden units in DNN \n",
    "use_schedule = True ## option to use a constraint annealing schedule \n",
    "temp = 0.5 ## initial temperature for constraints \n",
    "inc_temp = 0.1 ## increment of temperature per 100 iterations \n",
    "save_cf_data = False ### whether to save data for causal forest training \n",
    "\n",
    "## set a random seed to reproduce results \n",
    "seed = 1234; tf.compat.v2.random.set_seed(seed); np.random.seed(seed) \n",
    "\n",
    "sample_frac = 1.0 ## option to sample data by a fraction \\in (0, 1) \n",
    "data_filename =  '../data/r2e_ma_training_data_v5_2019_07_08_vc_tr_featuremod3' \n",
    "prefix = 'r2e_v5_07_08_featuremod3_tr_iter100_run4' \n",
    "\n",
    "D_tre, D_unt, Dv_tre, Dv_unt, Dt_tre, Dt_unt, o_tre, o_unt, ov_tre, ov_unt, ot_tre, ot_unt, c_tre, c_unt, cv_tre, cv_unt, ct_tre, ct_unt, D, w, o, c, Dv, wv, ov, cv, Dt, wt, ot, ct = LoadDataFromPkl(data_filename, frac = sample_frac, save_cf_data=save_cf_data) \n",
    "\n",
    "print('### ----- start the training of deep learning models ------ ') \n",
    "gs_tqr = [] \n",
    "gs_drm = [] \n",
    "for i in range(num_modeling_inits): \n",
    "    gs_tqr.append(tf.Graph()) \n",
    "for i in range(num_modeling_inits): \n",
    "    gs_drm.append(tf.Graph()) \n",
    "\n",
    "print('------> Training TQR ranking model .... ') \n",
    "val_results = [] \n",
    "sess_list = [] \n",
    "for i in range(num_modeling_inits): \n",
    "    print('---> running cross validation, iteration: ' + str(i)) \n",
    "    obj, opt, dumh, dumhu, vtemp, p_quantile = TunableTQRankingModelDNN(gs_tqr[i], D_tre, D_unt, o_tre, o_unt, c_tre, c_unt, 'train-first', temp, p_quantile, num_hidden, use_schedule) \n",
    "    ### session definitions and variable initialization \n",
    "    sess = tf.Session(graph = gs_tqr[i]) \n",
    "    sess_list.append(sess) \n",
    "    \n",
    "    ### initialize variables and run optimization \n",
    "    with gs_tqr[i].as_default() as g: \n",
    "        init = tf.global_variables_initializer() \n",
    "    sess.run(init) \n",
    "    cur_temp = temp \n",
    "    for step in range(num_optimize_iterations): \n",
    "        _, objres = sess.run([opt, obj]) \n",
    "        if step % 100 == 0: \n",
    "            cur_temp = cur_temp + inc_temp \n",
    "            print('opt. step : ' + str(step) + ' obj: ' + str(objres)) \n",
    "            if use_schedule: \n",
    "                sess.run(vtemp.assign(cur_temp))\n",
    "                print('setting temperature to :' + str(sess.run(vtemp))) \n",
    "    \n",
    "    print('---> optimization finished ... ') \n",
    "    tempvalue = sess.run(vtemp)\n",
    "    p_quantilevalue = p_quantile\n",
    "    print('temp:') \n",
    "    print(tempvalue)\n",
    "    print('p_quantile:')\n",
    "    print(p_quantilevalue) \n",
    "    \n",
    "    ### evaluate CPIT metric on validation set \n",
    "    objv, dumo, dumh, dumhu, dvtemp, dp_quantile = TunableTQRankingModelDNN(gs_tqr[i], Dv_tre, Dv_unt, ov_tre, ov_unt, cv_tre, cv_unt, 'eval', temp, p_quantile, num_hidden, use_schedule) \n",
    "    \n",
    "    val_result = sess.run(objv) \n",
    "    print('validation CPIT:') \n",
    "    print(val_result) \n",
    "    val_results.append(val_result) \n",
    "\n",
    "from operator import itemgetter \n",
    "best_index = min(enumerate(val_results), key=itemgetter(1))[0] \n",
    "\n",
    "print('best performing model: iteration ' + str(best_index)) \n",
    "\n",
    "### run scoring on whole test set \n",
    "with gs_tqr[best_index].as_default() as g: \n",
    "    if num_hidden > 0: \n",
    "        with tf.variable_scope(\"tqrhidden\") as scope: \n",
    "            h1_test = tf.contrib.layers.fully_connected(Dt, num_hidden, activation_fn=tf.nn.tanh, reuse=tf.AUTO_REUSE, scope=scope, weights_initializer=tf.contrib.layers.xavier_initializer()) \n",
    "        with tf.variable_scope(\"tqranker\") as scope: \n",
    "            h_test = tf.contrib.layers.fully_connected(h1_test, 1, activation_fn=None, reuse=tf.AUTO_REUSE, scope=scope) \n",
    "    else: \n",
    "        with tf.variable_scope(\"tqranker\") as scope: \n",
    "            h_test = tf.contrib.layers.fully_connected(Dt, 1, activation_fn=None, reuse=tf.AUTO_REUSE, scope=scope) \n",
    "    tqrscore = sess_list[best_index].run(h_test) \n",
    "\n",
    "print('------> Training DRM ranking model .... ') \n",
    "sess_list = [] \n",
    "val_results = [] \n",
    "for i in range(num_modeling_inits): \n",
    "    print('---> running cross validation, iteration: ' + str(i)) \n",
    "    ### ---- train cpit ranking model for comparison --- \n",
    "    dobjc, doptc, ddumh, ddumu = DirectRankingModelDNN(gs_drm[i], D_tre, D_unt, o_tre, o_unt, c_tre, c_unt, 'train-first-drm', num_hidden) \n",
    "    \n",
    "    dsess = tf.Session(graph = gs_drm[i]) \n",
    "    sess_list.append(dsess) \n",
    "    \n",
    "    ### initialize variables and run optimization \n",
    "    with gs_drm[i].as_default() as g: \n",
    "        dinit = tf.global_variables_initializer() \n",
    "    dsess.run(dinit) \n",
    "    for step in range(num_optimize_iterations): \n",
    "        _, dobjres = dsess.run([doptc, dobjc]) \n",
    "        if step % 100 == 0: \n",
    "            print('opt. step : ' + str(step) + ' obj: ' + str(dobjres)) \n",
    "    \n",
    "    print('---> optimization finished ... ') \n",
    "    \n",
    "    ### evaluate CPIT metric on validation set \n",
    "    dobjv, ddumo, dumh, dumhu = DirectRankingModelDNN(gs_drm[i], Dv_tre, Dv_unt, ov_tre, ov_unt, cv_tre, cv_unt, 'eval', num_hidden)\n",
    "    val_result = dsess.run(dobjv) \n",
    "    print('validation CPIT:') \n",
    "    print(val_result) \n",
    "    val_results.append(val_result) \n",
    "\n",
    "best_index = min(enumerate(val_results), key=itemgetter(1))[0] \n",
    "\n",
    "print('best performing model: iteration ' + str(best_index)) \n",
    "\n",
    "### run scoring on whole test set \n",
    "with gs_drm[best_index].as_default() as g: \n",
    "    if num_hidden > 0: \n",
    "        with tf.variable_scope(\"drmhidden\") as scope: \n",
    "            h1_test = tf.contrib.layers.fully_connected(Dt, num_hidden, activation_fn=tf.nn.tanh, reuse=tf.AUTO_REUSE, scope=scope, weights_initializer=tf.contrib.layers.xavier_initializer()) \n",
    "        with tf.variable_scope(\"drmranker\") as scope: \n",
    "            h_test = tf.contrib.layers.fully_connected(h1_test, 1, activation_fn=tf.nn.tanh, reuse=tf.AUTO_REUSE, scope=scope) \n",
    "    else: \n",
    "        with tf.variable_scope(\"drmranker\") as scope: \n",
    "            h_test = tf.contrib.layers.fully_connected(Dt, 1, activation_fn=tf.nn.tanh, reuse=tf.AUTO_REUSE, scope=scope) \n",
    "    drmscore = sess_list[best_index].run(h_test) \n",
    "\n",
    "### ---- train hte model for comparison ---- \n",
    "### we could utimize the original HTE functions \n",
    "from LinearHTEModels import * \n",
    "from PromotionModels import PromotionModels \n",
    "\n",
    "pmodels = PromotionModels() \n",
    "\n",
    "## set-up RLearner \n",
    "rl_ridge_model_O, rl_ridge_model_C = pmodels.fit_rlearner(D, o, c, w) \n",
    "\n",
    "## one model for order lift and one model for cost drop \n",
    "pred_values_va_rlearner_O = rl_ridge_model_O.predict(Dt) \n",
    "pred_values_va_rlearner_C = rl_ridge_model_C.predict(Dt) \n",
    "\n",
    "#if ranking_model == 'effectiveness-ratio': ## if we use the effectiveness ratio model, compute effectiveness ratio \n",
    "pred_values_va_rlearner = np.divide(np.maximum(pred_values_va_rlearner_O, 0), pred_values_va_rlearner_C + 1e-7) \n",
    "\n",
    "lhmodels = LinearHTEModels() \n",
    "lambds = [0.0001, 0.00001] \n",
    "rlearnerscores = [] \n",
    "rl_ridge_model_L_list = [] \n",
    "## set-up lagrangian rlearner \n",
    "for i in range(len(lambds)): \n",
    "    lambd = lambds[i] \n",
    "    rl_ridge_model_L = lhmodels.fit_rlearner_lagrangian(D, o, c, w, lambd) \n",
    "    rl_ridge_model_L_list.append(rl_ridge_model_L) \n",
    "    rlearnerscores.append(rl_ridge_model_L.predict(Dt)) \n",
    "\n",
    "\"\"\" \n",
    "### this section is to load the results trained by grf R code \n",
    "### \n",
    "\n",
    "ot_cf = pd.read_csv('../results/causal_forest_grf_test_set_results_O_finalsize_numtrees1002.csv') \n",
    "ct_cf = pd.read_csv('../results/causal_forest_grf_test_set_results_C_finalsize_numtrees1002.csv') \n",
    "\n",
    "ot_cf = ot_cf.as_matrix() \n",
    "Ocfscores = ot_cf[0] \n",
    "\n",
    "ct_cf = ct_cf.as_matrix() \n",
    "Ccfscores = ct_cf[0] \n",
    "\n",
    "cfscore = np.divide(Ocfscores, Ccfscores) \n",
    "\"\"\" \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rpu_control: 0.02723167203007112\n",
      "nipu_control: -0.06350085810577477\n",
      "rpu_ft: 0.05108359133126935\n",
      "nipu_ft: -0.1816481303288189\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.10\n",
      "treated_target_rpu: 0.05\n",
      "treated_target_nipu: -0.16\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.05\n",
      "treated_nontarget_nipu: -0.18\n",
      "nontreated_nontarget_rpu: 0.03\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 9.999582538997815% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.7057568942726995\n",
      "--> in non-targeted users: \n",
      "cpit = 4.975699554091625\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.03\n",
      "nipu_cohort: -0.07\n",
      "lift targeted cohort vs control: 0.08\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 4.71\n",
      "lift targeted-treated vs control: 0.86\n",
      "cpit cohort: 4.714694\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.20\n",
      "treated_target_rpu: 0.05\n",
      "treated_target_nipu: -0.16\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.05\n",
      "treated_nontarget_nipu: -0.19\n",
      "nontreated_nontarget_rpu: 0.03\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 19.99916507799563% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.863634055568386\n",
      "--> in non-targeted users: \n",
      "cpit = 4.972774090609214\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.03\n",
      "nipu_cohort: -0.08\n",
      "lift targeted cohort vs control: 0.15\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 4.86\n",
      "lift targeted-treated vs control: 0.82\n",
      "cpit cohort: 4.861345\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.30\n",
      "treated_target_rpu: 0.05\n",
      "treated_target_nipu: -0.17\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.05\n",
      "treated_nontarget_nipu: -0.19\n",
      "nontreated_nontarget_rpu: 0.03\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 29.998747616993448% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.626854725547319\n",
      "--> in non-targeted users: \n",
      "cpit = 5.092842035794802\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.03\n",
      "nipu_cohort: -0.10\n",
      "lift targeted cohort vs control: 0.26\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 4.63\n",
      "lift targeted-treated vs control: 0.92\n",
      "cpit cohort: 4.625109\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.40\n",
      "treated_target_rpu: 0.05\n",
      "treated_target_nipu: -0.18\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.05\n",
      "treated_nontarget_nipu: -0.18\n",
      "nontreated_nontarget_rpu: 0.03\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 39.99833015599126% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.66941002775602\n",
      "--> in non-targeted users: \n",
      "cpit = 5.1617689348971165\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.04\n",
      "nipu_cohort: -0.11\n",
      "lift targeted cohort vs control: 0.36\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 4.67\n",
      "lift targeted-treated vs control: 0.95\n",
      "cpit cohort: 4.666633\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.50\n",
      "treated_target_rpu: 0.05\n",
      "treated_target_nipu: -0.18\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.05\n",
      "treated_nontarget_nipu: -0.18\n",
      "nontreated_nontarget_rpu: 0.03\n",
      "nontreated_nontarget_nipu: -0.07\n",
      "--- with 49.997912694989076% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.748263461439313\n",
      "--> in non-targeted users: \n",
      "cpit = 5.181935335350282\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.04\n",
      "nipu_cohort: -0.12\n",
      "lift targeted cohort vs control: 0.46\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 4.75\n",
      "lift targeted-treated vs control: 0.91\n",
      "cpit cohort: 4.747893\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.60\n",
      "treated_target_rpu: 0.05\n",
      "treated_target_nipu: -0.18\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.05\n",
      "treated_nontarget_nipu: -0.19\n",
      "nontreated_nontarget_rpu: 0.03\n",
      "nontreated_nontarget_nipu: -0.07\n",
      "--- with 59.997495233986896% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.812126844459838\n",
      "--> in non-targeted users: \n",
      "cpit = 5.1761394931483045\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.04\n",
      "nipu_cohort: -0.13\n",
      "lift targeted cohort vs control: 0.53\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 4.81\n",
      "lift targeted-treated vs control: 0.87\n",
      "cpit cohort: 4.812139\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.70\n",
      "treated_target_rpu: 0.05\n",
      "treated_target_nipu: -0.18\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.05\n",
      "treated_nontarget_nipu: -0.19\n",
      "nontreated_nontarget_rpu: 0.03\n",
      "nontreated_nontarget_nipu: -0.08\n",
      "--- with 69.99707777298471% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 5.269030108498157\n",
      "--> in non-targeted users: \n",
      "cpit = 4.279020630152788\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.04\n",
      "nipu_cohort: -0.15\n",
      "lift targeted cohort vs control: 0.60\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 5.27\n",
      "lift targeted-treated vs control: 0.86\n",
      "cpit cohort: 5.265269\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.80\n",
      "treated_target_rpu: 0.05\n",
      "treated_target_nipu: -0.18\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.05\n",
      "treated_nontarget_nipu: -0.18\n",
      "nontreated_nontarget_rpu: 0.03\n",
      "nontreated_nontarget_nipu: -0.08\n",
      "--- with 79.99666031198252% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 5.102708525128061\n",
      "--> in non-targeted users: \n",
      "cpit = 4.31446017284461\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.05\n",
      "nipu_cohort: -0.16\n",
      "lift targeted cohort vs control: 0.71\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 5.10\n",
      "lift targeted-treated vs control: 0.89\n",
      "cpit cohort: 5.101986\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.90\n",
      "treated_target_rpu: 0.05\n",
      "treated_target_nipu: -0.18\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.05\n",
      "treated_nontarget_nipu: -0.19\n",
      "nontreated_nontarget_rpu: 0.03\n",
      "nontreated_nontarget_nipu: -0.09\n",
      "--- with 89.99624285098034% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 5.015209619267795\n",
      "--> in non-targeted users: \n",
      "cpit = 4.391355834422183\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.05\n",
      "nipu_cohort: -0.17\n",
      "lift targeted cohort vs control: 0.79\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 5.02\n",
      "lift targeted-treated vs control: 0.88\n",
      "cpit cohort: 5.015024\n",
      "rpu_cohort\n",
      "0.04872833435981905\n",
      "treated_target_rpu\n",
      "0.05108359133126935\n",
      "---------------------------->>>>>>\n",
      "perc - target: 1.00\n",
      "treated_target_rpu: 0.05\n",
      "treated_target_nipu: -0.18\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.00\n",
      "treated_nontarget_nipu: 0.00\n",
      "nontreated_nontarget_rpu: 0.00\n",
      "nontreated_nontarget_nipu: 0.00\n",
      "--- with 99.99582538997815% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.953608269649674\n",
      "--> in non-targeted users: \n",
      "cpit = nan\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.05\n",
      "nipu_cohort: -0.18\n",
      "lift targeted cohort vs control: 0.88\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 4.95\n",
      "lift targeted-treated vs control: 0.88\n",
      "cpit cohort: 4.953365\n",
      "rpu_control: 0.02723167203007112\n",
      "nipu_control: -0.06350085810577477\n",
      "rpu_ft: 0.05108359133126935\n",
      "nipu_ft: -0.1816481303288189\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.10\n",
      "treated_target_rpu: 0.09\n",
      "treated_target_nipu: -0.36\n",
      "nontreated_target_rpu: 0.04\n",
      "nontreated_target_nipu: -0.08\n",
      "treated_nontarget_rpu: 0.05\n",
      "treated_nontarget_nipu: -0.16\n",
      "nontreated_nontarget_rpu: 0.03\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 9.999582538997815% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 5.259141110501879\n",
      "--> in non-targeted users: \n",
      "cpit = 4.860339137211073\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.03\n",
      "nipu_cohort: -0.09\n",
      "lift targeted cohort vs control: 0.20\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 5.27\n",
      "lift targeted-treated vs control: 2.43\n",
      "cpit cohort: 5.268593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------->>>>>>\n",
      "perc - target: 0.20\n",
      "treated_target_rpu: 0.08\n",
      "treated_target_nipu: -0.30\n",
      "nontreated_target_rpu: 0.04\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.04\n",
      "treated_nontarget_nipu: -0.15\n",
      "nontreated_nontarget_rpu: 0.03\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 19.99916507799563% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 5.244450827449803\n",
      "--> in non-targeted users: \n",
      "cpit = 4.763808833388052\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.04\n",
      "nipu_cohort: -0.11\n",
      "lift targeted cohort vs control: 0.34\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 5.25\n",
      "lift targeted-treated vs control: 2.00\n",
      "cpit cohort: 5.251697\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.30\n",
      "treated_target_rpu: 0.07\n",
      "treated_target_nipu: -0.27\n",
      "nontreated_target_rpu: 0.04\n",
      "nontreated_target_nipu: -0.07\n",
      "treated_nontarget_rpu: 0.04\n",
      "treated_nontarget_nipu: -0.14\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 29.998747616993448% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 5.353443371087527\n",
      "--> in non-targeted users: \n",
      "cpit = 4.556873737970425\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.04\n",
      "nipu_cohort: -0.13\n",
      "lift targeted cohort vs control: 0.42\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 5.37\n",
      "lift targeted-treated vs control: 1.75\n",
      "cpit cohort: 5.369322\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.40\n",
      "treated_target_rpu: 0.07\n",
      "treated_target_nipu: -0.25\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.04\n",
      "treated_nontarget_nipu: -0.13\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 39.99833015599126% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 5.38095274530423\n",
      "--> in non-targeted users: \n",
      "cpit = 4.301165767139291\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.04\n",
      "nipu_cohort: -0.14\n",
      "lift targeted cohort vs control: 0.53\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 5.39\n",
      "lift targeted-treated vs control: 1.52\n",
      "cpit cohort: 5.387308\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.50\n",
      "treated_target_rpu: 0.07\n",
      "treated_target_nipu: -0.24\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.07\n",
      "treated_nontarget_rpu: 0.04\n",
      "treated_nontarget_nipu: -0.12\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 49.997912694989076% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 5.2936750429579025\n",
      "--> in non-targeted users: \n",
      "cpit = 4.143242330045477\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.04\n",
      "nipu_cohort: -0.15\n",
      "lift targeted cohort vs control: 0.61\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 5.30\n",
      "lift targeted-treated vs control: 1.42\n",
      "cpit cohort: 5.299337\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.60\n",
      "treated_target_rpu: 0.06\n",
      "treated_target_nipu: -0.22\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.07\n",
      "treated_nontarget_rpu: 0.04\n",
      "treated_nontarget_nipu: -0.12\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.05\n",
      "--- with 59.997495233986896% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 5.0912244344664845\n",
      "--> in non-targeted users: \n",
      "cpit = 4.515126265296844\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.05\n",
      "nipu_cohort: -0.16\n",
      "lift targeted cohort vs control: 0.66\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 5.09\n",
      "lift targeted-treated vs control: 1.26\n",
      "cpit cohort: 5.092696\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.70\n",
      "treated_target_rpu: 0.06\n",
      "treated_target_nipu: -0.22\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.07\n",
      "treated_nontarget_rpu: 0.03\n",
      "treated_nontarget_nipu: -0.10\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.05\n",
      "--- with 69.99707777298471% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 5.078521186081353\n",
      "--> in non-targeted users: \n",
      "cpit = 4.164581869396178\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.05\n",
      "nipu_cohort: -0.17\n",
      "lift targeted cohort vs control: 0.76\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 5.08\n",
      "lift targeted-treated vs control: 1.19\n",
      "cpit cohort: 5.078373\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.80\n",
      "treated_target_rpu: 0.06\n",
      "treated_target_nipu: -0.20\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.07\n",
      "treated_nontarget_rpu: 0.03\n",
      "treated_nontarget_nipu: -0.10\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.05\n",
      "--- with 79.99666031198252% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 5.071127009098672\n",
      "--> in non-targeted users: \n",
      "cpit = 3.81552260104738\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.05\n",
      "nipu_cohort: -0.17\n",
      "lift targeted cohort vs control: 0.79\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 5.07\n",
      "lift targeted-treated vs control: 1.08\n",
      "cpit cohort: 5.071308\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.90\n",
      "treated_target_rpu: 0.05\n",
      "treated_target_nipu: -0.19\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.07\n",
      "treated_nontarget_rpu: 0.03\n",
      "treated_nontarget_nipu: -0.08\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.04\n",
      "--- with 89.99624285098034% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 5.004627928109246\n",
      "--> in non-targeted users: \n",
      "cpit = 3.869799128995379\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.05\n",
      "nipu_cohort: -0.18\n",
      "lift targeted cohort vs control: 0.84\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 5.00\n",
      "lift targeted-treated vs control: 0.97\n",
      "cpit cohort: 5.004974\n",
      "rpu_cohort\n",
      "0.05000080959564787\n",
      "treated_target_rpu\n",
      "0.05108505575781899\n",
      "---------------------------->>>>>>\n",
      "perc - target: 1.00\n",
      "treated_target_rpu: 0.05\n",
      "treated_target_nipu: -0.18\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.00\n",
      "treated_nontarget_nipu: 0.00\n",
      "nontreated_nontarget_rpu: 0.00\n",
      "nontreated_nontarget_nipu: 0.00\n",
      "--- with 99.99582538997815% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.953441500173492\n",
      "--> in non-targeted users: \n",
      "cpit = nan\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.05\n",
      "nipu_cohort: -0.18\n",
      "lift targeted cohort vs control: 0.88\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 4.95\n",
      "lift targeted-treated vs control: 0.88\n",
      "cpit cohort: 4.953280\n",
      "rpu_control: 0.02723167203007112\n",
      "nipu_control: -0.06350085810577477\n",
      "rpu_ft: 0.05108359133126935\n",
      "nipu_ft: -0.1816481303288189\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.10\n",
      "treated_target_rpu: 0.09\n",
      "treated_target_nipu: -0.36\n",
      "nontreated_target_rpu: 0.04\n",
      "nontreated_target_nipu: -0.08\n",
      "treated_nontarget_rpu: 0.05\n",
      "treated_nontarget_nipu: -0.16\n",
      "nontreated_nontarget_rpu: 0.03\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 9.999582538997815% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 5.248790206507604\n",
      "--> in non-targeted users: \n",
      "cpit = 4.8633601682455305\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.03\n",
      "nipu_cohort: -0.09\n",
      "lift targeted cohort vs control: 0.20\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 5.26\n",
      "lift targeted-treated vs control: 2.45\n",
      "cpit cohort: 5.256386\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.20\n",
      "treated_target_rpu: 0.08\n",
      "treated_target_nipu: -0.30\n",
      "nontreated_target_rpu: 0.04\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.04\n",
      "treated_nontarget_nipu: -0.15\n",
      "nontreated_nontarget_rpu: 0.03\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 19.99916507799563% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 5.186623950970784\n",
      "--> in non-targeted users: \n",
      "cpit = 4.79669966034839\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.04\n",
      "nipu_cohort: -0.11\n",
      "lift targeted cohort vs control: 0.34\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 5.19\n",
      "lift targeted-treated vs control: 2.01\n",
      "cpit cohort: 5.193244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------->>>>>>\n",
      "perc - target: 0.30\n",
      "treated_target_rpu: 0.07\n",
      "treated_target_nipu: -0.27\n",
      "nontreated_target_rpu: 0.04\n",
      "nontreated_target_nipu: -0.07\n",
      "treated_nontarget_rpu: 0.04\n",
      "treated_nontarget_nipu: -0.14\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 29.998747616993448% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 5.350447167726364\n",
      "--> in non-targeted users: \n",
      "cpit = 4.564400347675225\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.04\n",
      "nipu_cohort: -0.13\n",
      "lift targeted cohort vs control: 0.42\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 5.37\n",
      "lift targeted-treated vs control: 1.73\n",
      "cpit cohort: 5.365938\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.40\n",
      "treated_target_rpu: 0.07\n",
      "treated_target_nipu: -0.25\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.04\n",
      "treated_nontarget_nipu: -0.13\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 39.99833015599126% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 5.324680928343854\n",
      "--> in non-targeted users: \n",
      "cpit = 4.376897213210107\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.04\n",
      "nipu_cohort: -0.14\n",
      "lift targeted cohort vs control: 0.53\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 5.33\n",
      "lift targeted-treated vs control: 1.53\n",
      "cpit cohort: 5.331360\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.50\n",
      "treated_target_rpu: 0.07\n",
      "treated_target_nipu: -0.24\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.07\n",
      "treated_nontarget_rpu: 0.04\n",
      "treated_nontarget_nipu: -0.12\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 49.997912694989076% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 5.2827283852288005\n",
      "--> in non-targeted users: \n",
      "cpit = 4.162069819027474\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.04\n",
      "nipu_cohort: -0.15\n",
      "lift targeted cohort vs control: 0.62\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 5.29\n",
      "lift targeted-treated vs control: 1.42\n",
      "cpit cohort: 5.286733\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.60\n",
      "treated_target_rpu: 0.06\n",
      "treated_target_nipu: -0.22\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.07\n",
      "treated_nontarget_rpu: 0.04\n",
      "treated_nontarget_nipu: -0.12\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.05\n",
      "--- with 59.997495233986896% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 5.087305061260028\n",
      "--> in non-targeted users: \n",
      "cpit = 4.520439473541784\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.05\n",
      "nipu_cohort: -0.16\n",
      "lift targeted cohort vs control: 0.67\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 5.09\n",
      "lift targeted-treated vs control: 1.26\n",
      "cpit cohort: 5.089274\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.70\n",
      "treated_target_rpu: 0.06\n",
      "treated_target_nipu: -0.22\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.07\n",
      "treated_nontarget_rpu: 0.03\n",
      "treated_nontarget_nipu: -0.10\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.05\n",
      "--- with 69.99707777298471% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 5.0825957767955945\n",
      "--> in non-targeted users: \n",
      "cpit = 4.179910206888776\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.05\n",
      "nipu_cohort: -0.17\n",
      "lift targeted cohort vs control: 0.75\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 5.08\n",
      "lift targeted-treated vs control: 1.18\n",
      "cpit cohort: 5.082399\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.80\n",
      "treated_target_rpu: 0.06\n",
      "treated_target_nipu: -0.20\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.07\n",
      "treated_nontarget_rpu: 0.03\n",
      "treated_nontarget_nipu: -0.10\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.05\n",
      "--- with 79.99666031198252% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 5.084052159809381\n",
      "--> in non-targeted users: \n",
      "cpit = 3.7301773389635624\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.05\n",
      "nipu_cohort: -0.17\n",
      "lift targeted cohort vs control: 0.79\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 5.08\n",
      "lift targeted-treated vs control: 1.08\n",
      "cpit cohort: 5.084113\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.90\n",
      "treated_target_rpu: 0.05\n",
      "treated_target_nipu: -0.19\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.07\n",
      "treated_nontarget_rpu: 0.03\n",
      "treated_nontarget_nipu: -0.08\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.04\n",
      "--- with 89.99624285098034% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 5.005000550119987\n",
      "--> in non-targeted users: \n",
      "cpit = 3.8991534183548286\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.05\n",
      "nipu_cohort: -0.18\n",
      "lift targeted cohort vs control: 0.83\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 5.01\n",
      "lift targeted-treated vs control: 0.97\n",
      "cpit cohort: 5.005222\n",
      "rpu_cohort\n",
      "0.04996621367839925\n",
      "treated_target_rpu\n",
      "0.05108505575781899\n",
      "---------------------------->>>>>>\n",
      "perc - target: 1.00\n",
      "treated_target_rpu: 0.05\n",
      "treated_target_nipu: -0.18\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.00\n",
      "treated_nontarget_nipu: 0.00\n",
      "nontreated_nontarget_rpu: 0.00\n",
      "nontreated_nontarget_nipu: 0.00\n",
      "--- with 99.99582538997815% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.953441500173492\n",
      "--> in non-targeted users: \n",
      "cpit = nan\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.05\n",
      "nipu_cohort: -0.18\n",
      "lift targeted cohort vs control: 0.88\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 4.95\n",
      "lift targeted-treated vs control: 0.88\n",
      "cpit cohort: 4.953280\n",
      "rpu_control: 0.02723167203007112\n",
      "nipu_control: -0.06350085810577477\n",
      "rpu_ft: 0.05108359133126935\n",
      "nipu_ft: -0.1816481303288189\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.10\n",
      "treated_target_rpu: 0.09\n",
      "treated_target_nipu: -0.36\n",
      "nontreated_target_rpu: 0.04\n",
      "nontreated_target_nipu: -0.08\n",
      "treated_nontarget_rpu: 0.05\n",
      "treated_nontarget_nipu: -0.16\n",
      "nontreated_nontarget_rpu: 0.03\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 9.999582538997815% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 5.266802784512649\n",
      "--> in non-targeted users: \n",
      "cpit = 4.85771584301018\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.03\n",
      "nipu_cohort: -0.09\n",
      "lift targeted cohort vs control: 0.20\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 5.28\n",
      "lift targeted-treated vs control: 2.44\n",
      "cpit cohort: 5.275931\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.20\n",
      "treated_target_rpu: 0.08\n",
      "treated_target_nipu: -0.30\n",
      "nontreated_target_rpu: 0.04\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.04\n",
      "treated_nontarget_nipu: -0.15\n",
      "nontreated_nontarget_rpu: 0.03\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 19.99916507799563% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 5.245947443900461\n",
      "--> in non-targeted users: \n",
      "cpit = 4.763383938553878\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.04\n",
      "nipu_cohort: -0.11\n",
      "lift targeted cohort vs control: 0.34\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 5.25\n",
      "lift targeted-treated vs control: 2.00\n",
      "cpit cohort: 5.252879\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.30\n",
      "treated_target_rpu: 0.07\n",
      "treated_target_nipu: -0.27\n",
      "nontreated_target_rpu: 0.04\n",
      "nontreated_target_nipu: -0.07\n",
      "treated_nontarget_rpu: 0.04\n",
      "treated_nontarget_nipu: -0.14\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 29.998747616993448% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 5.353443371087527\n",
      "--> in non-targeted users: \n",
      "cpit = 4.556873737970425\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.04\n",
      "nipu_cohort: -0.13\n",
      "lift targeted cohort vs control: 0.42\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 5.37\n",
      "lift targeted-treated vs control: 1.75\n",
      "cpit cohort: 5.369322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------->>>>>>\n",
      "perc - target: 0.40\n",
      "treated_target_rpu: 0.07\n",
      "treated_target_nipu: -0.25\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.04\n",
      "treated_nontarget_nipu: -0.13\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 39.99833015599126% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 5.379623989406273\n",
      "--> in non-targeted users: \n",
      "cpit = 4.301807613857797\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.04\n",
      "nipu_cohort: -0.14\n",
      "lift targeted cohort vs control: 0.53\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 5.39\n",
      "lift targeted-treated vs control: 1.52\n",
      "cpit cohort: 5.386263\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.50\n",
      "treated_target_rpu: 0.07\n",
      "treated_target_nipu: -0.24\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.07\n",
      "treated_nontarget_rpu: 0.04\n",
      "treated_nontarget_nipu: -0.12\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 49.997912694989076% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 5.2456035508347725\n",
      "--> in non-targeted users: \n",
      "cpit = 4.231417794145651\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.04\n",
      "nipu_cohort: -0.15\n",
      "lift targeted cohort vs control: 0.62\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 5.25\n",
      "lift targeted-treated vs control: 1.42\n",
      "cpit cohort: 5.251455\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.60\n",
      "treated_target_rpu: 0.06\n",
      "treated_target_nipu: -0.22\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.07\n",
      "treated_nontarget_rpu: 0.04\n",
      "treated_nontarget_nipu: -0.12\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.05\n",
      "--- with 59.997495233986896% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 5.08984002687661\n",
      "--> in non-targeted users: \n",
      "cpit = 4.51709097509861\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.05\n",
      "nipu_cohort: -0.16\n",
      "lift targeted cohort vs control: 0.66\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 5.09\n",
      "lift targeted-treated vs control: 1.26\n",
      "cpit cohort: 5.091586\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.70\n",
      "treated_target_rpu: 0.06\n",
      "treated_target_nipu: -0.22\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.07\n",
      "treated_nontarget_rpu: 0.03\n",
      "treated_nontarget_nipu: -0.10\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.05\n",
      "--- with 69.99707777298471% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 5.078752016552878\n",
      "--> in non-targeted users: \n",
      "cpit = 4.1640349081116685\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.05\n",
      "nipu_cohort: -0.17\n",
      "lift targeted cohort vs control: 0.76\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 5.08\n",
      "lift targeted-treated vs control: 1.19\n",
      "cpit cohort: 5.078558\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.80\n",
      "treated_target_rpu: 0.06\n",
      "treated_target_nipu: -0.20\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.07\n",
      "treated_nontarget_rpu: 0.03\n",
      "treated_nontarget_nipu: -0.10\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.05\n",
      "--- with 79.99666031198252% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 5.069994611845951\n",
      "--> in non-targeted users: \n",
      "cpit = 3.8387186198842476\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.05\n",
      "nipu_cohort: -0.17\n",
      "lift targeted cohort vs control: 0.79\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 5.07\n",
      "lift targeted-treated vs control: 1.08\n",
      "cpit cohort: 5.070296\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.90\n",
      "treated_target_rpu: 0.05\n",
      "treated_target_nipu: -0.19\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.07\n",
      "treated_nontarget_rpu: 0.03\n",
      "treated_nontarget_nipu: -0.08\n",
      "nontreated_nontarget_rpu: 0.02\n",
      "nontreated_nontarget_nipu: -0.04\n",
      "--- with 89.99624285098034% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 5.004627928109246\n",
      "--> in non-targeted users: \n",
      "cpit = 3.869799128995379\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.05\n",
      "nipu_cohort: -0.18\n",
      "lift targeted cohort vs control: 0.84\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 5.00\n",
      "lift targeted-treated vs control: 0.97\n",
      "cpit cohort: 5.004974\n",
      "rpu_cohort\n",
      "0.05000080959564787\n",
      "treated_target_rpu\n",
      "0.05108505575781899\n",
      "---------------------------->>>>>>\n",
      "perc - target: 1.00\n",
      "treated_target_rpu: 0.05\n",
      "treated_target_nipu: -0.18\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.00\n",
      "treated_nontarget_nipu: 0.00\n",
      "nontreated_nontarget_rpu: 0.00\n",
      "nontreated_nontarget_nipu: 0.00\n",
      "--- with 99.99582538997815% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.953441500173492\n",
      "--> in non-targeted users: \n",
      "cpit = nan\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.05\n",
      "nipu_cohort: -0.18\n",
      "lift targeted cohort vs control: 0.88\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 4.95\n",
      "lift targeted-treated vs control: 0.88\n",
      "cpit cohort: 4.953280\n",
      "rpu_control: 0.02723167203007112\n",
      "nipu_control: -0.06350085810577477\n",
      "rpu_ft: 0.05108359133126935\n",
      "nipu_ft: -0.1816481303288189\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.10\n",
      "treated_target_rpu: 0.04\n",
      "treated_target_nipu: -0.10\n",
      "nontreated_target_rpu: 0.02\n",
      "nontreated_target_nipu: -0.04\n",
      "treated_nontarget_rpu: 0.05\n",
      "treated_nontarget_nipu: -0.19\n",
      "nontreated_nontarget_rpu: 0.03\n",
      "nontreated_nontarget_nipu: -0.07\n",
      "--- with 9.999582538997815% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 3.8704927443967\n",
      "--> in non-targeted users: \n",
      "cpit = 5.025152779445002\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.03\n",
      "nipu_cohort: -0.07\n",
      "lift targeted cohort vs control: 0.05\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 3.87\n",
      "lift targeted-treated vs control: 0.29\n",
      "cpit cohort: 3.873501\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.20\n",
      "treated_target_rpu: 0.04\n",
      "treated_target_nipu: -0.13\n",
      "nontreated_target_rpu: 0.02\n",
      "nontreated_target_nipu: -0.05\n",
      "treated_nontarget_rpu: 0.05\n",
      "treated_nontarget_nipu: -0.20\n",
      "nontreated_nontarget_rpu: 0.03\n",
      "nontreated_nontarget_nipu: -0.07\n",
      "--- with 19.99916507799563% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 3.8869669221816796\n",
      "--> in non-targeted users: \n",
      "cpit = 5.167667053855713\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.03\n",
      "nipu_cohort: -0.08\n",
      "lift targeted cohort vs control: 0.15\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 3.88\n",
      "lift targeted-treated vs control: 0.48\n",
      "cpit cohort: 3.884642\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.30\n",
      "treated_target_rpu: 0.04\n",
      "treated_target_nipu: -0.14\n",
      "nontreated_target_rpu: 0.02\n",
      "nontreated_target_nipu: -0.05\n",
      "treated_nontarget_rpu: 0.05\n",
      "treated_nontarget_nipu: -0.20\n",
      "nontreated_nontarget_rpu: 0.03\n",
      "nontreated_nontarget_nipu: -0.07\n",
      "--- with 29.998747616993448% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.210133160448\n",
      "--> in non-targeted users: \n",
      "cpit = 5.21986349482062\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.03\n",
      "nipu_cohort: -0.09\n",
      "lift targeted cohort vs control: 0.23\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 4.21\n",
      "lift targeted-treated vs control: 0.55\n",
      "cpit cohort: 4.210655\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.40\n",
      "treated_target_rpu: 0.04\n",
      "treated_target_nipu: -0.14\n",
      "nontreated_target_rpu: 0.02\n",
      "nontreated_target_nipu: -0.05\n",
      "treated_nontarget_rpu: 0.06\n",
      "treated_nontarget_nipu: -0.21\n",
      "nontreated_nontarget_rpu: 0.03\n",
      "nontreated_nontarget_nipu: -0.07\n",
      "--- with 39.99833015599126% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.208252326894815\n",
      "--> in non-targeted users: \n",
      "cpit = 5.3203080872718935\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.04\n",
      "nipu_cohort: -0.10\n",
      "lift targeted cohort vs control: 0.29\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 4.21\n",
      "lift targeted-treated vs control: 0.61\n",
      "cpit cohort: 4.209151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------->>>>>>\n",
      "perc - target: 0.50\n",
      "treated_target_rpu: 0.04\n",
      "treated_target_nipu: -0.15\n",
      "nontreated_target_rpu: 0.02\n",
      "nontreated_target_nipu: -0.05\n",
      "treated_nontarget_rpu: 0.06\n",
      "treated_nontarget_nipu: -0.22\n",
      "nontreated_nontarget_rpu: 0.03\n",
      "nontreated_nontarget_nipu: -0.08\n",
      "--- with 49.997912694989076% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.661019245103469\n",
      "--> in non-targeted users: \n",
      "cpit = 5.1761018600866375\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.04\n",
      "nipu_cohort: -0.11\n",
      "lift targeted cohort vs control: 0.38\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 4.66\n",
      "lift targeted-treated vs control: 0.64\n",
      "cpit cohort: 4.661628\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.60\n",
      "treated_target_rpu: 0.05\n",
      "treated_target_nipu: -0.15\n",
      "nontreated_target_rpu: 0.02\n",
      "nontreated_target_nipu: -0.05\n",
      "treated_nontarget_rpu: 0.06\n",
      "treated_nontarget_nipu: -0.22\n",
      "nontreated_nontarget_rpu: 0.03\n",
      "nontreated_nontarget_nipu: -0.08\n",
      "--- with 59.997495233986896% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.792140942344628\n",
      "--> in non-targeted users: \n",
      "cpit = 5.1375676563001385\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.04\n",
      "nipu_cohort: -0.12\n",
      "lift targeted cohort vs control: 0.47\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 4.79\n",
      "lift targeted-treated vs control: 0.69\n",
      "cpit cohort: 4.792150\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.70\n",
      "treated_target_rpu: 0.05\n",
      "treated_target_nipu: -0.16\n",
      "nontreated_target_rpu: 0.02\n",
      "nontreated_target_nipu: -0.05\n",
      "treated_nontarget_rpu: 0.06\n",
      "treated_nontarget_nipu: -0.23\n",
      "nontreated_nontarget_rpu: 0.03\n",
      "nontreated_nontarget_nipu: -0.09\n",
      "--- with 69.99707777298471% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.725763786563725\n",
      "--> in non-targeted users: \n",
      "cpit = 5.44060525028158\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.04\n",
      "nipu_cohort: -0.14\n",
      "lift targeted cohort vs control: 0.60\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 4.73\n",
      "lift targeted-treated vs control: 0.76\n",
      "cpit cohort: 4.726000\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.80\n",
      "treated_target_rpu: 0.05\n",
      "treated_target_nipu: -0.17\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.06\n",
      "treated_nontarget_nipu: -0.23\n",
      "nontreated_nontarget_rpu: 0.03\n",
      "nontreated_nontarget_nipu: -0.09\n",
      "--- with 79.99666031198252% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.863869049175804\n",
      "--> in non-targeted users: \n",
      "cpit = 5.2872772273358075\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.05\n",
      "nipu_cohort: -0.16\n",
      "lift targeted cohort vs control: 0.69\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 4.86\n",
      "lift targeted-treated vs control: 0.80\n",
      "cpit cohort: 4.864002\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.90\n",
      "treated_target_rpu: 0.05\n",
      "treated_target_nipu: -0.18\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.06\n",
      "treated_nontarget_nipu: -0.24\n",
      "nontreated_nontarget_rpu: 0.04\n",
      "nontreated_nontarget_nipu: -0.10\n",
      "--- with 89.99624285098034% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.828297966086453\n",
      "--> in non-targeted users: \n",
      "cpit = 6.1567422165782215\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.05\n",
      "nipu_cohort: -0.17\n",
      "lift targeted cohort vs control: 0.79\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 4.83\n",
      "lift targeted-treated vs control: 0.85\n",
      "cpit cohort: 4.828146\n",
      "rpu_cohort\n",
      "0.048850116446874745\n",
      "treated_target_rpu\n",
      "0.05108652026833324\n",
      "---------------------------->>>>>>\n",
      "perc - target: 1.00\n",
      "treated_target_rpu: 0.05\n",
      "treated_target_nipu: -0.18\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.00\n",
      "treated_nontarget_nipu: 0.00\n",
      "nontreated_nontarget_rpu: 0.00\n",
      "nontreated_nontarget_nipu: 0.00\n",
      "--- with 99.99582538997815% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.953274760930709\n",
      "--> in non-targeted users: \n",
      "cpit = nan\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.05\n",
      "nipu_cohort: -0.18\n",
      "lift targeted cohort vs control: 0.88\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 4.95\n",
      "lift targeted-treated vs control: 0.88\n",
      "cpit cohort: 4.953194\n",
      "rpu_control: 0.02723167203007112\n",
      "nipu_control: -0.06350085810577477\n",
      "rpu_ft: 0.05108359133126935\n",
      "nipu_ft: -0.1816481303288189\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.10\n",
      "treated_target_rpu: 0.03\n",
      "treated_target_nipu: -0.11\n",
      "nontreated_target_rpu: 0.02\n",
      "nontreated_target_nipu: -0.03\n",
      "treated_nontarget_rpu: 0.05\n",
      "treated_nontarget_nipu: -0.19\n",
      "nontreated_nontarget_rpu: 0.03\n",
      "nontreated_nontarget_nipu: -0.07\n",
      "--- with 9.999582538997815% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 5.01428639875132\n",
      "--> in non-targeted users: \n",
      "cpit = 4.950425303943778\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.03\n",
      "nipu_cohort: -0.07\n",
      "lift targeted cohort vs control: 0.07\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 5.00\n",
      "lift targeted-treated vs control: 0.25\n",
      "cpit cohort: 5.002597\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.20\n",
      "treated_target_rpu: 0.04\n",
      "treated_target_nipu: -0.13\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.04\n",
      "treated_nontarget_rpu: 0.05\n",
      "treated_nontarget_nipu: -0.20\n",
      "nontreated_nontarget_rpu: 0.03\n",
      "nontreated_nontarget_nipu: -0.07\n",
      "--- with 19.99916507799563% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 6.046017419037721\n",
      "--> in non-targeted users: \n",
      "cpit = 4.797256974148165\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.03\n",
      "nipu_cohort: -0.08\n",
      "lift targeted cohort vs control: 0.11\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 6.05\n",
      "lift targeted-treated vs control: 0.47\n",
      "cpit cohort: 6.050557\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.30\n",
      "treated_target_rpu: 0.04\n",
      "treated_target_nipu: -0.13\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.04\n",
      "treated_nontarget_rpu: 0.05\n",
      "treated_nontarget_nipu: -0.20\n",
      "nontreated_nontarget_rpu: 0.03\n",
      "nontreated_nontarget_nipu: -0.07\n",
      "--- with 29.998747616993448% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 5.04367656935683\n",
      "--> in non-targeted users: \n",
      "cpit = 4.928491226947264\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.03\n",
      "nipu_cohort: -0.09\n",
      "lift targeted cohort vs control: 0.19\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 5.04\n",
      "lift targeted-treated vs control: 0.60\n",
      "cpit cohort: 5.042184\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.40\n",
      "treated_target_rpu: 0.05\n",
      "treated_target_nipu: -0.14\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.05\n",
      "treated_nontarget_rpu: 0.05\n",
      "treated_nontarget_nipu: -0.21\n",
      "nontreated_nontarget_rpu: 0.03\n",
      "nontreated_nontarget_nipu: -0.07\n",
      "--- with 39.99833015599126% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 5.411820037331256\n",
      "--> in non-targeted users: \n",
      "cpit = 4.759764408446358\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.03\n",
      "nipu_cohort: -0.10\n",
      "lift targeted cohort vs control: 0.26\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 5.41\n",
      "lift targeted-treated vs control: 0.66\n",
      "cpit cohort: 5.410252\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.50\n",
      "treated_target_rpu: 0.05\n",
      "treated_target_nipu: -0.15\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.05\n",
      "treated_nontarget_rpu: 0.06\n",
      "treated_nontarget_nipu: -0.21\n",
      "nontreated_nontarget_rpu: 0.03\n",
      "nontreated_nontarget_nipu: -0.08\n",
      "--- with 49.997912694989076% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 5.2114841224900195\n",
      "--> in non-targeted users: \n",
      "cpit = 4.784944209818544\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.04\n",
      "nipu_cohort: -0.11\n",
      "lift targeted cohort vs control: 0.35\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 5.21\n",
      "lift targeted-treated vs control: 0.67\n",
      "cpit cohort: 5.211685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------->>>>>>\n",
      "perc - target: 0.60\n",
      "treated_target_rpu: 0.05\n",
      "treated_target_nipu: -0.15\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.05\n",
      "treated_nontarget_rpu: 0.06\n",
      "treated_nontarget_nipu: -0.22\n",
      "nontreated_nontarget_rpu: 0.03\n",
      "nontreated_nontarget_nipu: -0.08\n",
      "--- with 59.997495233986896% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 5.15361733423047\n",
      "--> in non-targeted users: \n",
      "cpit = 4.763641523502547\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.04\n",
      "nipu_cohort: -0.12\n",
      "lift targeted cohort vs control: 0.43\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 5.15\n",
      "lift targeted-treated vs control: 0.71\n",
      "cpit cohort: 5.150900\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.70\n",
      "treated_target_rpu: 0.05\n",
      "treated_target_nipu: -0.16\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.06\n",
      "treated_nontarget_nipu: -0.23\n",
      "nontreated_nontarget_rpu: 0.03\n",
      "nontreated_nontarget_nipu: -0.08\n",
      "--- with 69.99707777298471% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 5.051474968900553\n",
      "--> in non-targeted users: \n",
      "cpit = 4.795292562366148\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.04\n",
      "nipu_cohort: -0.14\n",
      "lift targeted cohort vs control: 0.54\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 5.05\n",
      "lift targeted-treated vs control: 0.76\n",
      "cpit cohort: 5.050840\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.80\n",
      "treated_target_rpu: 0.05\n",
      "treated_target_nipu: -0.17\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.06\n",
      "treated_nontarget_nipu: -0.23\n",
      "nontreated_nontarget_rpu: 0.03\n",
      "nontreated_nontarget_nipu: -0.08\n",
      "--- with 79.99666031198252% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.9659517881669375\n",
      "--> in non-targeted users: \n",
      "cpit = 4.919177399645933\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.04\n",
      "nipu_cohort: -0.15\n",
      "lift targeted cohort vs control: 0.65\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 4.97\n",
      "lift targeted-treated vs control: 0.79\n",
      "cpit cohort: 4.965637\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.90\n",
      "treated_target_rpu: 0.05\n",
      "treated_target_nipu: -0.18\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.06\n",
      "treated_nontarget_nipu: -0.22\n",
      "nontreated_nontarget_rpu: 0.03\n",
      "nontreated_nontarget_nipu: -0.08\n",
      "--- with 89.99624285098034% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.980749357451491\n",
      "--> in non-targeted users: \n",
      "cpit = 4.775718248070693\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.05\n",
      "nipu_cohort: -0.17\n",
      "lift targeted cohort vs control: 0.77\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 4.98\n",
      "lift targeted-treated vs control: 0.86\n",
      "cpit cohort: 4.979570\n",
      "rpu_cohort\n",
      "0.04811730575853775\n",
      "treated_target_rpu\n",
      "0.05108652026833324\n",
      "---------------------------->>>>>>\n",
      "perc - target: 1.00\n",
      "treated_target_rpu: 0.05\n",
      "treated_target_nipu: -0.18\n",
      "nontreated_target_rpu: 0.03\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.00\n",
      "treated_nontarget_nipu: 0.00\n",
      "nontreated_nontarget_rpu: 0.00\n",
      "nontreated_nontarget_nipu: 0.00\n",
      "--- with 99.99582538997815% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 4.953274760930709\n",
      "--> in non-targeted users: \n",
      "cpit = nan\n",
      "rpu_control: 0.03\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.05\n",
      "nipu_ft: -0.18\n",
      "rpu_cohort: 0.05\n",
      "nipu_cohort: -0.18\n",
      "lift targeted cohort vs control: 0.88\n",
      "lift random vs control: 0.88\n",
      "cpit cohort vs control: 4.95\n",
      "lift targeted-treated vs control: 0.88\n",
      "cpit cohort: 4.953194\n",
      "temp:\n",
      "2.553404854109812\n",
      "p_quantile:\n",
      "0.4\n",
      "AUCC results: \n",
      "random: [0.5]\n",
      "rlearner: [0.47550633]\n",
      "duality rlearner 1 with lambda = 0.01:[0.47696234]\n",
      "duality rlearner 2 with lambda = 0.001:[0.47585387]\n",
      "drm: [0.48863398]\n",
      "tqr: [0.52491746]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi40LCBodHRwOi8vbWF0cGxvdGxpYi5vcmcv7US4rQAAIABJREFUeJzsnXlclMX/wN+z3CCKiveFRykiAqIomuaRR5pIKWZa3paaWmqWZYd2Wmrf8ugwTdLMI83UX5qmYVYeoKamQh554FECBoIssOzO749nd1lgWRYEEXnevp6X7DPzzPOZeeaZzzMzn/mMkFKioqKioqICoClrAVRUVFRU7h5UpaCioqKiYkZVCioqKioqZlSloKKioqJiRlUKKioqKipmVKWgoqKiomJGVQplhBBithDi6wLCugohLt9pmYz3HiaE2FkW91YpHkKIzkKIv8pajjuFEGK7EGJEWctRVIQQUgjRzI54Zfb+QwVSCkKIoUKIQ0KINCHENWPFeqCs5brbkFKullL2Kms57EEIsUcIMbas5ShrpJS/Simbl0baZV3G1j6epJQPSym/KiuZ7nUqhFIQQkwDPgLeBWoBDYFPgAFlKdedRgjhWNYylEfUcis+atmVQ6SU9/QBVAHSgAgbcUKA/UAycA1YDDgbw3wACThaxN8DjDX+3Qz4BUgBEoF1FvE+BuKBm8BhoLNF2Gzg6wLk6QpctvhdF9gIJADngSn2yG4Ml8CzwBngvMW58cZzycASQBjDRgK/5bm+oLgOwAJjvs8Dk/KWVZ58NQC+M+YjCVhsPK8BXgUuAteBlUAVY5gr8LUxfjIQg6LY3wH0QIbx+S4u4J4PAPuM18YDI/M+Qxv5Npcb8CkwP0/am4Fpdj6jQ8Z68C/wYQGy5pLBQo5mxr/7AqeAVOAK8EIB9eUC8AJwHKVergNcLcJfNNaVq8BYy3vkubfVMqbwer3B+MxuGtN3A74C/gNijfcvtH4DfYAsQGe8/zEr799I4DdgvjH988DDFmk3BvYay2wXSv21+d4Z5btuLKNwY7mfBm4Ar1jEd0H52LxqPD4CXCzCZ1iU8+g8z9LFKPMlY534DHAr4Hm+ZHzeqcBfQI9SbTNLM/G74TBWrGwKaKiMcYKBDoAjihKIBZ43hvlgWymsAWahNGyuwAMW8Z4EqhvTnQ78g/HlxE6lYEz3MPA64Aw0Af4GehcmuzFcAj8B1SwqnQT+D/BC6TUlAH0sX7I81xcUdzxKI1UfqIry0llVCigK5BjwP8DDsqyML8xZY94qoSiOVcawZ4CtgLsxjWCgct7nUEA5NjK+SE8ATsZnEWjt2gLybS43oAtKQ2hSiFUBLUqDVtgz2g88Zfy7EtChAHlzyWAhh6khuYaxATbev03e+mL8fQGINspWzVgnxlu8D/8AfsYy/ZoClEJBZUzh9VqH0phqjGU3F+XDqaqxrhzH/vo9mzzvCfmVgg4YZ6wfE1AaYWFR9vONaT+AoqhsvXfZRlmcjGkmAN8AnsYy0wKNjfHfBA4ANYEaKB8fb1mU879AK5T6/k2eZ/k/YIvx+Xii1PH3rLz/zVHqXV2L9qhpqbaZpZn43XAAw4B/injN88Ami4dgSymsBJYC9e1I9z8goKDKnqdymipFe+BSnvCXgRWFyW78LYHueeJIciuv9cBM498jyd84FhT3Z+AZi7CH8paVRVio8QWzFrYbmGjxuznKi+6IojD2Aa2tXGd+DgWUxcuWZWHr2gLy3d3it0D5quti/D0O+NmeZ4TypToH8C6kfuSSwUIOU0NyCUVJVi6ovhh/XwCetPj9AfCZ8e8vMTY+xt/NKKJSsKNe780Tbm7kjb/HYmf9xj6lcNYizN2Yn9ooHzHZgLtF+Nd508tTjlrAwfjb05hWe4s4h4Fw49/ngL4WYb2BCxblPNci7H5TORvr0i0sGneU9+N83udpjH8d5d1ysvUcSuqoCHMKSYC3rbFNIcT9Qoj/E0L8I4S4iTL34G1n+i+iPORoIcRJIcRoi3RfEELECiFShBDJKENZ9qZrohFQVwiRbDqAV1CGUOyVPd5Kuv9Y/J2O8gVbEAXFrZsnbWv3MdEAuCilzLYSVhdl6MjERRSFUAtYBewA1gohrgohPhBCONm4T957nrMzrjXM+ZHKG7oWpdcBMBRYbfzb5jMCxqA0CnFCiBghxCPFlGcgylDGRSHEL0KIUBtxS+KZWcWOep03TVv3LKzs7MGcVylluvHPSsb73rA4Z022vCRJKfXGv7XG//+1CNeSuyzz1tu6FmHxecJM1EBRXoct8vyj8XwupJRnUT70ZgPXhRBrhRB188YrSSqCUtgPZKJ0ZwviUyAOuE9KWRmlUgpj2C3j/+4W8Wub/pBS/iOlHCelrIvyFfeJEKKZEKIzisIYDFSVUnqhjO8KikY8yheEl8XhKaXsa4fsZjGLeE97uYYyHGCigY248UDDApTzVZTGwYTpC+9fKaVOSjlHStkS6Ag8Agw3xissX/FA0wLCblHAM7Ugb/prgEFCiEYoX7gbLe5T4DOSUp6RUj6BMszwPrBBCOFRmExCiFwySSljpJQDjOl8j9JrKypFeWaQpwzsrNd5y83WPQur37dTd68B1YQQls+5sPwWBWv19qrFvRvkCTORiKJc/CzyXEVKafXDTEr5jZTyAeO9JEodKjXueaUgpUxBGSNcIoQIF0K4CyGchBAPCyE+MEbzRBlrTBNCtEAZlzRdn4AyyfOkEMLB2BMwNzRCiAghhKnC/4fy0AzGNLMxDpkIIV4HKhcjC9FAqhDiJSGEm1GGVkKIdoXJfgdYDzwnhKgnhPBCmRAriGiUF2WuEMJDCOEqhOhkDFsDTBVCNBZCVELp7ayTUmYLIboJIfyFEA4o+dShlC8oX3BNbNxzNfCQEGKwEMJRCFFdCBFoDDsKPGasD81QvuZtIqX8A+WFXgbskFImW+StwGckhHhSCFFDSmlAmfDGIg+WHAP8hBCBQghXlK9DjGk4G9eQVJFS6oxlYS2NwlgPjBJC+Boby9cKiZ+3jItTr9cDLwshqgoh6qEYJJgorH7/C/gIIYrcVkkpL6JM8M82ll8o0L+o6dhgDfCqEKKGEMIbpZ0xmc+uB0YKIVoay/kNC7kMwBfA/4QQNQGM71DvvDcQQjQXQnQXQrigTPhrKd5zt5t7XikASCkXANNQLFwSUL5OJqF8bYFiqTEUZVLyCxRrDUvGoVgSJKFMNu2zCGsHHBRCpKFMHD0npfwbZcjjRxSrhYsoD7TIXXVjV/YRIBDFssLUKFWxU/bS5AtgJ8rE4R/ANpQGQ583ojEf/VHGSC+hWHk8bgz+EmWYaC9KHjOAycaw2ijWLDdRJkx/McYFxQpmkBDiPyHEQiv3vIQy3DIdxXLkKBBgDP4fimXLvyiWMavzXl8A36CM736TJ2+2nlEf4KSxjnwMDJFSasmDlPI0yuTlLhSrp9/yRHkKuGAcJhyPMl9WJKSU24GFQBTK5P4BY1BmAZfkLePi1Os3UZ73eZS8bTDdz46y+9b4f5IQ4ojdGc1hGMp4fRLwNsr7UVBei8rbKErnOPAncMR4zlTOH6HMu501/m/JS8bzB4zPcxfKXFpeXFAm6hNRhslqosy5lBqmGXoVldtGCPEwyoRmo0Ijq9wVCCF8gRMoppTW5ntK454TUBTjg3fifnnuvQ6Ik1K+UWjkCkqF6CmolA7G7n5f49BMPZQu8qaylkvFNkKIR4UQLkKIqijj01tLUyEIIeoIIToJITRCiOYoPbc7Uk+EEO2EEE2N9+6DsmD1+8Kuq8ioSkHldhAoppb/oQwfxaKMq6rc3TyDYuZ4DmWor7TnoZyBz1GGOH9GWfT3SSnf00RtFBPWNJRhswnGuSGVAlCHj1RUVFRUzKg9BRUVFRUVM+XOWZW3t7f08fEp1rW3bt3Cw8Oaefi9i5rnioGa54rB7eT58OHDiVLKfAvk8lLulIKPjw+HDh0q1rV79uyha9euJSvQXY6a54qBmueKwe3kWQhxsfBY6vCRioqKiooFqlJQUVFRUTFT7oaPVFRUVCoKuiwdiyduwHfDf7inNAGc2cuPpFc5R2xEdSYtGYiTs73+Ie3jnlAKOp2Oy5cvk5GRYTNelSpViI2NvUNS3R2oeb53cXV1pX79+jg5lWyjoHJ3kPBPCod8vyY4uSkGamLAAQADrrimtCB4WRa7NiylbeyT1KhdpZDU7OeeUAqXL1/G09MTHx8fhCjYCWlqaiqenp53ULKyR83zvYmUkqSkJC5fvkzjxo3LWhyVEkaXpeOQ79e4JzfFgKuVGA4YcMM9uSmHfL/moX+fLrEeQ6nNKQghvhRCXBdCnCggXAghFgohzgohjgsh2hT3XhkZGVSvXt2mQlBRuZcQQlC9evVCe8cq5ZPFEzfgkdwEaVUh5CBxxSO5CYuf3WgzXlEozYnmSBTvkAXxMHCf8XgaZV+AYmOPQpBScvDgQSIiIvDw8ECj0eDh4cHgwYOJjo5GXd2tUp5QP4LuXXw33MCAs11xDTjju+FGid271JSClHIvirvighgArJQKBwAvIUSd0pJHp9MxZswYunfvznfffUd6ejpSStLT09m4cSPdu3dn6NCh6HS60hJBRUVFxS7cU5qCcQ6hcBxwT7a1rUjRKMs5hXrk9sN+2XjuWt6IQoinUXoT1KpViz179uQKr1KlCqmpqQXeSErJmDFj+OGHH9Bq87mxx2AwcOvWLTZv3szQoUNZvnx5kb/CvLy88PPzIzs7m0aNGrF06VK8vLyKlIY1Ll68yODBgzl48GCxrtfr9TbL5l6kIuU5IyODPXv2kJaWlu+9uNe5t/NsXy/BhAHnEiuLcjHRLKVcCiwFaNu2rcy7oi82NtbmxOLBgwfZvn27VYVgiVarZfv27cTFxRESElIkGd3c3Dh+/DgAI0aMYOXKlcyaNatIaVijUqVKaDSaYk+cVoRJ17xUpDy7uroSFBSkru69l/j1V/aSiQEXuy/RkEWXrrZG6+2nLBevXSH3Hqb1jedKnAULFhSqEExotVoWLFhwW/cLDQ3lyhUlK2lpafTo0YM2bdrg7+/P5s2bAbhw4QK+vr6MGzcOPz8/evXqZZbx8OHDBAQEEBAQwJIlS8zpZmRkMGrUKPz9/QkKCiIqKgqAyMhIwsPD6dmzJz4+PixevJgPP/yQoKAgunfvzo0bJTfeqKKiUkocPkx2z15c6bLAbH5qH3rSvf4uMTHKUilsAYYbrZA6AClSynxDR0VFCJHv+PbbbzEY7NvW1GAwsH79eqvp2INer2f37t2EhYUBypfcpk2bOHLkCFFRUUyfPt08oX3mzBmeffZZTp48iZeXFxs3KhYEo0aNYtGiRRw7dixX2kuWLEEIwZ9//smaNWsYMWKE2frkxIkTfPfdd8TExDBr1izc3d35448/CAkJYeXKlXbJrqKiUvoYDAaWX7tG/X37EHv20DIykg0PPkhG236c2NWHMzxPUQZxNOiIHVStxOQrteEjIcQaoCvgLYS4jLIrlxOAlPIzlP18+6LsU5oOjCotWe4EWq2WwMBArly5gq+vLz179gSU+YxXXnmFvXv3otFouHLlCv/++y8AjRs3JjBQ2Uc+ODiYCxcukJycTHJyMl26dAHgqaeeYvv27QD89ttvTJ6sbF3cokULGjVqxOnTpwHo1q0bnp6eeHp6UqVKFfr3V/Yn9/PzM8dRUVEpW27psmm26wj/OGjxuX6VyFWRDPtpF9dlH2JYjp4cD6gGBy0Oeg3SxjCSIINbXueYtOTpEpOx1JSClPKJQsIl8Gxp3f9O4+bmxtGjR0lPT6d3794sWbKEKVOmsHr1ahISEjh8+DBOTk74+PiYv+5dXHIetoODg91DXNawTEuj0Zh/azQasrPvyNa7KioqNsjMNFDzyxNUqXyZJeu/Yuy2bRiyvTjFu9ygvTmeQUjWDhFsCvZi5dtH8EhuYjRPtRxS0qNBxy2vc7SNfbJEXV3ccw7xpJT5joiICDQa+7Kq0WgYPHiw1XTswd3dnYULF7JgwQKys7NJSUmhZs2aODk5ERUVxcWLtr3Xenl54eXlxW+//QbA6tWrzWGdO3c2/z59+jSXLl2iefPmdsmloqJSdkgJjzz7N2/sfp9zo59gwpYt3MjuTgwrcimESw1g0mLBF2Ng7pCGPPTv0xwem0JGlTg0ZAAGNGSQ4fUXR55O4eH/ni1RFxdQTqyPbpfp06ezbds2bt26VWhcV1dXpk+fflv3CwoKonXr1qxZs4Zhw4bRv39//P39adu2LS1atCj0+hUrVjB69GiEEPTq1ct8fuLEiUyYMAF/f38cHR2JjIzM1UNQUVG5C7l5kyvT/8fGr+dROfMWmVTlBK+TRCdzFIOAjQNh2VjIcgEkzLl4kTH16jH1iyHwhRJvz549ZiujkrE1yk+526O5bdu2Mu8mO7Gxsfj6+hZ4jZSSoUOHsnnzZptDNG5ubgwYMIBvvvnmnlktWpHMM01UpDyb6v49a55pg7s+z1otLFkCc+dCUhISuE43zvAc2eR83V+pC++/BH+2zp+EzJO/29xk57CUsm1h8e654SNrCCFYuXIl/fr1M7u3sESj0eDu7s6AAQNYuXLlPaMQVFRUyoCsLPj0U2jWDGbMgKQksqjCKd4gltdzKYRN4TB2mXWFUFZUCKUA4OTkxPLly/n5558ZOHBgLt9HgwYNYs+ePaxZs0Z1Q6yiolI89HpYtQpatICJE+HqVQAS6MwBVpJAV3PUf2rB9Pmw8DnIcCsjeQugQswpmBBCEBISwvr168taFBUVlXsFKWHTJnjtNTh1ynxahyfHmUIqD+WK/n/94NMJkO6RNyEL9NDArWiuLkqKCqUUVFRUVEoMKWHnTnj1Vcgzz3lR05FYw1Rc8TafS/CGeTMgxh4POnrBnDLaJ6PCDB+B0XX2zZtEnDyJx969aPbswWPvXgafPEn0zZuq62wVlYqOlHDwIEREgIcHaDTK/4MHQ3S0Eg7w22/QtSv06ZNLIfzn5s2apks5b3gnl0LY0QtGrTAqhMKamQwNtfVujKhVq8SzZw8VpqegMxgYc/4821JSyDAYMDm9SDcY2JiQwLakJPp7e7OyRQuc7FzToKKicg+h08Hw4bBlC2RkgMk1Tno6hg0byPruO/ZKSbbBQN88l2qdnVnZfjLVT/Wlzrmc9uNGVVgwHfaZrE/PucM1Nwj+D5wNedejgU6D+/nKnB3byu61VSVNhWj9pJQMj4vjh+Rk0i0UggkDcMtgYHNiIsPj4orVY3BwcCAwMJBWrVrRv39/kpOTrcabPXs28+fPL3omygGVKlUqaxGKzbvvvmtXPB8fHxITE/OdT0tLY8KECTRt2pQ2bdoQHBzMF198UWh6HTt2LLKsKqWAlDkKIT09RyEY0UiJq15PrzwKQafR8Hnvgbzb5Xua//oI3kk5Teru7krvwKwQDnjRbUsA7nP9YHoA7K0BWo3SAGk18Js37be2InlsIB5OZfe9bpdSEEJUFUK0FkK0MR2lLVhJEp2aytbERLSFNPZag4GtiYnEFMMXv8nNxYkTJ6hWrVou76alQUm4rtDr9SUgSclSVi457FUKBTF27FiqVq3KmTNnOHLkCD/++KNd3mn37dt3W/dVKSGio2HrVkUh2IEBWFmlCgNe+IbKxybRY1eOCVFyFXhjNrz9Gtw0WZ9mC1jbiCef0xH1s4aIVlXwWOCH5pEueIR1ZXBkF6L7tuLAkmqUtQFkoUpBCPEWcBxYCCwwHuXqU3dBfDxaO72kag0GFsTHFx7RBpaus21x7tw5+vTpQ3BwMJ07dyYuLg6ArVu30r59e4KCgnjooYfMDvRmz57NU089RadOnXjqqaeIjIzkscceo0+fPtx33328+OKL5rR37txJaGgonTt3JiIigrS0NED50n3ppZdo06YN3377bS55Lly4QPfu3WndujU9evTg0qVLAIwcOZIpU6bQsWNHmjRpwoYNG2zmy7TAZtCgQbRo0YJhw4aZe18xMTF07NiRgIAAQkJCSE1NJTIykrCwMLp3706PHj0AmDdvHu3ataN169a88cYbZvlatGjByJEjuf/++xk2bBi7du2iU6dO3HfffURHRwNw69YtRo8eTUhICEFBQWZ35QWV18yZM80ODYcNGwZAeHg4wcHB+Pn5sXTp0kKfY3R0NG+//ba5y1+jRg1eeukloGD36ZDTu7JVZip3gAULlMVmdmAAduDKoeaLefGDWtT5Jydsb2eld7D3wTwXCQlhV5g9T09ICKxfD2lpihVrWhqsWwft2pVYbm4Paz5+8vj7+QtwLizenTqCg4NlXk6dOmX+m6ioUjts4eHhIaWUMjs7Ww4aNEhu377darw33nhDzps3T0opZffu3eXp06ellFIeOHBAduvWTUop5Y0bN6TBYJBSSvnFF1/IadOmma9t06aNTE9Pl1JKuWLFCtm4cWOZnJwstVqtbNiwobx06ZJMSEiQnTt3lmlpafLmzZty7ty5cs6cOVJKKRs1aiTff/99q7I98sgjMjIyUkop5fLly+WAAQOklFKOGDFCDho0SOr1enny5EnZtGlTm2UQFRUlK1euLOPj46Ver5cdOnSQv/76q8zMzJSNGzeW0dHRUkopU1JSpE6nkytWrJD16tWTSUlJUkopd+zYIceNGycNBoPU6/WyX79+8pdffpHnz5+XDg4O8vjx41Kv18s2bdrIUaNGSYPBIL///nuzvNOnT5erVq2SUkr533//yfvuu0+mpaUVWF6WspswyZKeni79/PxkYmKiufwSEhJyxd28ebMMDw+3WiZSSqnT6WRKSoqUUsqEhATZtGlT8/MtrMwKw1T3owqpn/ciJZpnd3cplUGkQo9kWsl9rJJRRJmPzZ5RssesKMnPNtqQbb9IXLNvS8zbyTNwSNrRxtozcHUC8AKul6JuKvcU5Dq7INLS0ti3bx8RERHmc5mZmQBcvnyZxx9/nGvXrpGVlUVjC9O0sLAw3Nxyuqo9evSgShWlj9qyZUsuXrxIcnIyp06dolOnThgMBrKzswkNDTVf8/jjj1uVaf/+/Xz33XeA4rLbsucRHh6ORqOhZcuW5p6LLUJCQqhfvz4AgYGBXLhwgSpVqlCnTh3aGT+JKleubI7fs2dPqlVTfMLv3LmTnTt3EhQUZC6rM2fO0LBhQxo3boy/vz+guAXv0aMHQgj8/f25cOECAD///DM//vijee4mIyPD3OuxVl4NGlju9aSwcOFCNm3aBEB8fDxnzpyhevXqheYb4J133uHbb7/l+vXrXL16tUD36bVr1y60zB544AG77qlym2i1SCAVX+IZTBIdMOCMhiyqs58GrMedv7nAaC4TgeUgy75QZTL5RmHVw8UAmXf/NK49SuE94A8hxAkg03RSShlWalKVQwpynT1r1ix++OEHAI4ePWqObzAY8PLyynXOxOTJk5k2bRphYWHs2bOH2bNnm8M8PHKveMnrfjs7OxspJT179mTNmjVW/QDlTcMeLO8j7RjWsCaXLSxlklLy8ssv88wzz+SKc+HCBbtchEsp2bhxYz4PsgcPHrRLrj179rBr1y7279+Pu7s7Xbt2Nbs7t0bLli05duwYBoMBjUbDrFmzmDVrlnloyJb7dEuKWmYqJYfB2Z24zKkk0jGXm2oDriTQhSQ6ItChJ8eYIs1dsniyYEdvwB7POJkaRTEUaVe1O489ausr4H1gLjlzCre3X2UpIrt2zXdE1Khht5mVBhhco4bVdOwhr+vsd955h6NHj+Zr/CtXrkzjxo3N4/pSSvNOaykpKdSrVw+Ar776yk7Jc+jQoQO///47Z8+eBZQxdns22unYsSNr164FlIasc+fORb63LZo3b861a9eIiYkBFMd11hq+3r178+WXX5rnQa5cucL16/Z3VHv06MGiRYvMyuuPP/4o9BonJyd0Oh2glH/VqlVxd3cnLi6OAwcO2Ly2WbNmtG3blldffdU8eZ+RkWG+f1Hdp6vcQaREfrGMuMxpJNIJA27kb7QdMOCSSyFkup1k9BeCHX2wTyHogf3VaNA1reRkLyXsaSvTpZQLpZRRUspfTEepS1aCTG/QADc7bX5dNRqmWxlOKAqWrrNtsXr1apYvX05AQAB+fn7mCcjZs2cTERFBcHAw3t7eNtOwRo0aNYiMjOSJJ54gNDSU0NBQ8yS2LRYtWsSKFSto3bo1q1at4uOPPy7yvW3h7OzMunXrmDx5MgEBAfTs2dPqF3OvXr0YOnQooaGh+Pv7M2jQIFKLYBH24osvotPpaN26NX5+frz22muFXvP000/TunVrhg0bRp8+fcjOzsbX15eZM2fSoUOHQq9ftmwZSUlJZgXRs2dPPvjgAwCGDRvGoUOH8Pf3Z+XKlXa5T1e5AyQkQHg4qU9/SCKhGHC14yJJbYe1vDZfQ0LdItwrSwOb6zPnxbu7lwB2uM4WQnyIMmy0hdzDR0dKVzTrFNt1dmwsmxMSbJqlumk0DPD25htf33vGU2pFciNtoiLlWXWd3bV4F2/bBqNHw7//cpLXSaAL9g3r6EmvGUe/tS1BCGV9gYMEZxvtaIYG9lenwaF6XNhaBY2m+G3LnXCdbc+cQpDxf8vPJQl0L45gZYEQgpUtWjBUp2N7SgraPAvYNCg9hDDjiuZ7RSGoqKjkIT0dXnhBcW1tJIlQ7B/nd0DcNCqEA5Xhw/fQTPTHEPogOMr8K5SzNHCgOg2O1CPuu8q3pRDuFIUqBSlltzshSGnjpNGwvHFj4oD58fFsS0pCazDgptHQr3p1XmjQgHYW1jAqKir3GDEx8OSTYDm/Vrs2hn+KtnuhS6ZQFis0Oov7rW30/8uRSZOeZeqflzmclYJ0NFoZRVej5oVqfDC8MiPmlJ/V/oUqBSHE69bOSynfLHlxShchBCGenqz38ytrUVRUVO4U2dnK7mdz5ih/G9EPGMDcxo1p95Ee5yK4gct0QRleqF2DPXv2mE2sY7rlsUl9uARkLwPsmX29ZXHoUbLqU4oyqaioqJQM585Bly7KXgcmhVCpEmdefpmOf15F/1HVIikEvYD9piU/QpgVwr2EPcNHucxPhRDzgR2lJlEpYvKKO3++Ms+k1YLKZmsEAAAgAElEQVSbG/TrpwwztmunDBWqqKiUc6SEFSvguecUPxJG9O3b8/b9zTn83gle43UqUbRhnSxn+Dai8HjlmeIsr3MH6pe0IKWNTgdjxrjSvTt8950y3ySl8v/GjdC9OwwdqsRTUVEpxyQmwsCBMGZMjkJwdOTMiBF0uQReq9owjWm5FMKVSg5kFLLRWYaL4vE0zmhR3MC5bHZGK23scYj3pxDiuPE4ieIL6aPSF63kMHnF/eEHR2tecTEY4NYt2LxZiVccP2Qm19l+fn4EBASwYMECDHY64bNG165dMZne9u3bl+TkZJKTk/nkk0+KlM7Fixdxc3MjMDCQli1bMnz4cPMirbyMHDmyUGd3Kip3NT/+CP7+yvaYRvRNm/Jmr768/ZXkjWtvEkCAOSy1rgPPv+zMiE16fn8AtK7KEJElegFaF/i9E7z3MubFamW1M1ppY89g2iMWf2cD/0opy9X6e5NXXK3W9tiQVqvEi4mBEHu2zLPA5OYC4Pr16wwdOpSbN28yZ86c4optZtu2bYDi5uGTTz5h4sSJRbq+adOmHD16FL1eT8+ePVm/fr3ZG2hpkJ2djaPj7fmD1+v1ODjc/Qt9VO4S0tPhpZdg8eJcp8/17s346FsM2/YoXSymQqWDZFNvNz6fkkGWi7IK/e1XoUWMA4P/T0+HGHDJVCaV94fC+sHwl2nNYZagoadzme2MVtoU2lOQUl4EbgJVgFpA6/K2n0IRvOKi1Srxb4eaNWuydOlSFi9ejJSSyMhIJk2aZA5/5JFH2LNnDwATJkygbdu2+Pn5mV1E58W0scvMmTM5d+4cgYGBzJgxg+HDh/P999+b4w0bNiyXW+a8ODg4EBISYpdb78OHD/Pggw8SHBxM7969uXbtGgBffPEF7dq1IyAggIEDB5Ju9D8/cuRIxo8fT/v27XnxxReZPXs2o0ePpmvXrjRp0oSFCxea0/76668JCQkhMDCQZ555xuwaolKlSkyfPp2AgAD2799fqIwqKgAcOQLBwbkUgt7bm7nturJoRwte/m8OPhYK4d9mToz9wIlFMzLIMlmjpjnA/+4nblZH3nywJn2/09DjJ+i7Hd563agQ9Ji3yoxt167MdkYrbe65/RSEyH98+23+IaOCMBgUX+fW0ikKTZo0Qa/XF+qz55133uHQoUMcP36cX375hePHjxcYd+7cueav/nnz5jFmzBgiIyMBxb/Ovn376NevX4HXZ2RkcPDgQfr06WNTJp1Ox+TJk9mwYQOHDx9m9OjRzJo1C4DHHnuMmJgYjh07hq+vL8uXLzdfd/nyZfbt28eHH34IQFxcHDt27CA6Opo5c+ag0+mIjY1l3bp1/P777xw9ehQHBwdWr14NKD6a2rdvz7Fjx1TvoCqFo9fDe+9B+/Zg4cblUlAQj98KomnMRMIJR2Ns5vQukqWPuzH0Mx1/t8kZ7HD604tOXwXjtqsuZDvA274wLbDAndGu9gnB/TZ7wncz9uRsMNBUSplV2sJURNavX8/SpUvJzs7m2rVrnDp1itatW9t17YMPPsjEiRNJSEhg48aNDBw40Oqwjal3cf78efr161do+n/99RcnTpwwu//W6/XUqVMHgBMnTvDqq6+SnJxMWloavXv3Nl8XERGRa8inX79+uLi44OLiQs2aNfn333/ZvXs3hw8fNpvyabVaatasCSg9mYEDB9qVd5WKh5SS6Oho5s+fz4n/+z+W5vGbZXB3Z0nd1vz3x8NMokuusNOBLrw2OZvrTSyGDJKd6JpYn58mNECO1zB8eM4wsyGuMryprGfSaMDVFcLCYOXKe99CUd1PoZT4+++/cXBwoGbNmjg6OuaadDY5gTt//jzz588nJiaGqlWrMnLkSJsumq0xfPhwvv76a9auXcuKFSusxjH1LhITE+nUqRNbtmwhLCyMUaNG8ccff1C3bl3zvAUoL5+fn5/VIZyRI0fy/fffExAQQGRkpHkYDOx36z1ixAjee++9fGm7urqq8wgqVtHpdAwfPpwtmzcTkZHBQSmx9D9wAA3LtA8RfnYc/hZWRVlVYP7jrvw0JCOXN1P3Y9X4sV9TOjfLqbPffKPMJ9oyWa8I2DMoZtpPYYcQYovpKG3Biou1rZIiIhRtbw8aDQwebD0de0lISGD8+PFMmjQJIQQ+Pj4cPXoUg8FAfHy8edvImzdv4uHhQZUqVfj333/Zvn27zXQ9PT3zeQsdOXIkH32kGIO1bNnS5vXe3t7MnTvX3CCvWLGCo0eP5lIIoLi4TkhIMCsFnU7HyZMnAcXZXJ06ddDpdOZhn6LQo0cPNmzYYB5Wu3HjhupKWkXBtJAoIgI8PJSX0cMDOXgwc/r149fvv2eFVkukhULIBubSgGg+5Ek5NZeZ6YHObgxaKvjpCQuFcN2FIf80I21K61wKAZQewF2/VeYdwJ6egmk/hT+BItlYCiH6AB+juIlaJqWcmye8oTF9L2OcmVLKbfkSuk2mT1c0/61bhcd1dVXiFxXTzms6nQ5HR0eeeuoppk2bBkCnTp1o3LgxLVu2xNfXlzZtlHn6gIAAgoKCaNGiBQ0aNKBTp04271G9enU6depEq1atePjhh5k3bx61atXC19eX8PBwu+QMDw9n9uzZ/PrrrwXul+Ds7MyGDRuYMmUKKSkpZGdn8/zzz+Pn58dbb71F+/btqVGjBu3bty+SS2tQFNfbb79Nr169MBgMODk5sWTJEho1alSkdFTuMXQ6xR58yxbIyMiZBExPR27YwKtS8grKIikTp3EkkqF0ZRjO5KwZSKlh4M1R7hx52GKoyADVTtTgt8HN8K1dNF9HFQ17XGfHSCmLrCeFEA7AaaAncBmIAZ6QUp6yiLMU+ENK+akQoiWwTUrpYyvd4rnOVhambd4sbZqlurnBgAFKN7K8jBump6fj7+/PkSNHzNtMWlKR3EibqEh5vidcZ5te0C1bFNNSO/gKP+AFGllYFWWTzdoOBla94kyW5eO/7MbUao34sG/tvMmUO+4W19m/CiHeo+j7KYQAZ6WUfxsFWgsMAE5ZxJFg7glWAa7aIU+REUKZIBo6NJvt253QanNbI5XXiaRdu3YxZswYpk6dalUhqKiUC0wLiexQCFl4sJqxNCLMbFUEEOuZxPyX6vB3Jwt7GJ2g/umaxDzVjNqVnUpD8nsSe3oKUVZOSymlzf0UhBCDgD5SyrHG308B7aWUkyzi1AF2AlUBD+AhKeVhK2k9DTwNUKtWrWDTlpEmqlSpQrNmzWzmAyA7W8/Ro04sWuTMjh2O5omkPn2ymTw5i+Dg4q9AvlupiIvAKlKez549S0pKCmlpaeY9ocsbLWfPxnvvXjSFtEUJdOIMz5FFDfM5LRks6+3M99M0GCy8Tojz7jzjIHm8oZ0LlMoJt/Ocu3XrVjI9hVLeT+EJIFJKuUAIEQqsEkK0klLmap2llEuBpaAMH+XtPsXGxto1XJCamkq3bh50y5cjJ+Nx71GRhlJMVKQ8u7q6EhQUVL6Hj2JibFpyZFKdM0whMY+Z6f6aSXz0em2u+1m4bcnQIHbcIO39zrg733sfBnfiOReoFIQQT0opvxZCTLMWLqX8sJC0rwCWmx3XN56zZAzQx5jefiGEK+CNav6qolJxKMDdgERwjUc4x9PoLayKnLjBa497E/VMdRAWCuGUK3z2FhG+lXB3ts/wQiU/tnoKJnut4n5yxQD3CSEaoyiDIcDQPHEuAT2ASCGEL+AKJBTzfoUipeTgzZsF77zm6aluxamicie5ckWZ1DO6OjFxiwacZjopFs7rAGrzA7WdI4ka/23OyVRH2HIGlo3B3d2N6cusjXir2EuBSkFK+bnx/3we3YQQhfqMlVJmCyEmoey94AB8KaU8KYR4EzgkpdwCTAe+EEJMRZl0HikLm+QoJjqDgTHnz7MtJYUMiz2a0w0GNiYksC0pif7GPZqd7lGfJioqdw23bsG8ecphoRAMOHKJoVxkGNLCzNSNeO5nAZXFcb7t1DUnnT+cYfHz8HcMbm5uhIWF3ZMb39xJ7PF9tEcI4WPxux1KL6BQpJTbpJT3SymbSinfMZ573agQkFKeklJ2klIGSCkDpZQ7i5WLwuVgeFwcPyQnk26hEEwYgFsGA5sTExkeF0dx9JLqOltFxQ70emXzm/vuU7bHtLA4SsGPQ3zBBUaZFYIgm4Z8TVvGUpVjZDg782FEhPLSrr8K0zqhuXAYd3d3BgwYwMqVK9Xe/m1ij0nqe8CPQoiFQD2U7ThHlapUJUx0aipbExPRFtLYaw0GtiYmEpOaSkjlyjbj5kV1nZ2D6jpbxRIpJanRqcS/eIikX7MxyEZo+JLq7KcB69HW0XMqbQgitSuW36mexNKc+VTibwBuubiwuVMnYlq0UJSCdzU8PDzo168fL7zwgtpDKCHscZ29AxiPsjJ5NNDXjjUKdxUL4uPR2vnVrjUYWBAff1v3U11nq66zVRQMOgOxjxzkaKcDJOyVGKQzoMGAKwl04ZBYyB/XFiJSu2NqjjRoacYi2jCJSvyNXgizQhjx8svKQiIHoKM7aWlprFu3TlUIJUihn3NCiNdQPKV2AVoDe4QQ06WUP5S2cMVBWDhoKw4GYH1CAuutpCOLYApWFNfZ1apVQ6/X06NHD44fP16gF9O5c+dy4sQJc4/kl19+4X//+x/h4eFm19lfffVVgfcyuc7++OOPbcpkcp29efNmatSowbp165g1axZffvkljz32GOPGjQPg1VdfZfny5UyePBnIcZ3t4ODA7NmziYuLIyoqitTUVJo3b86ECRM4e/as2XW2k5MTEydOZPXq1QwfPtzsOnvB7W5ooXJXIK9fJ+6BH0k8UxMDrlZiOKCRDrhamIPHtkrF22MZbY7txJAp0bq48n+hoSwYPJhDLVrkvtz53ltXdDdgTx+/OhAipdQC+4UQPwLLgLtSKZQ3VNfZquvse46MDFi0iNTZ60lMf7MAhZAbiWT5cMHqkZ4gpgJTC79PlmoQUhrYs3jt+Ty/L6L4M1Kxgeo6W3WdXeGQUtnR6qWX4MIF4nkdA/Ztbi+FoMmfjiCzc7m4LhA91DjrUXg8lSJjz/BRDeAloCXkqPzC3FyUFdaGeAafPMnGhAS7XLxqgEE1arDOz6/YMlhznf3JJ59gMBi4cuWKTdfZtlYrFuQ6OyQkhNq1axfJdXZYWFiBSsTSdXZoaCg6nY7Tp0/j5+eXz3V2vXr1ilQ2PXr0YMCAAUydOpWaNWty48YNUlNTVS+p5Z0DB2DaNLD4kEgiFGXwv3A0EkJPZdvnzB9Ap2GUh77weCpFxp5HsBqIBRoDc4AL2GmSercwvUED3Oxce+Cq0TC9QYPCI+bB5Drbz8+Phx56iF69epknji1dZ0+ZMsWq6+yhQ4cWyXX2jBkzAMyus0eNss8gLDw8nPT0dH799dcC45hcZ7/00ksEBAQQGBjIvn37AMyuszt16kSLvGO8dmDpOrt169b07NnTPImtUg65cAGGDIHQ0FwKgWrVMFA0F9Uu9u7tmKGhYXx1evvY51FVpWjY4xDvsJQyWAhxXErZ2niuWO60S4Liuc6WDI2NZXNCgk2zVDeNhgHe3nzj61tubJ1V19n5qUh5LjPX2Skp8O678PHHkJmZc97JCaZM4feuXUkPc8FJ2u9TTOsKfbcD153BM1uZSLbsaOgBnaIQYof7Er1/b/n191RM7oTrbHs+n00rna4JIfoJIYKAasWSqowQQrCyRQv6eXnhodHky7QGcDcqhJUtWpQbhbBr1y58fX2ZPHmy6jpb5Y4gdTrOz5jBzZo14YMPcimEG927kxodzbM3tXzVfwuO0v61KnoB+0MBAzRwdqFtujfEVoYMjWISmKGh1jlvIr0CuTjOD3cXdZK5tLDnqb0thKiC4pJiEcr+B3aYBtxdOGk0LG/cmDgo2PdREReslTUPPfSQupWlyp1BSrK3bOHf4cNpfPNmrqCDwAtCEPP77zToEMGMzBncz/1FSj7LGb6NADRw1eMW34bcR/sq5et9vFewx/ro/4x/pgCl6Ua71BFCEOLpyfrbmERWUalwHDuGnD4dx927sTQruAjMBNahDNH2y3yIZ3kWN9zMcRxqOKBPNUBGwcO2GS6wrxPEGaeo9BoDrx6P56fO6ntaFtjj+6ixEOJDIcR3QogtpuNOCKeiolIKSAkHD0JEBHh4KF5KPTxg8GBlFzTTvNu1azBmDAQFIXbvNl9+E0UZtADWAp5U5i3e4gVeMCsEg4OBpgua0jG+I6e7OaN1UYaILNEL0LrA753gvZfJMUV1gKiMpNItA5UCsWf46HtgObAV7LLqvHsxvQzz58O2bZi3XuvXD154Adq1Kz97caqoFAedDoYPV/ZDzsjI2Zc2PR02blTei4cfhpYtYcECxZupET3wOTCbHP/2bWnLTGZSnermeBe4QHSPaD6ZpjhvnPpSFg0fgcHrocNBcMmETBdlDmH9YPjLihGb3qF8NzXlGXuUQoaUcmHh0e5ydDpcx4xRKn1BL0P//somzU735i5sKhUcKXMUgrX9kA0GRQlY8ZT7o0bDNIOBWONvJ5wYxzgiiMgV7zu+43M+x+l3Jz5BUQpaKYlrquHN2UVo6DPVieSywp6S/1gI8YYQIlQI0cZ0lLpkJYnxZXD84QflZcjrHM/0MmzerLw0RXSdnZSURGBgIIGBgdSuXZt69eqZf2dl2Wt8bU1syZw5c2jWrBn3338/3bp148SJE8VOryBu3LjBZ599Zv4dHx/P448/DigWTuHh9u9idfbsWbOrbl9fX0aOHEl2dnaxZatfvz7Jycm5zun1ejp37lzsNO3h77//Ju9e4HlJSUmhTp06PP98zqL/mJgYWrVqRbNmzZg61bo9hpSSiRMn0qxZM1q3bm32ZRUbG0twcDABAQHmBY46nY4ePXqgLWB3siIRHQ1bt1pXCAXh7w87d9JXSrNC8MGHT/k0l0K4wQ1mMpNFLCKLLLO8Ukoc9QIci6AQ9OAQU73weCqlgj1KwR8YB8wFFhiP+aUpVIljfBlEYS+WVqu8NDFFW5tXvXp1jh49ytGjRxk/fjxTp041/3Z2tm+ZvzU+/vhjYmJi+PPPPzl9+jQvvvgi/fv3L5kGwoK8SqFBgwasW7eu2Ok1b96co0eP8ueff3L+/Hk2btxYEmKacXBwsLn4riSwRym88sordMuz4ff48eNZsWIFZ86c4eTJk/z000/5rtu6dSvx8fGcPXuWTz75hGeffRaATz/9lCVLlrB582azU8DFixczatQo3Nzc8qVTZBYsKHDrS6u0bQt//IG+e3ezT61wwvmMz2hKU3O0/exnDGM4yEHzOTc3N65nZdHxlz/ROUh7FzYrZGnomlD0BaQqJYM9SiECaCKlfFBK2c143JUuLgqkKC+DVqvELyE++OADWrVqRatWrVi0aBGgfE37+fkxZMgQfH19GTx4sNWG/v3332fJkiXmBuHhhx+mQ4cOrFmzhuzsbLy8vMxx165dy9ixYwHYvHkz7du3JygoiAEDBpg9tb766quMGTOGBx98kCZNmrBkyRIAZs6cyV9//UVgYCAzZ87k7NmzBAYG5pMnLS3N7FYjKCiIrVu32sy7o6Mj7dq1M7vqPnfuHJ07dyYoKIjg4GAOHlQakV27dtGjRw8ee+wxmjdvzvDhw/OllZ6eTq9evfjyyy9z5d3WtVu2bKF58+YEBwczefJkqz2egmSaOXMmUVFRBAYG5nL7bSI6Oprk5GS6d895FeLj48nIyKBdu3YIIXjqqadyuTY3sXnzZrOcDzzwAP/88w8JCQk4OTmRnp5Oeno6Tk5O3Lhxgx9//LHk9r744Yf8vWRbxMZyIjaWjh07UklXifd4j+d4DhfjSuVMMvmIj3iFV0gmpzen0WhoPWYKjXbHcIAbOemlOkBmIXN2GRo0B6vzzpMVY/Hh3Yg9cwonAC/Atg/ou4XbnSg2GGD9euXISxGHlQ4ePMjq1auJiYkhOzubkJAQunbtipubG6dOnWL58uV06NCB4cOH8/nnn+cahrhx4wbZ2dn5fAK1bduWU6dO2bxvly5dCAsLQwjBRx99xIIFC3j//fcBOH36NLt37yY5ORlfX1/Gjx/P3LlzOXv2rHkY4+zZs1bTffPNN+nTpw+RkZH8999/tG/fnp49e+Lqat0LplarJSYmxrxbXJ06dfjpp59wdXUlLi6OESNGmBvhI0eOcPLkSWrVqkWHDh04cOAAHTp0AJQVyiNGjGDs2LEMHTo033BU3mujo6MJDQ1l4sSJ/P777zRs2JDBgwdblbEgmebOncvixYutNup6vZ4XXniBtWvX5nIkeOXKFRpYuEipX7++1b0rCoo3efJkRowYgU6nY+nSpcyZM4fXXnut5BZTFrGHaUhPp02bNgTrglnOcqpS1Rx2lrO8zdtcJM86GScnGD+P/Y8GkLPuFdhUF6JqwKNXoUOS9dXKWRo4UJ1BZ1sQ8oZq8FFW2NNT8ALihBA7VJPUovHbb78xcOBA3Nzc8PT0JDw83Dzs0bhxY3Oj9+STT/Lbb7+V2H0vXbpEr1698Pf3Z/HixZw8edIc9sgjj+Ds7EzNmjWpVq0aCQkJNlLKzc6dO3nnnXcIDAykW7duZGRkcOnSpXzxTL2OWrVq0ahRI/yM60IyMzMZM2YMrVq1YsiQIbmUW4cOHahbt655W9MLFy7kkvmZZ55h6NChVuXKe+2lS5c4deoUzZs3p1GjRggheOKJJ6xea0umgli0aBHh4eHUrVu30LhFwcfHh19++YV9+/bh5OREQkICTZs25cknn+Txxx8vUFnbTRGHoNKkExN0E3iP93IphHWsYyIT8yuERsHw2XYMjwXknLvhBCsaMWqQEwNXXkXzuzfMbA2/eoPWuFpZq4FfvNHMDODx0y35OtJBNQIsQ+zpKVjfDkzltsj79Zf3d7Vq1XB0dOTSpUs0bNjQfP7w4cOEhYWh0Why7SVt6XL72Wef5ZVXXqFv375s2bIl1/CHNXfW9iKl5Pvvv6dp06Y245nmFBISEggNDWXbtm307duXBQsW0KBBA77++mt0Oh2VKlWyS65OnTqxfft2Bg8ebPWr+XbyZEumgjhw4AD79u1j4cKFpKWlkZWVhYeHB+PHjyfeYte+y5cvW/UiW69ePeLj480fBdbizZo1iw8++ICPPvqICRMmULt2bd58802bmyjZJCMD6tWDM2fsip5CU2J4lUfxMZ9zquPEpuabWBWzCr1Wn9tAfcD7MKE9uFj0pmOq4i2d2fBRVR6s6oWUkuiNqczansiez2uhf98XMjU4uEq6Pazn3WVOqBuolT32bMf5i7XjTghXLKTMf0REKAt07EGjURbxWEuniHTu3JlNmzah1WpJS0tj8+bNZquZ8+fPE2Oc0P7mm2944IEH8l0/Y8YMJk+ebG7wd+zYwZkzZ3j00UfRaDRUrVqVM2fOYDAY2LRpk/m6lJQU6tWrh5SSb775plA5rbnktkbv3r3N8yIAf/zxh834NWrU4L333jPvnWCy1hFC8NVXX1GYM0YT7777Lu7u7kyZMsWu+KB4Y/3rr7+Ij49HSlngxHlBMtkqk7Vr13Lp0iUuXLjA3LlzGT16NO+88w4NGjTAxcWFmJgYpJSsWrWKAQMG5Ls+LCyMlStXAkpvslatWtSoUcMcvnv3bho3bkyTJk1IT09Ho9Gg0WjMW58WmVOnoH17uxSCRBBPBEf5BEcLheAd7k274+2Y9/M8fv75ZwYOHKjsn+HVBt7dA8+H5CiETA38VJPRXdy5MP1+HqyqzP8IIWhfpTK7hjQhO6oGUuuANAiy0zX8tFFVCHcLFcMYePp0+7vOrq5K/BIgJCSEJ554gnbt2tGhQwcmTJiAv78/AL6+vnz44Yf4+vqSnp7O008/ne/6559/nsDAQFq1aoWPjw9jxoxh586d5i/j999/n969e9OxY0fq169vvm727Nk8+uijtGvXzryrmS1q1apFcHAw/v7+zJw5s8B4b7zxBrdu3cLf3x8/Pz9mz55daNqDBg3ixo0bHDhwgEmTJrFs2TICAgI4f/58ri/8wliyZAnJycm88sordsV3d3dn8eLFPPTQQ7Rt2xYvLy+rTgMLkikoKAi9Xk9AQIDVieaC+PTTTxk5ciTNmjXD19eXXr16meVftmwZAP3796devXo0bdqUCRMmmCf8AQwGA++++y6zZs0CFGumiRMnMmDAAKZNm2a3HIDyIfPppxAcDMeP55wv4AMpk+oc5wPOMRFp3BxH467h/qX34/edH87ezoqrmJAQVq9ez5B5l2D5Igi1UO6X3Kh2sQq7X6jD8vb34aFumlT+kFKWqyM4OFjm5dSpU/nO5cJgkHLIEGlwc7P2/Z9zuLlJOWSIEr8UOXPmjAwICCjSNTdv3pTdunWTr732WpGvq2iY8pyamiqllNJgMMhx48bJhQsXlqVYpYKp7kdFReUOSEiQMiwsd/12dZXy44+VOu7hIfVCmMOu84D8le9lFFHmIyY4Rt6Ku5Xvnvti9NL79TOSqKjcx8LDcviROJmi092BnFvJcwXgdvIMHJJ2tLEFzikIIXZLKXsIId6XUr50B/VUySMErFxJ9tChOG3frlhhWJrmaTRKDyEsTFnRfBfOcnl6evLzzz+XtRjlik8//ZTVq1eTmZlJ27ZtGTduXFmLdGfYtUtZhHntGhJIxZf4ymNJymqD4XkQrgFc8+yM061F9OAC//As//BIzvUCGs5siM9sHzTOOb2K9HSY9MEtVtSLhW5pOfFvOlI53ZX1w3zoXa1cedVXsYKtieY6QoiOQJgQYi15dk6VUh4pVclKGicnMpYvxykuzrbvoztAs2bNzOafKqXHjBkzzDvUVQiysmDWLKV+AwYciONlEh0fxJDmaJ4YllpJDW1zsvmI38nGg5y9jl0auOC7yhevB71yJf3TLskT31wlafA5cLX4oLrqSkQrT9U/cq4AACAASURBVJb63o+X6h7mnsCWUngdeA2oD3yYJ0wC5WsBGyg9gJAQ62sQVFTKMW6XLil7JBsn/yUQ5zKbRDphsLJgzMH4z8Viy8wag2tw/2f341Q1p3G/cQMmzcpiTb2/YLiF51KdwCPDhTU9m9LfYpJcpfxToFKQUm4ANgghXpNSvnUHZVJRUSkKy5bRdvJkxezUSGqHUSQe74wh3T4Lr0avN8Jnto/Z5FdK+PZbePrzG6SMj4MaFj68Uh3p27Ayq1r6Uk3tHdxz2LPJzltCiDCgi/HUHpmz8U65QkrJzYM3iZ8fT9K2JAxaAxo3DdX7VafBCw3wbOdZbrbiVKnYSClJv3mTzMuXYdw48+JgnUbD1eeeIzV+NIboRLvS0gtYsfcib/10iZp6V2bUbUTUG95sq30RZsXnslF0zXJkRch9DKlVq+QzpXJXUKhSEEK8B4QAq42nnhNCdJRS2mcbeJdg0Bk4P+Y8KdtSMGQYzOOrhnQDCRsTSNqWhHd/b1qsbIHGqWJY6qqUTwwGA/+cOYN3aiouer35/EngSSk5/fnnbNL2wVna54zRQULoAcBZcl2vZca10zD6DFTOSZsswQPennzXqhU1bsPJo8rdjz2tXz+gp5TySynll0AfsDRVuPuRUhI3PI7kH5IxpBvybxVkAMMtA4mbE4kbHmf3oipLTC4W/Pz8CAgIYMGCBRiMFk6HDh0q0sIrW0RGRnL16lWrYSNHjqRx48YEBgYSEBDAbovdsopzn0mTJuU7/9lnn5kXXt0uXbt2pWHDhrnKOzw83K5VxZaMHDmSDVb2AChqnPKANBhIOXWKOqmpWDbNnwDtgKNSkp6ejqO0x1lBDi6Zxj8cUCaSLRSCo17weav7+LVNG1UhVADsrTleYHZ3mH8FUAEIIfoAH6NUtWVSyrlW4gxG2cxJAseklNYd3NwGqdGpJG5NRGptN/YGrYHErYmkxqRSOaRom4a7ubmZLYquX7/O0KFDuXnzJnPmzKFt27a0bds23zXZ2dlml8T2EhkZSatWrQr0uzNv3jwGDRpEVFQUTz/9NEeOlKyR2Pjx40s0PS8vL37//XceeOABkpOTuXbtWommf0+RkYHh7FmqWswd6IGw/2/vvMOjKrM//jkz6SEESGhCqCIJRUEIVTAqAoqC2FZR0BVBUbABq+iqiIorgot1V+z1JwgKqKi7ohEVpFhBiot0RQmhJaRNZs7vj3szmYSUG0jP+3meebjz3recdybMuW87XyxZxEByyCGMogMVFkV2UecIFVqEhrC2Rw+al+GgoaFm42Sk8AjwvYi8IiKvAt8CD5dWSETcwDPAeUAn4EoR6VQoTwdgGtBfVTsDtx1TUTmwe85ufJnOQgb7Mn3snrO79Iwl0KRJE+bNm8fTTz+NqpKcnMwFF1iDq+nTpzN69Gj69+/P6NGj8Xq9TJ06lcTERE499VSee+45fz2PPvooXbt25bTTTuOuu+5i4cKFrFu3jquuuopu3bqVqKvQt2/fAhE6Z8yYQWJiIl26dGH8+PH+p/OkpCTuvPNOevXqxSmnnFKkTsGHH35I37592b9/P9OnT2e2veWxuLIZGRlcfvnldOrUiZEjR9K7d2/WrVtXpJ1XXHGFX7fg3Xff5eKLL/bfU1WmTp1Kly5d6Nq1qz9UhaoyceJEOnbsyKBBg/yhwcGKDXXeeefRo0cPhgwZUjucjCrs3w8bN+IOcAhHgL0c6xA60hEvXpziFUsa89h2rR8I4xDqFk4Wmv9PRJKxRqcAd6rqHw7q7gVsVdVtAPZZhxFAYBjKccAzqnrQbuuEw3MnS/KJVeCDlAUpJC84tp4kTXJcTbt27fB6vQV+sPLYuHEjX331FeHh4cybN4/o6GjWrl1LdnY2/fv3Z/DgwWzevJklS5awevVqIiIiOHDgAI0aNeLpp59m9uzZRY48Avn4448L6AdMnDiR++67D4DRo0fzwQcfcOGFFwLWiGXNmjUsW7aMBx54gE8//dRf7r333uPxxx9n2bJlNGzYkMIUVfbZZ5+lYcOGbNy4kQ0bNhSpzZDHOeecw7hx4/B6vbz99tvMmzePBx+0Nru9++67/PDDD/z444/s37+fxMREBg4cyKpVq9iyZQsbN27kzz//pFOnTlx33XV4PB4mTZrEm2++Sdu2bZk/fz733HMPL730UomfVbUmNxd27oSDB/1JPuA34E8o8NPvxs1VXMUYxuAug6pNTgi8c1kRN1yw+wSUAw01E0dzF6q6FyhruOwWQOAj9x6gd6E8pwCIyNdYU0zTVfXjwhWJyHhgPFhxepKTkwvcj46OdhTQ7UQprY2i7qenp5ORkUFubi5paWlkZ2czZMgQ//tly5axYcMGFthnJ44cOcKPP/7I8uXLufLKK/F6vaSlpREcHExaWhper5ejR48W2ZbH42HKlCncdddd/P7773z66af+8suWLWPu3LlkZmZy8OBBTj75ZJKSkvB6vQwdOpS0tDQ6duzItm3bSEtLIysri08//ZTVq1ezePFigoKC/PYH2lJU2eTkZCZMmEBaWhqtW7emS5cuRdrs9XrJysqiV69evPzyy6SnpxMTE+P/LD/77DNGjhxJRkYGERER9OvXjxUrVvDFF1/406Oiohg4cCCZmZl89913bNiwwa8l4fV6adq0KWlpaXg8HjIzMyvl76S8cGdkEPbHH7g8+boEmcB2oHBovDjimMY0Ekjwp+WSi6IEU/y20axQWNkfNscXb0fh/2/VhfT09GprW0VRGX0u24R2xbTfAUjCOiS3QkS6qmoBUV5VnQfMA+jZs6cmJSUVqGTTpk1ERVW8UlNpbQTe37ZtG263m3bt2rF7926CgoKIiooiNDSUevXq+fO63W6eeeYZhgwZUqCuL7/8krCwsGPadLvdREZGFmlLcHAws2fP5tJLL+Wpp55i0qRJJCcnExwczOTJk1m3bh1xcXFMnz4dVSUqKgq3203Dhg2JiooiOzsbn89HVFQUYWFhdOjQgW3btrF3715/aOfQ0FBCQ0NLLBsUFERERITfRpfLVaTNeX0ZM2YMI0eOZPr06f48UVFRhISEFPgMgoODCQ8PPyY9KCiI8PBwIiIi6Ny5M//5z3+OaSuvbGX8nZwwqvD771B46is2li2pqeQW2ggxkpHcwA0FDqKtZz2zmMVY91jODjvbmj4NmEH1ijVCWNkfHplGoXgFBSn8/626kJycXG1tqygqo88VuffyNyBQaLWlnRbIHmCpqnpUdTvwC5aTOG6SNOmYV+PLGjvvqcs62VlUPU5JSUnhxhtvZOLEiaWeexgyZAj/+te/8NhPg7/88gtHjx7l3HPP5eWXX/aHSz5wwFrndxrmeuLEifh8Pj799FN/6O3Y2FjS09Md78Jp3bo1ixYtYsyYMQWEekqjf//+/pHPxo0bWb9+fYn5BwwYwLRp044RwhkwYADz58/H6/WSkpLCihUr6NWrFwMHDvSn7927l88//xywdBxSUlL8am4ej6dMdlcLsrNh8+aCDsHthvbtORgdXWC6KIggGtKQW7jF7xA8eHiO57iN2/jd9TsbRmxl9V+68UVoIzKDwSeQGQZfJMHtc+Ghe8Fb3KOhD+LMbqM6h+ORgoiEAVcD4cBbqppaSpG1QAcRaYvlDK4ACu8sWgxcCbwsIrFY00nbnNrklLjJcdZhtaOlLza7wlzETS67aHhmZibdunXD4/EQFBTE6NGjHYU6vv7669mxYwenn346qkrjxo1ZvHgxQ4cO5YcffqBnz56EhIRw/vnnM3PmTK699lpuvPFGwsPDWbVqVbGC7iLC3//+d5544glGjhzJuHHj6NKlC82aNSOxDDGe4uPjefPNN7nssstK1WTO46abbuKaa66hU6dOxMfH07lz5yLDVgfaOmXKlGPSR44cyapVqzjttNMQEWbNmkWzZs0YOXIkn332GZ06daJVq1b07WutkoaEhLBw4UJuvvlmJk+eTG5uLrfddptf+a3ak5pqrR8EBmuMisLTsiW7/viDgwHrCvWpTxOasJ3tZGJtOPiVX5nJTLbZ/4VCgy9g1ffzWDRgH7x3CI5jvfiBtm1PqEuGmoc43ZMvIs8BX2MNQm9Q1QEOypwPzMVaL3hJVR8WkRlYIVyXivUYPQfr7IMXeFhV3y6pzp49e2rhnSybNm0iISGhmBLWbpVNozaRsiSlxG2prnAXsSNiSXgrodacbE5LS6v0KROv14vH4yEsLIxff/2VQYMGsWXLFkIq6amzKvp8Qni9ljM4ECByL4KedBIHgoPZtXs3XvuQmhs3TWlKFFb/tu7fysHzDvI2b/MKr+DBAzTF5X4CX9+z4aZfoXlWwfb2hkIjD4SW8JDkEVrVC2F77964nApUVTJm+qhsiMi3qlryDhVKGCmIyP8Bf1fVX+2kRsA79nXxSiwBqOoyYFmhtPsCrhW4w35VGCJC/GvxeEZ5OPzR4WPmV3FZI4TY4daJ5triEKqKjIwMzjrrLDweD6rKs88+W2kOocaRng7bt1vTRnmEhpITF8eOffs4cuSIPzmSSE5ynYTLl/8j7cXLrdzKBjYALkRuQlvdj+/mvZBYcOosTFzMatOeL59vxjsdNkPvVAjxUWCjkhfwCnGRIWxKTKy2DsFQcZQ0fXQP8JCI7AUeBGYD7wFhWIfNahSuYBdtX2wLmyk29lH9xLIdWDMUTVRUVLHnEgw2qta6QaHT6RoTw/7wcHZv2+Y/ES8IzV3NifJFFXyYaQCZRzPZHrkdjnZD6j+PjmoAl2yCoPwRsfjgL82a8ErHjoS63Ux8A+5YncCkVw6x7qTfIfGANWrIFZp6w3i0Wyuuad68Mj4FQzWkpCip24BRInIGMB/4EBimqs5PxVQiqlrqE76IENUris4Lasgcs6HmoQpHj8Kff8Lhw9b6gMsF0dHQrBlERFi6B9u3W6OEPNxuck46iW0HD5Kemr9cF044LdwtcHvzH+clWAhrHYY72k1MTizXjzvCE5v/RMdtg0Z7AmyBTpERLO7cmQ6R+ZoJItCnj4u1fRphTQAYDPmUNH3UEGth2ANchnXw7BMReUJVna04VhJhYWGkpqYSExNjpn4MVYfPBzt2wKFDBReLfT7r8Nnhw5ZTyMy01hFstF49UurVY/eePf6T5oLQNKgp0bnRBU6oBTUMIrRVKLiFnTtT+eI7N0+0/wFG5E8zAUSJm3kJp5hopoYyU9L00WKsswERwOuqOkJEFgJTRWS8ql5YKRY6oGXLluzZs4eUlJQS82VlZREW5jweTG3A9LkSSUmxfvDLEFDRGxXFviNHyAk4ORxEEA1dDUnxpZCC/TctENwoGHeOm9zNkHJA2ZDuZXqLA9Ayvz2XV7gxrjlPnXyyWQ8wHBclOYUYYCHWFtQbAFQ1E5ghItVqwjE4OJi2DrbOJScn071790qwqPpg+lxJrF4N559vTR05wNe8Oc8NGsSkt97y7yxy4eL2Frdzwb4LSPPkn0VpcE4D4l+Ox90sjMf+6eO+db/hHb0TonIDKoRe0VEs7tLFxCoynBClyXF+jDV4LbDbyA57YTAY8pgzxxolOECB/x45wk2vv+5PaxPShidPepKoHflbaV1hLto92o4WE1uw6hvh0omp7B2+DW4q6HhiCOFvrhz+1qNHuXTFULcpaaH5XeDdSrTFYKi5fPhhwXWEEhCgf8CI4rYOt3HRbxehO/KngaJ6RhH/ejzZTSK55LYM3oveAbcXDK7oznEx7eSWzGjbli+++KI8emEwVHnsI4OhduBwlJBHOBAXGcez7Z6l3vp6KLZDcEObe9sQN60VL77tY+KXO/BcvAvCAxxOrnB2o2gWde1MA6ORbChnjFMwGI4TVWXNmjXMnj2bV1SJLL2Inz9dZ/JGyAx86/N/7MM7hpPwegJ769enw01/sv2s7XBVwdPIzX1hvJuYQJ8SwoYYDCeCcQoGw3Hg8XgYM2YMS5cupV1mJkfBkVPwEMn/uIV9vsFwMN8htLilBS2mt+OGZ47yRvBPcPWBAuWCM4J4tEtrbm9V9rhcBkNZKNUpiMgpwL+ApqraRUROBYar6kMVbp3BUA1RVcaMGcPnS5YwIzOTW7H+IymQRgK7uZxU+uAjBBc5xLCKOBaQSwRb+BvZ5J8dCG0ZSvwr8XyaG8mpD28ja/DvEBKwpTXbxYjYGN4eEE+Y27lwjsFwvDgZKTwPTAWeA1DVn0TkLcA4BUOdZM3q1YS99x7fZWeTp5Ttw80mppFKP3yEkBdQyEcYKQxkPwPQQv/dmlzVhKh7TqbPq3/yS49NcEGAypkPWnvqseyMBDpFlmViymA4MZw4hQhVXVPopHBucZkNhlrNzz8TOXw4LwcEsFNgBdPIoT8hFHVozk3gcbbDUcrjdwjfdknj6PL1MLSgPkbooVD+ldiGv7aoVseBDHUEJ0ce94tIe6y/fUTkUiy9cIOh7pCWBlOnQrdudAk4Ob8XuI0EMulXjEMoiNcFM+8WViTB0ZhM6BLgENKDGBXRnPThvY1DMFQZTpzCzVhTR/Ei8htwGzChQq0yGKoLqvD22xAfD7NnQ641SM7FEgLpCDTgMkJwGBpcYch/7Ou8wXcudDjcgF2DevJmr44EmfAUhiqk1OkjO1rqIBGJBFyqWnOUzw2GE2HjRpg4EWy5zzy+dLmY4PORp1bQl764cbYI7FbouyogQSEmJIhfBnUrH5sNhhPEye6j+wq9B0BVZ1SQTQZD1ZKeDjNmwD//6R8ZANCsGdtvvpkLH3uMwwHiN45HCTahAXo6CKT6zBKdofrgZKE5MNBKGHABsKlizDEYqhBVeOcduOMO+O23/HS3m9wJE3jQ7eah++/3i98ABBOMDx8uRzOxFtkmXp2hGuNk+mhO4HsRmQ18UmEWGQxVwebN1lTR8uUF0884g2+vu44rH3mE//3vf/5kl8tFZ+nMHd47CCrDGVCvwKq+5WW0wVD+HM+J5gigZXkbYjBUCenp8NBD8Pjj4PHkpzdtSuaMGUz+/nv+dd11BYoMGjCIh9s/TPqr6WUaIQDkhMA7lwUkeCEu3OhXG6oPTtYU1oN/m7UbaAyY9QRDzUYVFi60por2BEhYulwwaRL/6d+f6ydPZvfu3f5b9evX5+lxT9NhSQcyvszwO4Qst7KzhYvWfyph2YUbyicrFFb2h83xAYle4QEHWiAGQ2Xh5DHnAuBC+zUYOElVn65QqwyG40EVVq+m0/TpEBlp/cBHRsLll8OaNfmKaJs3w+DBVnqgQ+jfn4PLlzM6NZUhl19ewCGMHDqS5IuSiZsTR9bW/CB16zoEce0bws0vKl/3h8wwa4ooEK9AZih83R8emUb+VtQsF8284VxjJDMN1YiSNJrzFL0Lb0GtLyKo6oHCZQyGKsPjgTFjYOlSYgMlMTMyYNEiWLYMzjsP2raFuXMLThU1aYLOmsU7YWFMvPzyArKusbGx/Pv6f3PSWydx+OPD/vT0UOHZicpHw3L9P/IP/Q0Gra3Ppc8H03rXQULwkR0Kq/rAgitgS94IwQt4XERsr8/W67sY2UxDtaKk6aNvsaaNpIh7CrSrEIsMhrKi6ncIZGQcO/z1+SyZzEWLCuonu1xw883snTCBCdOmsWTJkgLFrr30Wm4NuZVD/zhENvnzQisT4Z9Tlf2N8/PG/FGfRee058wh0XjutM1530dGqzQ4cw+0TrXsyHbBmkb03ncSX85thJFDMFQ3SlJeMxOdhprBmjXw/vvWqKAkAh1Cv37o00/z0nffMblvXw4fzh8FtGjRguf/+jzRL0Vz6PdD/vTDUfDULbD8HPyPSuEp4Tyd2Jrrkpr58wUHw1tvwdq1LmbPjmbZnGgyMyE8HIYNgylTIDGxPDpuMJQ/jnYfiUhDoAPkB3dR1RUVZZTBUCbKoI8MQK9ebHv1VcbdcAOfffZZgVuTxkxibOZYDj50kBzyo5YmnwlP3AqHGlrv3YdCmNrhJB4e2KrI6R8R6NULFiw4rh4ZDFWGk91H1wO3Ym1D/QHoA6wCzq5Y0wwGh5RBHxnA88MPdD3tNDICRhbt27XnhdEvEPxsMAdTDvrTDzS0nMGKM+2EDDeXxjbm9QEdjL6BoVbiZKRwK5AIfKOqZ4lIPDCzYs0yGMpAGfWRXTk5ZORYowCXy8W0G6Zx2W+XcfCBg3jIX4D+ZDA8czOk1QdyhN6hDXjv7I40Dys9GqrBUFNx4hSyVDVLRBCRUFXdLCIdK9wyg8EJqmhICJJdwgGBQuS5kK5duvLvS/5N7hM+Dh7KHx3sawyP3wGr+wA+aJtbj0V9O9I9Kqp8bTcYqiFOnMIeEWkALAb+KyIHgZ0Va5bB4ICvvsJ31124inAIxUljNmIVv/AO/7jjGs75cQjpDxwqUO79C+C5G+BoPWiQFcpLPU5mZOPGx9RvMNRWnMQ+GmlfTheRz4Fo4OMKtcpgKIkffoC774aPPiry9KUPN5uZxv4ipDH3M5BGQUkkzhXSffkO4ffmMGcyfNcDQrKCeLRdK/7WqlXl9MdgqEaUempGRJ4UkX4AqvqFqi5V1ZzSytllh4rIFhHZKiJ3lZDvEhFREenp3HRDneOXX+CKK6B7d/joI3+yB/gFyMAaIVgOoT8+wuEYnQM35Aoue13aByy6GMa+CD90dTGuWXPSB/czDsFQZ3EyffQt8Hd7HeE94G1VXVdaIRFxA88A5wJ7gLUislRVNxbKF4W1mL26rMYb6gi7d1v6Bi+/DF6vP9kHvAncD+wGXqUvZ7sz2e/th8+BNKZPrLWDD4cKg2Mb8FanBGJCTHA6Q92m1JGCqr6qqudj7UDaAjwqIv8rpRhAL2Crqm6zRxZvAyOKyPcg8CiQVcQ9Q10mJcUKWNehA7zwQgGHwEUX0SssjDHAdiCXXlx177+Z3/UBvDgTLFDgrB/dbOzTg0+6nWYcgsFA2UJnnwzEA61xJrLTAusBLo89QO/ADCJyOhCnqh+KyNTiKhKR8cB4gKZNm5KcnFwGs/NJT08/7rI1lZrYZ/fRo8S98w4tFywgqNB204Pdu7Pt+utJ69SJ7wLDUvR4APoeouOs+kXGZSmyHYUeX3n5c906/iw/86uEmvg9nyimzxWDk8Nrs4CRwK9YT/sPquqhkkuVjoi4gMeBa0vLq6rzgHkAPXv21KSkpONqMzk5meMtW1OpUX3OzIRnn4VHHoHU1IL3evWCmTNpeM459ABUleDgYHLs8wZc2AJCUglxtNoVQA415/MpgRr1PZcTps8Vg5ORwq9AX1XdX8a6fwPiAt63tNPyiAK6AMm27nMzYKmIDHeyZmGoRXg88Mor8MADBWUwATp1gocfhhEjrNgRwJ49e5gwYUK+QwDofdBaQw6CEA+OcYWbCKUGQyBOtqQ+d5x1rwU6iEhbLGdwBTAqoN7DQGzeexFJBqYYh1CH8Pms4ED33Qf/K7RM1aaN5SSuugrscBI+n48XXniBqVOncuTIkYDMjQnP9XHzY2VzCLggZljMifbCYKhVHI8cpyNUNVdEJmLpObuBl1T1ZxGZAaxT1aUV1bahmqNq6Rvccw/8+GPBe02bwr33wrhxELDwu3XrVsaNG3fMfGqTJtOIrXcdd4/fQ4u9ZTPDFeYibnJc6RkNhjpEhTkFAFVdBiwrlHZfMXmTKtIWQzXhyy+tg2dffVUwvUEDuPNOmDTJUkuzyc3NZe7cudx7771kZeVvUGvdeggRzV6nj+zkqjV7cAfEw/ujCTQ4BGElrC9kh0Lc8FiiEk3oCoMhECfKa0VilNcMZeL77y1n8HGhw/AREXDrrTB1KjRsWODW+vXrGTt2LGvXrvWnuVzh9Om3lD2uDtzy+0bit+ZrJKRHwtzbIDkJpj0C/VZCSLa1yygPr0BOCOQOjSL+tXjs9SyDwWBjlNcMFcuWLdaaQWFhgeBguOEGawqpWbMCt7Kzs5k5cyYzZ84kNzfXn96+/V850vgxGjf9H/d+sJ2wgJBHP3cTnr3HzcZoLwQpD/0d4jfD5fOhz2oIzbZGB6t6wxdXB/P5dd2NDKbBUARGec1QdlQttbPZs621gaJkxfbssRaKX3ml4KEzlwtGj4b777f0kguxevVqxo4dy88//+xPCw5uQqfEj9nVuh5/27qePovy8+cEw84pDbjpodP4q89Lwtq17Mq0vMXmBJgx3c5oTy+1Cg9lU2KicQgGQzEY5TVD2fB48vWQs7LyxW0yMiwN5A8/hJYtYft2K28gF18MDz5obTMtxNGjR7n33nuZO3cuGiCb2eGUe9nT6maiumzl5ZcOEx2w6eiP9i76ze/K4B7WtFOEK4jtvXszbcUK3goJYU/AltW4sBAebNuWa5o3L7/PwmCohRjlNYNzVPMdQlF6yD6flf7LLwXTBw2CmTOLFSZevnw548aNY/v27f608PBONO3+PnvOTGfS95s4b27BMtk3xnDZPzvhDisY8M7lcnEe8Gi/fsfTQ4OhzmOU1wzOWbMG3n+/aIdQFJ07w5NPwtlFPz8cOnSIqVOn8sILLwSkumkf/2+2dxtMvR47ePhxHycFbDU92sxFn9c7EzPInC8wGCoCo7xmcM6cOc6lL0Usp1CMQ1iyZAkTJkxg7978X/yoqLMJ6vkqOy7by7UrtzHqTgpsNQ2/rBH9n0sguGHwifTCYDCUgFFeMzjnww/z1xBKQ9XKX4h9+/Zxyy23MH/+/IDUesR1X8jupDbEnbqVRx6BjgEzUN76Lrr8qyNNRzU9MfsNBkOpHK/y2kclFDHUVpyOEmy8R49SPzKSYcOGcccdd7Dz4538OvNXrvVcy3jGk0MO64L3sqDfGayf+AcXfbmXG26kwFbTqKRoOr+aQFir0vURDAbDieNkofl1VR0NlvJaXhowuoJtM1Q3QkKgCD3k4sgEMjIyWLxwMfHvxNOXvvSmN25bDS2MMPrmtqXnN7+Rvh5iA49DhgjtZ7aj5e0tEZc5YGYwVBZOpo86B76x2RRCXwAAHMdJREFUFdV6VIw5hmqJ12spn5XBIXiBD+zrO/VO+tGPsCLU0NwK7uyCo4PIrpEkvJFAvVPrnZjdBoOhzJQU5mIacDcQLiJ5u8MFyMHWNjDUAVJSYNQo+PTTMhXLwhLLSCChWIdQFE1GNaHjix2P2WpqMBgqh2KPdarqI6oaBTymqvXtV5SqxqjqtEq00VBVfP01dO9e0CE0bWqdXi6Bo8ASrNjpl3EZITiUuRTQXDUOwWCoQpxoNE8TkRYi0k9EBua9KsM4QxWhCo8/DklJ+aI3IlZI6x07LMGbyEgrZEUAXvIdwjV2Wl/O8K8hlN4upH6YWno+g8FQYThZaP4HlkDORqz/92AFxDNhLmojhw/DX/8K772Xn9aoEbz5Jgwdar1/6y1Yu9Yf+8h79CiZWGsIcwBLJSkWer5KyLqynSnwZTrc8mowGCoEJwvNI4GOqup8ldFQfSkpmN3w4TB9Ovz6a37+3r2tCKetWuWniViayQsWsHLlSs4444wC8YqIuQVGj+f0Fin5sXYdYuQxDYaqxYlT2AYEA8Yp1HRKCma3cCG8807B/LfcAo89VkABLY/09HTuuecennrqqQCHcApc+Do9uuVwzXspdN1QRvuMPKbBUOU4cQoZwA8ispwAx6Cqt1SYVYbyp7RgdoFP+m63NV30l78UWdV///tfxo8fz44dO+yUYEj4Jz3P6MU1K4/S5f1CVaNIkbIcBTHymAZD1ePEKSy1X4aaTFmC2YWEFKl1cPDgQSZPnszLL7+cnxgxiN5nz2L0r4fp/PzRAvk9Li/LfB8QSyw96FHitlRXuItYI49pMFQ5TsJcvCoi4UArVd1SCTYZKoKyBLPLzrbyB8Qnevfdd7n55pv5448/7JRo+vRYwOhDoXT64HCB4jlu5aOgT3gr+2X2sY9gCeZu1930pz/BGuwXvAHAZY0QYofHGnlMg6Ea4GT30YXAbCAEaCsi3YAZqjq8oo0zlCNlCWbn8/mD2f3xxx9MnDiRRYvy5c76NH6YMSEDSPjWS+Aqck4QHBju4j/Zr7AgeQGZnkwiw63YR+dPPp944tk9ezepy1LxZfpwhbuIGRZD3JQ46ifWL8/eGgyG48TJ9NF0oBeQDKCqP4iI0WeuaZQxmJ1mZvLaq69y++23c/DgQQD6ui9mTINbiU/xkb872ZLE3DwigrFzuhLZKpwrGMhLvFRkvZ0XdC4y3WAwVA+cOAWPqh4uNKw3m8lrEqmp1kGzQK3kUjgaHMK1f3qgSVP6H+zCmMhpnHI0HFLzv/qcYFg+OJjR/+zE4A4NK8Jyg8FQyThxCj+LyCjALSIdgFuAlRVrlqG8iFm5Eq680u8QFEgjgd1cTip98BGCixxiWEUcC4hiMz4RPujbl/5ZJ3NN7r/oANZRZZvsEHh/sIv2f2vFowPaVEGvDAZDReHEKUwC7sHajvp/wCfAgxVplKEcOHQIbruNrq++6k/y4WYz09hPP3yEgB1+wkcYKQwklT7EsJIo1zf4tk7moeSCVWaFwvvD4JeLG7H4L52IDHLy52MwGGoSTnYfZWA5hXsq3hxDufDxx3D99flxiwBt0pTNejf7U07BV+TWUDc+wknhLFK853DSnvw7WaGwZAQsGRzKm8MTOKtxg4rvg8FgqBKc7D7qiRVCu01gflU9teLMMhwXR47AlCnw/PMF00eNIu2af7B/5HZ8pS4H5YeZyAyznMH8v8ChaLi8aX3jEAyGWo6T8f+bwFRgPWaBufry2WdWILtdu/xJKcAE4KPFi3lixVmcnHmyo6oU2BUHtz4JhwN8wIepJoKpwVDbceIUUlTVnGiurqSnw113wTPPFEheBNwI7AfIyKBlRkvHVQrQJKWgQwDIdHrOwWAw1FicOIX7ReQFoHDso3crzCqDM778Eq69FrZt8yelAjcD8wtldSx0YxNaRPjDcJeJYGow1Hac/C//K9ANGApcaL8ucFK5iAwVkS0islVE7iri/h0islFEfhKR5SLSuizG11kyM+H22+HMMws4hA/cbjpzrEMAyCGnTE1khxZK8MGwGBPB1GCo7TgZKSSqaseyViwibuAZ4FxgD7BWRJaq6saAbN8DPVU1Q0QmALOAokNzGiy++QauuQZ++SU/LTqap085hVvXrSt20WcjG+lOd0fRSr0Cq/oWTAsRF5PjTARTg6G242SksFJEOh1H3b2Araq6TVVzgLeBEYEZVPVze8srwDeA84nvukZWFtx5J/TvX9AhDB0KGzZw588/49Oi1WzOkqF0dTlzCAA5IfDOZfnvxSNc3CSGxCgTwdRgqO04GSn0wdJT2I61piCAOtiS2gLYHfB+D9C7hPxjgY+KuiEi44HxAE2bNiU5OdmB2ceSnp5+3GWrkqgtW4h/5BEid+70p+VGRLD1ppv44/zzYetWMouJbXRVq3lcv6uDP26dQomuISsUVvaHzfFY4Y28wsAgZWxKCl988UV5dalCqanf84lg+lw3qIw+O3EKQyvUAkBErgZ6AmcWdV9V5wHzAHr27KlJSUnH1U5ycjLHW7ZCKEkac8oUOO00eOgheOSRgnGLzjmHoBdfJL51a+LtpPDwcDICtBKCYhO5o/kczlufX25nHOxpIpz+g4cQr+C2TzSD9fufEwwr+8Ajd4J4XCQGR/N0YlsS69esCKbV7nuuBEyf6waV0WcnJ5p3isgZQAdVfVlEGgP1HNT9GxA4Cd3STiuAiAzCOi19Zp3SgS5JGnPRIksQJyzMCleRR0SEJY95441WgDub7du3U69ePdsphFDv4td5YEtTTg9wCN+dBvefe4D0Z64hwRfHHS3v4JSDp/hDWDe2Q1ifl1jfxDAxGOowTk4034/1FN8ReBlLr/kNoH8pRdcCHUSkLZYzuAIYVaju7sBzwFBV3Vdm62sqpUlj+nyWo8jKyk8bOBBefhna5Uct93q9PPPMM0ybNs1yCN3H03zYWB55LYPWu/LXFz7qJzyeNoPc2Z8BsDNiJ6cuOpVevXpVWBcNBkPNxMn00UigO/AdgKr+LiKlrjiqaq6ITMQKoOcGXlLVn0VkBrDOPhD3GNao4x07NPeuOiHeUxZpTLC2n86eXWB0sGnTJsaOHcuqVaugfnuY/AqdWuby0AMZNAwYXLzQfSdvrrzW/z48PJzhw4eTmJhYTp0xGAy1CSdOIUdVVUQUQEQinVauqsuAZYXS7gu4HuS0rlpFWaQxXS4rsJ3tEDweD7NmzWLGjBnk5OTCyOfhss4kbc5m2t8gxGMVywlS/hEyl8+/X2pX4yIsLIzhw4fz2muvGdlLg8FQJE6cwgIReQ5oICLjgOuA50spYyiJ45TG/Pbbb7nuuuv46aefIP5SuO5O6JnOqLeyGfdCfpGc+vBBj/dYs2Y5IkJERATDhg1jypQpZoRgMBhKxMlC82wRORc4grWucJ+q/rfCLavNlFUaMyODu+68k9mzZ+MLjoVJn8J5wbiD07njMTg/YCNveMdwen94KoPbJ/EkT9bJHRoGg+H4KdEp2KeSP1XVswDjCMqL8HDn6wlAJjBr1iwY8hhcOQBaZxKZ7uOBv0OP7/LzNUhqQOdFnQluFFz+NhsMhjpBiU5BVb0i4hORaFU9XFlG1Xo6d4a1a0vMkiebuZPLSdG+LCeUnGRYlZXJ8nPg+hegTX6UbJpe05SO8zriCjFB6wwGw/HjZE0hHVgvIv8lQKlXVW+pMKtqK16vFaqiFIdQWDbTZR8yC8uGM1dA0hcFTyW3ebANre9pbRaPDQbDCePEKbxrvwwnwuHDMGqUdXI5DxHrzEIACrZD6F+kbKYrMLtA/BvxNBvVrGJsNhgMdQ4nTmEhkKWqXvCvMxQOrGwoia1bYfhw2LQpP+2CC6wTyx99hGZmIvZupDQS7BFCUTrKBXGFuog4OaKirDYYDHUQJxPQy4HwgPfhwKcVY04t5LPPoHfvgg5h2jRYsgQWLCBl/ny+btaMdMCLsN11BV6HPteX42P3nN2lZzQYDAaHOHEKYaqanvfGvjaPp6WgqmyfOhXvoEFw4AAAWcCTvXqx5qKL8AEvvPgiHa66igEtLiDqmTUEff4Ze4MHIo6+FsAHqR8a3WSDwVB+OJk+Oioip6vqdwAi0gNrl6ShGDwZGSSfdhrnbt3qT9uLJSbx7bp1hCYlERUVxb6cKLjxfRjkgyBrDb8oGcyS8GUa3WSDwVB+OHEKt2HFJvoda9NLM4w6WrHo/v380rkz5+7Lj++3DrgIO0Ssz0dmZhaZFz4Jl3SCJjm4c+GMZBj5XslaB0XhCjdbUA0GQ/nh5ETzWhGJxzrNDLBFVT0Va1YNZeNGsocMoXOAQ3gbKy6If2jV+VK4/m/Q7SgND+Qw7HUYvhQa7z+O9lwQM8zoJhsMhvLDyUgBIBFoY+c/XURQ1dcqzKqayLJlcMUVhKWl+ZP+Djyc9yaiCdz4JpwbTMK2o4x8GJKSITi3UD15ujdeSsUV5iJustFNNhgM5YcTPYXXgfbAD+T/VClQp52CqpK2Jo3ds3eRuuRPfJ4wXCwghlXEsoAJbOa9vMwXPkbwyP6cvSWbi25T4rccW19w02BOuuEkmo9rzrap29i/ZH+J6wWucBexw2OJSjS6yQaDofxwMlLoCXRSLUYVvg7i8/jYPGYz+5fux5eRS97jvY8wUhjIHvrQmZUsbbeaRn95gBE7sxl2ezYNiggUspGNXPLmJTS+pDGuUGt9IP61eKv+923HEOgbXNYIIXZ4LPGvxZtTzAaDoVxx4hQ2YC0u761gW2oEqmr9YC9JwZepHLur100o4Qxwn03Xw+cQ849s3IXcaQ45LGc5i1nMb5G/cdOomwrcdwW7SHgrgbS1aeyevZvUZal+2cwYWzazfmLN0k02GAw1AydOIRbYKCJrAP+GyVqvkKZqKaTNnm2tF2RmQng4aX3+yv6vLsaXU/KunxCv0KTQEYI/3QdY4l3IMpZxmMO4XC4uHXZpkeVFhPq96tN5Qefy6pHBYDCUihOnML2ijah2eDz5GspZWfmCOBkZ7P4sFh9lm0n7LiaFd1OfYJV3Fb6AuaCwsDAmT55cnpYbDAbDCeFkS+oXlWFItUE13yEUoXmQSh/ytwiVTjbZTE69/Jh0o5VsMBiqI8U6BRFJgyIfiQVQVa2dk9pr1sD77xcrguMjpEzVBVNQ8MZoJRsMhupMsU5BVevmXsc5c0qUy3SR4yiCaR5et5fIsEgyMzMJDw83WskGg6Fa4/TwWt3hww/z1xAKYU0dlQEXnHTJSaTPTy89r8FgMFQDjFMoTBGjhByi2cok9nFOmaoyJ44NBkNNwziFwoSH+9cTFPiTc9nKzeQS7c8i5Nj3i19fMCeODQZDTcSE2AwkPR0aNAAgk6b8xKNs5u4CDqEp/6E3V9CYL3GRScHjxlgnjiNcxI4wJ44NBkPNw4wU8ti1C4YPR3//g9+4hG2MxRcgOBfKH5zC48SwFoAEHiIttBu7z3iC1G8wJ44NBkOtwDgFgFWr4KKLSN8XwRaeIo1OATd9tOBd2vIiQWT5UyU8nPoj4un81gAwowGDwVBLME7h9dfxjp3ALs9l7GIUGnCuIEx20FFn05Cf8/O7XBAWBsOHw2uvGYdgMBhqFbXaKXhyPDx900ISFh4k4nA7IIQVfExG9K9svrQhkxp8T/qcj9jC02TQJr9cELwx3E3igCb0WdkJlu3wxz5i2DCYMgXMOQODwVALqbVOIeWPw6xLeIMeh9rjowm+gPDWYYfjOf1FD2s5lSzOI3C9fUM8LLqsAUvv7kJUWBDcdn4V9cBgMBgqn1rpFDw5HtYlvEHEofbFnD5248NNFvlnCDLClZcuCOW6BzvxeccGlWeswWAwVCMqdEuqiAwVkS0islVE7irifqiIzLfvrxaRNuXR7tM3LSTyUDvUYTiKHXEZvPtYMxYu6Mf5xiEYDIY6TIU5BRFxA88A5wGdgCtFpFOhbGOBg6p6MvBP4NHyaDth4YEyBK7z0ezIDl64OaE8mjYYDIYaTUWOFHoBW1V1m6rmAG8DIwrlGQG8al8vBM6RcjjtFXG4Pc7DW7vsRWiDwWAwVOSaQgtgd8D7PUDv4vKoaq6IHAZigP2BmURkPDAeoGnTpiQnJ5fSdNnCW/sIcVBnzSQ9Pb3W9q04TJ/rBqbPFUONWGhW1XnAPICePXtqUlJSiflX8HGZwlu7yGFg0tATMbHakpycTGmfV23D9LluYPpcMVTk9NFvQGCI0JZ2WpF5RCQIiAYKKRuXnYzoXwGvw9xeMhpsO9EmDQaDoVZQkU5hLdBBRNqKSAhwBbC0UJ6lwDX29aXAZ6paNgHkIth0aSNcdiTT0nDhYdOljU60SYPBYKgVVJhTUNVcYCLwCbAJWKCqP4vIDBEZbmd7EYgRka3AHcAx21aPh4nPXsrRBtuQgFhFRSFkcbTBr0x85pLyaNZgMBhqPBW6pqCqy4BlhdLuC7jOAi4r73aDQ4Lpuelq1iW8QeShdvb21MDdSF5ceDja4Fd6brqa4JDg4qoyGAyGOkWt1VNo3CyaQX+O59vrD5MVvRkXWYAPF1lkNdjCd+MPc97Bm2ncLLrUugwGg6GuUCN2Hx0vwSHB3P78FfC89T45Odm/y6h27jUyGAyGE6PWjhQMBoPBUHaMUzAYDAaDHymHHaCVioikADuPs3gshU5L1wFMn+sGps91gxPpc2tVbVxaphrnFE4EEVmnqj2r2o7KxPS5bmD6XDeojD6b6SODwWAw+DFOwWAwGAx+6ppTmFfVBlQBps91A9PnukGF97lOrSkYDAaDoWTq2kjBYDAYDCVgnILBYDAY/NRKpyAiQ0Vki4hsFZFjIq+KSKiIzLfvrxaRNpVvZfnioM93iMhGEflJRJaLSOuqsLM8Ka3PAfkuEREVkRq/fdFJn0Xkcvu7/llE3qpsG8sbB3/brUTkcxH53v77Pr8q7CwvROQlEdknIhuKuS8i8qT9efwkIqeXqwGqWqteWOFQfwXaYely/gh0KpTnJuDf9vUVwPyqtrsS+nwWEGFfT6gLfbbzRQErgG+AnlVtdyV8zx2A74GG9vsmVW13JfR5HjDBvu4E7Khqu0+wzwOB04ENxdw/H/gIEKAPsLo826+NI4VewFZV3aaqOcDbwIhCeUYAr9rXC4FzREQq0cbyptQ+q+rnqpphv/0GSwmvJuPkewZ4EHgUShHXqBk46fM44BlVPQigqvsq2cbyxkmfFahvX0cDv1eifeWOqq4ADpSQZQTwmlp8AzQQkebl1X5tdAotgN0B7/fYaUXmUUsM6DAQUynWVQxO+hzIWKwnjZpMqX22h9VxqvphZRpWgTj5nk8BThGRr0XkGxGp6QGBnfR5OnC1iOzB0m+ZVDmmVRll/f9eJmp16GzDsYjI1UBP4MyqtqUiEREX8DhwbRWbUtkEYU0hJWGNBleISFdVPVSlVlUsVwKvqOocEekLvC4iXVTVV9WG1URq40jhNyAu4H1LO63IPCIShDXkTK0U6yoGJ31GRAYB9wDDVTW7kmyrKErrcxTQBUgWkR1Yc69La/his5PveQ+wVFU9qrod+AXLSdRUnPR5LLAAQFVXAWFYgeNqK47+vx8vtdEprAU6iEhbEQnBWkheWijPUuAa+/pS4DO1V3BqKKX2WUS6A89hOYSaPs8MpfRZVQ+raqyqtlHVNljrKMNVdV3VmFsuOPnbXow1SkBEYrGmk7ZVppHljJM+7wLOARCRBCynkFKpVlYuS4Ex9i6kPsBhVd1bXpXXuukjVc0VkYnAJ1g7F15S1Z9FZAawTlWXAi9iDTG3Yi3oXFF1Fp84Dvv8GFAPeMdeU9+lqsOrzOgTxGGfaxUO+/wJMFhENgJeYKqq1thRsMM+TwaeF5HbsRadr63JD3ki8n9Yjj3WXie5HwgGUNV/Y62bnA9sBTKAv5Zr+zX4szMYDAZDOVMbp48MBoPBcJwYp2AwGAwGP8YpGAwGg8GPcQoGg8Fg8GOcgsFgMBj8GKdg8CMi6VVtw/EiInc7zLfD3r9f3u23EZFRxdzrKCLf2hEt+9ppQSLyqYhElLGdeBH5wY4I2r48bC+lvZ4i8mRFt2OoPhinYChX7BPiVYEjp1CBtAGKdArADcCtWHvLp9hpE4A3AoIUOuUiYKGqdlfVX4/H0LKgqutU9ZaKbsdQfTBOwXAMIpIkIskislBENovIm3lRZEUkUURWisiPIrJGRKJE5FoRWSoinwHL7XxTRWSt/XT8gJ3Wxq7vFRH5xa53kB287X8i0svOF2nHlF9jPxGPsNOvFZF3ReRjO/8sO/0fQLj9BP2mnbbYfjr/WUTGO+jzUBH5zu5XXh8a2fX8ZAeXO9VOP9NuK++JPQr4BzDATru9UPUeIMJ+eUSkAXAh8FoJ9nSz2/xJRN4TkYZi6QTcBkwQkc+LKJMuIo/Zff5URHrZ3+M2ERke8B18aff1OxHpZ6ePFEtnQ0Skuf39NLP/Fj6w80wXkVft8jtF5GIRmSUi6+3vJNjO5x+N2SON5LKUN1QxVR073LyqzwtIt/9Nwooc2xLrwWEVcAZWPPttQKKdrz7WqfhrsWLuNLLTB2PFuBe7/AdYMeLbALlAVzv9W+AlO98IYLFdfiZwtX3dACt+T6TdzjasWFVhwE6sKKh+2wP6kmdLOLABiLHf7wBiC+VtjBV1sm2hsk8B99vXZwM/2NfvA/3t63r2Z5AEfFDM59oKSLY/x1OBOUBSKd/FT8CZ9vUMYK59PR2YUkwZBc6zr98D/oN1Eva0ANsjgDD7ugPWqeC88m8AE+3v68qAv4UPAtr+KqDOjELtXVT4M8YKvphclvLmVbWvWhfmwlBurFHVPQAi8gPWD/phYK+qrgVQ1SP2fYD/qmpeDPjB9ut7+309rB+gXcB2VV1vl/sZWK6qKiLr7Tbyyg8XkbypljCsH1bs/Ift8huB1hQMI5zHLSIy0r6Os9svLtxDH2CFWgHkCOjHGcAldtpnIhIjIvWBr4HH7VHJu6q6R0qQ41DVXeTHIzoZy9luEpHXsRztvar6S15+EYkGGqjqF3bSq8A7xTaQTw7wsX29HshWVU+hzzYYeFpEumGFwTgloPwkLAf6jar+XzFtfBRQp7tQe22KKVOe5Q0VjHEKhuIIjKLqpfS/laMB1wI8oqrPBWYQS/Y0sF5fwHtfQBsCXKKqWwqV7+3ELhFJAgYBfVU1w56+CCvFfseo6j9E5EOsNYKvRWRIGYo/DPwduAV4AeupeiZwVTmY5lH7sZuAz1ZVfZK/1nM78CfWk7qLguJDLe1yTUXEpUWHng6ss3B7eW3kkj81Xfhzd1LeUIWYNQVDWdgCNBeRRACx1hOK+o/8CXCdiNSz87UQkSZlaOcTYJKIfx2ju4MynoA56WjgoO0Q4rFGAiXxDTBQRNra7TWy07/E/rG2Hc1+VT0iIu1Vdb2qPooVxTMeSMMK110sInIm8Luq/g9rGsdnvwrsQLJHQgdFZICdNBr4gvIhGmu057Prddu2BWFN5V0JbALuOIE2dgA97OtLTqAeQxVgPLPBMaqaIyJ/AZ4SkXAgE+uJvHC+/4gVwniV/bueDlyN9WTvhAeBucBPYonlbAcuKKXMPDv/d8B1wI0isgnLkX1TSr9S7MXod+329gHnYs2BvyQiP2HNf+eFW79NRM7C+kH/GUvFzgd4ReRHLMGXfwa2YTu4vwN/CbD3Taz/gxOKMOsa4N9ibVndRvlFwnwWWCQiY7CmbvJGeHcDX6rqV3Yf1tqjoePhAeBFEXkQay3FUIMwUVINBoPB4MdMHxkMBoPBj3EKBoPBYPBjnILBYDAY/BinYDAYDAY/xikYDAaDwY9xCgaDwWDwY5yCwWAwGPz8P1UejVhaIWVMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lhmodels = LinearHTEModels() \n",
    "lambds = [0.01, 0.001] #[0.0001, 0.00001] \n",
    "rlearnerscores = [] \n",
    "rl_ridge_model_L_list = [] \n",
    "## set-up lagrangian rlearner \n",
    "for i in range(len(lambds)): \n",
    "    lambd = lambds[i] \n",
    "    rl_ridge_model_L = lhmodels.fit_rlearner_lagrangian(D, o, c, w, lambd) \n",
    "    rl_ridge_model_L_list.append(rl_ridge_model_L) \n",
    "    rlearnerscores.append(rl_ridge_model_L.predict(Dt)) \n",
    "\n",
    "\n",
    "### ---- experimentation and plotting cost-curves ----- \n",
    "from experimentation import * \n",
    "exp = Experimentation() \n",
    "ranscore = np.random.rand(ot.shape[0], ) \n",
    "colors = ['b', 'c', 'g', 'y'] \n",
    "plt.figure() \n",
    "rlearnerauccs = [] \n",
    "ranaucc = exp.AUC_cpit_cost_curve_deciles_cohort(ranscore, ot, wt, -1.0 * ct, 'k', plot_random=True) \n",
    "quasiaucc = exp.AUC_cpit_cost_curve_deciles_cohort(pred_values_va_rlearner_O, ot, wt, -1.0 * ct, 'c') \n",
    "for i in range(len(lambds)): \n",
    "    rlearnerauccs.append(exp.AUC_cpit_cost_curve_deciles_cohort(rlearnerscores[i], ot, wt, -1.0 * ct, colors[i] )) \n",
    "#cfaucc = exp.AUC_cpit_cost_curve_deciles_cohort(cfscore, ot, wt, -1.0 * ct, 'g') # causal forest aucc and plotting \n",
    "tqraucc = exp.AUC_cpit_cost_curve_deciles_cohort(tqrscore, ot, wt, -1.0 * ct, 'r' ) \n",
    "#drmaucc = exp.AUC_cpit_cost_curve_deciles_cohort(drmscore, ot, wt, -1.0 * ct, 'm' ) \n",
    "plt.title('Causal learning cost curves using targeting models') \n",
    "\n",
    "### --- saving data to results folder ---- \n",
    "save_filename = '../results/benchmarkwithcv_tqr_drm_hte_'+prefix+'_main_results.pkl' \n",
    "saveD = {'tqrscore':tqrscore, 'drmscore':drmscore, 'quasiscore':pred_values_va_rlearner, 'quasiscore_O':pred_values_va_rlearner_O, 'rlearnerscore':rlearnerscores, 'ot':ot, 'wt':wt, 'ct':ct, 'tempvalue':tempvalue, 'p_quantilevalue':p_quantilevalue, \n",
    "         'tqraucc':tqraucc, 'drmaucc':drmaucc, 'rlearnerauccs':rlearnerauccs, 'ranaucc':ranaucc, 'quasiaucc':quasiaucc} \n",
    "#'cfscore':cfscore, causal forest scores \n",
    "pkl.dump(saveD, open(save_filename, 'w')) \n",
    "\n",
    "print('temp:') \n",
    "print(tempvalue) \n",
    "print('p_quantile:') \n",
    "print(p_quantilevalue) \n",
    "\n",
    "### --- add legeneds to plot ---- \n",
    "leg_str = ['Random'] \n",
    "leg_str.append('R-learner on Incremental Gain') \n",
    "for i in range(len(lambds)): \n",
    "    leg_str.append('Duality R-learner') \n",
    "#leg_str.append('Causal Forest') # causal forest result \n",
    "leg_str.append('Top Quantile Ranking at ' + str(p_quantile*100) + '%') \n",
    "leg_str.append('Direct Ranking Model') \n",
    "plt.legend(leg_str) \n",
    "\n",
    "### --- print out aucc results for different models --- \n",
    "print('AUCC results: ') \n",
    "print('random: ' + str(ranaucc)) \n",
    "print('rlearner: ' + str(quasiaucc)) \n",
    "i = 0\n",
    "for rlearneraucc in rlearnerauccs: \n",
    "    print('duality rlearner ' + str(i + 1) + ' with lambda = ' + str(lambds[i]) + ':' + str(rlearneraucc)) \n",
    "    i = i + 1\n",
    "print('drm: ' + str(drmaucc)) \n",
    "print('tqr: ' + str(tqraucc)) \n",
    "\n",
    "plt.show() \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
