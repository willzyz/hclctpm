{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, cPickle as pkl \n",
    "import sys, os \n",
    "sys.path.append('../dataprep/') \n",
    "sys.path.append('../models/') \n",
    "from QueryFunctions import * \n",
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nlabel_dates_weekly = \"\\'2019-10-06\\', \\'2019-10-13\\', \\'2019-10-20\\', \\'2019-10-27\\'\" \\ncity_ids = \\'1,5,6,8,10,12,20,23,198\\' \\nfeature_dates=\"\\'2019-09-22\\'\" \\nproposal_start_date = \\'2019-09-30\\' \\n\\npredFrame4 = qr.execute(\\'presto\\', rxgy_data_sapphire_presto_featuremod2(label_dates_weekly, feature_dates,  city_ids)) \\npredFrame4 = pd.DataFrame(predFrame4.load_data()) \\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_query = 0 ### turn this switch on (to 1.0/True vs 0.0/False) to run query using QueryRunner \n",
    "\n",
    "if use_query: \n",
    "    from queryrunner_client import Client \n",
    "    qr = Client(user_email='will.zou@uber.com') \n",
    "    \n",
    "    predFrame2 = qr.execute('presto', r2e_data_sapphire_presto()) \n",
    "    predFrame2 = pd.DataFrame(predFrame2.load_data()) \n",
    "else: \n",
    "    predFrame2 = pd.read_csv('../data/r2e_data_marketing_kdd_paper_gb_data.csv') \n",
    "\n",
    "\"\"\" \n",
    "label_dates_weekly = \"'2019-07-07','2019-06-30','2019-06-23','2019-06-16'\"\n",
    "city_ids = '1,5,6,8,10,12,20,23,198' \n",
    "feature_dates=\"'2019-06-02'\" \n",
    "proposal_start_date = '2019-06-10' \n",
    "\n",
    "predFrame = qr.execute('presto', rxgy_data_sapphire_presto_featuremod2(label_dates_weekly, feature_dates,  city_ids)) \n",
    "predFrame = pd.DataFrame(predFrame.load_data()) \n",
    "\"\"\" \n",
    "\n",
    "\"\"\" \n",
    "label_dates_weekly = \"'2019-08-11', '2019-08-18', '2019-08-25', '2019-09-01'\" \n",
    "city_ids = '1,5,6,8,10,12,20,23,198' \n",
    "feature_dates=\"'2019-07-28'\" \n",
    "proposal_start_date = '2019-08-05' \n",
    "\n",
    "predFrame3 = qr.execute('presto', rxgy_data_sapphire_presto_featuremod2(label_dates_weekly, feature_dates,  city_ids)) \n",
    "predFrame3 = pd.DataFrame(predFrame3.load_data()) \n",
    "\"\"\" \n",
    "\n",
    "\"\"\"\n",
    "label_dates_weekly = \"'2019-10-06', '2019-10-13', '2019-10-20', '2019-10-27'\" \n",
    "city_ids = '1,5,6,8,10,12,20,23,198' \n",
    "feature_dates=\"'2019-09-22'\" \n",
    "proposal_start_date = '2019-09-30' \n",
    "\n",
    "predFrame4 = qr.execute('presto', rxgy_data_sapphire_presto_featuremod2(label_dates_weekly, feature_dates,  city_ids)) \n",
    "predFrame4 = pd.DataFrame(predFrame4.load_data()) \n",
    "\"\"\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1068726\n",
      "368384\n"
     ]
    }
   ],
   "source": [
    "cohort_column_name = 'cohort' \n",
    "treatment_indicator_value = 'treatment' \n",
    "control_indicator_value = 'control' \n",
    "\n",
    "print(len(predFrame2))\n",
    "print(sum(predFrame2[cohort_column_name] == control_indicator_value))\n",
    "predFrame2.to_csv('../data/r2e_data_marketing_kdd_paper_gb_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>ata_trip_max_avg_84d</th>\n",
       "      <th>churns_hard_lifetime</th>\n",
       "      <th>churns_soft_lifetime</th>\n",
       "      <th>cohort</th>\n",
       "      <th>days_active_84d</th>\n",
       "      <th>days_since_last_hard_churn_lifetime</th>\n",
       "      <th>days_since_last_soft_churn_lifetime</th>\n",
       "      <th>...</th>\n",
       "      <th>trip_complete_per_days_active_84d</th>\n",
       "      <th>trip_complete_win7d_sd_84d</th>\n",
       "      <th>trip_incomplete_total_84d</th>\n",
       "      <th>trip_pool_matched_avg_84d</th>\n",
       "      <th>trip_pool_per_x_84d</th>\n",
       "      <th>trip_pool_prc_84d</th>\n",
       "      <th>trip_x_prc_84d</th>\n",
       "      <th>trips_lifetime</th>\n",
       "      <th>useruuid</th>\n",
       "      <th>uuid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>1.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.276385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>df140d8a-7733-4351-a41c-e01850b2bbaf</td>\n",
       "      <td>df140d8a-7733-4351-a41c-e01850b2bbaf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>272.500000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>2.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.372678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>174cff21-848b-4973-99ab-b3850e2308ae</td>\n",
       "      <td>174cff21-848b-4973-99ab-b3850e2308ae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>198.214286</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>29.0</td>\n",
       "      <td>899.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.482759</td>\n",
       "      <td>2.984916</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>199.0</td>\n",
       "      <td>971d40d2-a965-49ac-ba37-87564bff2733</td>\n",
       "      <td>971d40d2-a965-49ac-ba37-87564bff2733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>173.450000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>20.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>1.771691</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>228.0</td>\n",
       "      <td>dcb048e0-7388-4c5e-8afa-2d8c42a4a455</td>\n",
       "      <td>dcb048e0-7388-4c5e-8afa-2d8c42a4a455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>166.083333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>12.0</td>\n",
       "      <td>953.0</td>\n",
       "      <td>1047.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>2.711857</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>75.0</td>\n",
       "      <td>b92beda1-ec65-4587-adee-01f486cd0b5a</td>\n",
       "      <td>b92beda1-ec65-4587-adee-01f486cd0b5a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>260.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>4.0</td>\n",
       "      <td>293.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.640095</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>52.0</td>\n",
       "      <td>563332bf-e639-446e-9017-000933541ea4</td>\n",
       "      <td>563332bf-e639-446e-9017-000933541ea4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>231.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>3.0</td>\n",
       "      <td>503.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3774ca20-1002-42cd-b958-f9f492df533c</td>\n",
       "      <td>3774ca20-1002-42cd-b958-f9f492df533c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>3.0</td>\n",
       "      <td>997.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.623610</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>144.0</td>\n",
       "      <td>884ae0a4-0689-4569-a4d3-1db40fdf51b6</td>\n",
       "      <td>884ae0a4-0689-4569-a4d3-1db40fdf51b6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>208.666667</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>6.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.771691</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>52.0</td>\n",
       "      <td>a3276f9f-5544-4e10-9dfd-b73796284caf</td>\n",
       "      <td>a3276f9f-5544-4e10-9dfd-b73796284caf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>273.250000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>4.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.623610</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>48.0</td>\n",
       "      <td>c99d1b97-a85a-4d16-b6c3-d250a1d68f55</td>\n",
       "      <td>c99d1b97-a85a-4d16-b6c3-d250a1d68f55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>304.600000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>5.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>1.421560</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>33.0</td>\n",
       "      <td>85586bd0-2c5c-44b6-83f2-87450d59a47b</td>\n",
       "      <td>85586bd0-2c5c-44b6-83f2-87450d59a47b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>4.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.862007</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7d3afcd0-bcd8-4e7c-8c39-f0b1f8e02f16</td>\n",
       "      <td>7d3afcd0-bcd8-4e7c-8c39-f0b1f8e02f16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>418.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.595119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>68edb4b0-df6a-4a03-8195-5ef9280fc141</td>\n",
       "      <td>68edb4b0-df6a-4a03-8195-5ef9280fc141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>349.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>3.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.384437</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>54.0</td>\n",
       "      <td>113ee0dd-e992-47a1-ac64-c72fc796389e</td>\n",
       "      <td>113ee0dd-e992-47a1-ac64-c72fc796389e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>287.282051</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>39.0</td>\n",
       "      <td>357.0</td>\n",
       "      <td>458.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.461538</td>\n",
       "      <td>2.680951</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>134.0</td>\n",
       "      <td>354272c5-2427-4af3-b049-19e6ba642b44</td>\n",
       "      <td>354272c5-2427-4af3-b049-19e6ba642b44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>244.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>10.0</td>\n",
       "      <td>647.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.080123</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>269.0</td>\n",
       "      <td>4684a513-71b6-4894-b631-8f812e7fc7c5</td>\n",
       "      <td>4684a513-71b6-4894-b631-8f812e7fc7c5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>464.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>2.0</td>\n",
       "      <td>524.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.372678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>c6faea83-c88a-4411-ac7d-95a125dc65dc</td>\n",
       "      <td>c6faea83-c88a-4411-ac7d-95a125dc65dc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>320.900000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>10.0</td>\n",
       "      <td>555.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.527525</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>94.0</td>\n",
       "      <td>53aa1911-a29d-4218-ae90-7d80f6165af5</td>\n",
       "      <td>53aa1911-a29d-4218-ae90-7d80f6165af5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>236.937500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>32.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.437500</td>\n",
       "      <td>2.034426</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>139.0</td>\n",
       "      <td>e0011c10-0846-4c43-a704-80e69bf48d6f</td>\n",
       "      <td>e0011c10-0846-4c43-a704-80e69bf48d6f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>276.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>6.0</td>\n",
       "      <td>567.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.705791</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1d1494f6-b34a-4783-b464-faba8113fa48</td>\n",
       "      <td>1d1494f6-b34a-4783-b464-faba8113fa48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>2.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.105542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>91.0</td>\n",
       "      <td>01d63b42-0f29-4a80-b639-cb8193e5ee1d</td>\n",
       "      <td>01d63b42-0f29-4a80-b639-cb8193e5ee1d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>1.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.276385</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>cb76ba0c-6e8e-42ec-8c8a-d205e038cade</td>\n",
       "      <td>cb76ba0c-6e8e-42ec-8c8a-d205e038cade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>525.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1259.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.276385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>d8461714-d01f-4faf-9123-0c74539639fc</td>\n",
       "      <td>d8461714-d01f-4faf-9123-0c74539639fc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>172.500000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>4.0</td>\n",
       "      <td>382.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>88.0</td>\n",
       "      <td>e6adb12f-4ee9-4971-a303-a1464a732be9</td>\n",
       "      <td>e6adb12f-4ee9-4971-a303-a1464a732be9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>151.250000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>8.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>0.924211</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>96.0</td>\n",
       "      <td>ec3f25b8-4bf9-4e1a-9913-23295fbafb21</td>\n",
       "      <td>ec3f25b8-4bf9-4e1a-9913-23295fbafb21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>336.111111</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>27.0</td>\n",
       "      <td>919.0</td>\n",
       "      <td>804.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.481481</td>\n",
       "      <td>3.009245</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>483.0</td>\n",
       "      <td>9aa3873c-cc63-498a-bc57-15ab67a2d4ce</td>\n",
       "      <td>9aa3873c-cc63-498a-bc57-15ab67a2d4ce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>206.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>5.0</td>\n",
       "      <td>578.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.645497</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>33.0</td>\n",
       "      <td>123d411b-9357-41b4-a473-9d7081b3b7f0</td>\n",
       "      <td>123d411b-9357-41b4-a473-9d7081b3b7f0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>346.538462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.307692</td>\n",
       "      <td>1.187317</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>225.0</td>\n",
       "      <td>04c2321b-ddc7-4932-887d-ee0aa8e99458</td>\n",
       "      <td>04c2321b-ddc7-4932-887d-ee0aa8e99458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>treatment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62b16b8d-9642-43d2-b05e-994e5a7c826d</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>227.714286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>7.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.640095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>c1962615-0448-4d21-8e7e-5a0dbf9fe17c</td>\n",
       "      <td>c1962615-0448-4d21-8e7e-5a0dbf9fe17c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068696</th>\n",
       "      <td>1068696</td>\n",
       "      <td>1068696</td>\n",
       "      <td>1068696</td>\n",
       "      <td>309.857143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>control</td>\n",
       "      <td>21.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.190476</td>\n",
       "      <td>1.605113</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>93.0</td>\n",
       "      <td>221aae5e-c41a-4079-8852-1889c3ba7ce3</td>\n",
       "      <td>221aae5e-c41a-4079-8852-1889c3ba7ce3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068697</th>\n",
       "      <td>1068697</td>\n",
       "      <td>1068697</td>\n",
       "      <td>1068697</td>\n",
       "      <td>545.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>control</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.953794</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>a7bcbd4a-23d4-494a-821d-bc8272572574</td>\n",
       "      <td>a7bcbd4a-23d4-494a-821d-bc8272572574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068698</th>\n",
       "      <td>1068698</td>\n",
       "      <td>1068698</td>\n",
       "      <td>1068698</td>\n",
       "      <td>218.750000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>control</td>\n",
       "      <td>4.0</td>\n",
       "      <td>618.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>70.0</td>\n",
       "      <td>b8aab666-4b2b-492b-ae3d-bb9a42363424</td>\n",
       "      <td>b8aab666-4b2b-492b-ae3d-bb9a42363424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068699</th>\n",
       "      <td>1068699</td>\n",
       "      <td>1068699</td>\n",
       "      <td>1068699</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>control</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5a7b3caf-a8aa-40de-a327-e25803761d2c</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068700</th>\n",
       "      <td>1068700</td>\n",
       "      <td>1068700</td>\n",
       "      <td>1068700</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>control</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.276385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94936bd2-c03d-44c2-b873-13a4148ceea8</td>\n",
       "      <td>94936bd2-c03d-44c2-b873-13a4148ceea8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068701</th>\n",
       "      <td>1068701</td>\n",
       "      <td>1068701</td>\n",
       "      <td>1068701</td>\n",
       "      <td>260.166667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>control</td>\n",
       "      <td>6.0</td>\n",
       "      <td>909.0</td>\n",
       "      <td>993.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.645497</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0517308d-b85a-4d7d-8c4a-9408d8d30c44</td>\n",
       "      <td>0517308d-b85a-4d7d-8c4a-9408d8d30c44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068702</th>\n",
       "      <td>1068702</td>\n",
       "      <td>1068702</td>\n",
       "      <td>1068702</td>\n",
       "      <td>171.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>control</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>497.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.276385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>53dcb85b-1c2d-4bf9-9fec-fd22f82afa4f</td>\n",
       "      <td>53dcb85b-1c2d-4bf9-9fec-fd22f82afa4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068703</th>\n",
       "      <td>1068703</td>\n",
       "      <td>1068703</td>\n",
       "      <td>1068703</td>\n",
       "      <td>61.500000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>control</td>\n",
       "      <td>2.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.372678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>37.0</td>\n",
       "      <td>5c0621c0-b51f-4a3a-b09a-20d6159bc6a5</td>\n",
       "      <td>5c0621c0-b51f-4a3a-b09a-20d6159bc6a5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068704</th>\n",
       "      <td>1068704</td>\n",
       "      <td>1068704</td>\n",
       "      <td>1068704</td>\n",
       "      <td>216.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>control</td>\n",
       "      <td>3.0</td>\n",
       "      <td>802.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>119.0</td>\n",
       "      <td>4391eead-bae6-45c8-9307-137742f5e101</td>\n",
       "      <td>4391eead-bae6-45c8-9307-137742f5e101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068705</th>\n",
       "      <td>1068705</td>\n",
       "      <td>1068705</td>\n",
       "      <td>1068705</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>control</td>\n",
       "      <td>2.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.372678</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20202959-8005-469c-8c72-adf24bf87356</td>\n",
       "      <td>20202959-8005-469c-8c72-adf24bf87356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068706</th>\n",
       "      <td>1068706</td>\n",
       "      <td>1068706</td>\n",
       "      <td>1068706</td>\n",
       "      <td>271.037736</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>control</td>\n",
       "      <td>53.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.811321</td>\n",
       "      <td>3.651484</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>218.0</td>\n",
       "      <td>fbebc154-7165-4b15-8376-d61766d46828</td>\n",
       "      <td>fbebc154-7165-4b15-8376-d61766d46828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068707</th>\n",
       "      <td>1068707</td>\n",
       "      <td>1068707</td>\n",
       "      <td>1068707</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>control</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.276385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>023b1f83-909e-4520-b7ff-f242ebf57c65</td>\n",
       "      <td>023b1f83-909e-4520-b7ff-f242ebf57c65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068708</th>\n",
       "      <td>1068708</td>\n",
       "      <td>1068708</td>\n",
       "      <td>1068708</td>\n",
       "      <td>356.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>control</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.829156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>478ddd49-750b-4ab2-b778-b7dffb0000be</td>\n",
       "      <td>478ddd49-750b-4ab2-b778-b7dffb0000be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068709</th>\n",
       "      <td>1068709</td>\n",
       "      <td>1068709</td>\n",
       "      <td>1068709</td>\n",
       "      <td>266.166667</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>control</td>\n",
       "      <td>6.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.027402</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>c9124fc2-0348-463b-a20d-b394a6ab11f7</td>\n",
       "      <td>c9124fc2-0348-463b-a20d-b394a6ab11f7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068710</th>\n",
       "      <td>1068710</td>\n",
       "      <td>1068710</td>\n",
       "      <td>1068710</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>control</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.276385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8fa3a74d-d9aa-447c-960a-072fe44d32bb</td>\n",
       "      <td>8fa3a74d-d9aa-447c-960a-072fe44d32bb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068711</th>\n",
       "      <td>1068711</td>\n",
       "      <td>1068711</td>\n",
       "      <td>1068711</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>control</td>\n",
       "      <td>2.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.372678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>71.0</td>\n",
       "      <td>4165f41d-fa37-4b93-aedf-dbbf564cde7c</td>\n",
       "      <td>4165f41d-fa37-4b93-aedf-dbbf564cde7c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068712</th>\n",
       "      <td>1068712</td>\n",
       "      <td>1068712</td>\n",
       "      <td>1068712</td>\n",
       "      <td>282.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>control</td>\n",
       "      <td>3.0</td>\n",
       "      <td>529.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.623610</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>32.0</td>\n",
       "      <td>b4e75f35-2762-4b2b-a584-2f313672562c</td>\n",
       "      <td>b4e75f35-2762-4b2b-a584-2f313672562c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068713</th>\n",
       "      <td>1068713</td>\n",
       "      <td>1068713</td>\n",
       "      <td>1068713</td>\n",
       "      <td>488.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>control</td>\n",
       "      <td>1.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.276385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>39.0</td>\n",
       "      <td>64496eee-2eb5-4065-a682-94a28ddedc5e</td>\n",
       "      <td>64496eee-2eb5-4065-a682-94a28ddedc5e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068714</th>\n",
       "      <td>1068714</td>\n",
       "      <td>1068714</td>\n",
       "      <td>1068714</td>\n",
       "      <td>131.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>control</td>\n",
       "      <td>2.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.372678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>834d0145-08ae-4cf8-bf56-996010516632</td>\n",
       "      <td>834d0145-08ae-4cf8-bf56-996010516632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068715</th>\n",
       "      <td>1068715</td>\n",
       "      <td>1068715</td>\n",
       "      <td>1068715</td>\n",
       "      <td>242.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>control</td>\n",
       "      <td>4.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0dbb7cb8-312b-4f20-bfb8-11ef36d055f4</td>\n",
       "      <td>0dbb7cb8-312b-4f20-bfb8-11ef36d055f4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068716</th>\n",
       "      <td>1068716</td>\n",
       "      <td>1068716</td>\n",
       "      <td>1068716</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>control</td>\n",
       "      <td>2.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.114924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>dec851ab-d314-4ac2-a9ad-e89be964d851</td>\n",
       "      <td>dec851ab-d314-4ac2-a9ad-e89be964d851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068717</th>\n",
       "      <td>1068717</td>\n",
       "      <td>1068717</td>\n",
       "      <td>1068717</td>\n",
       "      <td>272.875000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>control</td>\n",
       "      <td>8.0</td>\n",
       "      <td>762.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.897527</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>93.0</td>\n",
       "      <td>68440cd4-f24a-47c8-ba52-bc362099bc2f</td>\n",
       "      <td>68440cd4-f24a-47c8-ba52-bc362099bc2f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068718</th>\n",
       "      <td>1068718</td>\n",
       "      <td>1068718</td>\n",
       "      <td>1068718</td>\n",
       "      <td>138.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>control</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1175.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.763763</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>61.0</td>\n",
       "      <td>ee459d97-31d5-4104-9c8c-be6fdc1ba564</td>\n",
       "      <td>ee459d97-31d5-4104-9c8c-be6fdc1ba564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068719</th>\n",
       "      <td>1068719</td>\n",
       "      <td>1068719</td>\n",
       "      <td>1068719</td>\n",
       "      <td>270.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>control</td>\n",
       "      <td>4.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.745356</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>d79bc1b5-81e5-4fbe-938c-baef8b2e8006</td>\n",
       "      <td>d79bc1b5-81e5-4fbe-938c-baef8b2e8006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068720</th>\n",
       "      <td>1068720</td>\n",
       "      <td>1068720</td>\n",
       "      <td>1068720</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>control</td>\n",
       "      <td>1.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.276385</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>27.0</td>\n",
       "      <td>28c2924a-48a0-4297-80a3-cc25e72cdced</td>\n",
       "      <td>28c2924a-48a0-4297-80a3-cc25e72cdced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068721</th>\n",
       "      <td>1068721</td>\n",
       "      <td>1068721</td>\n",
       "      <td>1068721</td>\n",
       "      <td>219.909091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>control</td>\n",
       "      <td>11.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.454545</td>\n",
       "      <td>2.560382</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>590c538c-4ad0-4df4-8831-5fa3fa20d7f2</td>\n",
       "      <td>590c538c-4ad0-4df4-8831-5fa3fa20d7f2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068722</th>\n",
       "      <td>1068722</td>\n",
       "      <td>1068722</td>\n",
       "      <td>1068722</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>control</td>\n",
       "      <td>1.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.276385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>fe13ffcb-9661-4226-b893-debdb11bc67e</td>\n",
       "      <td>fe13ffcb-9661-4226-b893-debdb11bc67e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068723</th>\n",
       "      <td>1068723</td>\n",
       "      <td>1068723</td>\n",
       "      <td>1068723</td>\n",
       "      <td>607.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>control</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.276385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3c4b299a-751d-4894-b7d2-d17f23f2563c</td>\n",
       "      <td>3c4b299a-751d-4894-b7d2-d17f23f2563c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068724</th>\n",
       "      <td>1068724</td>\n",
       "      <td>1068724</td>\n",
       "      <td>1068724</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>control</td>\n",
       "      <td>5.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.640095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16c1dbaa-4d22-42ea-b548-d1ababe0cae6</td>\n",
       "      <td>16c1dbaa-4d22-42ea-b548-d1ababe0cae6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068725</th>\n",
       "      <td>1068725</td>\n",
       "      <td>1068725</td>\n",
       "      <td>1068725</td>\n",
       "      <td>348.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>control</td>\n",
       "      <td>1.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.276385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>c0d0762b-ce1d-49e9-b1a7-c1045f9740e0</td>\n",
       "      <td>c0d0762b-ce1d-49e9-b1a7-c1045f9740e0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1068726 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  ata_trip_max_avg_84d  \\\n",
       "0                 0             0               0            113.000000   \n",
       "1                 1             1               1            272.500000   \n",
       "2                 2             2               2            198.214286   \n",
       "3                 3             3               3            173.450000   \n",
       "4                 4             4               4            166.083333   \n",
       "5                 5             5               5            260.500000   \n",
       "6                 6             6               6            231.666667   \n",
       "7                 7             7               7            161.000000   \n",
       "8                 8             8               8            208.666667   \n",
       "9                 9             9               9            273.250000   \n",
       "10               10            10              10            304.600000   \n",
       "11               11            11              11            247.000000   \n",
       "12               12            12              12            418.500000   \n",
       "13               13            13              13            349.333333   \n",
       "14               14            14              14            287.282051   \n",
       "15               15            15              15            244.800000   \n",
       "16               16            16              16            464.000000   \n",
       "17               17            17              17            320.900000   \n",
       "18               18            18              18            236.937500   \n",
       "19               19            19              19            276.000000   \n",
       "20               20            20              20            108.000000   \n",
       "21               21            21              21            203.000000   \n",
       "22               22            22              22            525.000000   \n",
       "23               23            23              23            172.500000   \n",
       "24               24            24              24            151.250000   \n",
       "25               25            25              25            336.111111   \n",
       "26               26            26              26            206.200000   \n",
       "27               27            27              27            346.538462   \n",
       "28               28            28              28                   NaN   \n",
       "29               29            29              29            227.714286   \n",
       "...             ...           ...             ...                   ...   \n",
       "1068696     1068696       1068696         1068696            309.857143   \n",
       "1068697     1068697       1068697         1068697            545.250000   \n",
       "1068698     1068698       1068698         1068698            218.750000   \n",
       "1068699     1068699       1068699         1068699                   NaN   \n",
       "1068700     1068700       1068700         1068700            139.000000   \n",
       "1068701     1068701       1068701         1068701            260.166667   \n",
       "1068702     1068702       1068702         1068702            171.000000   \n",
       "1068703     1068703       1068703         1068703             61.500000   \n",
       "1068704     1068704       1068704         1068704            216.666667   \n",
       "1068705     1068705       1068705         1068705            420.000000   \n",
       "1068706     1068706       1068706         1068706            271.037736   \n",
       "1068707     1068707       1068707         1068707            110.000000   \n",
       "1068708     1068708       1068708         1068708            356.000000   \n",
       "1068709     1068709       1068709         1068709            266.166667   \n",
       "1068710     1068710       1068710         1068710            192.000000   \n",
       "1068711     1068711       1068711         1068711            143.000000   \n",
       "1068712     1068712       1068712         1068712            282.333333   \n",
       "1068713     1068713       1068713         1068713            488.000000   \n",
       "1068714     1068714       1068714         1068714            131.500000   \n",
       "1068715     1068715       1068715         1068715            242.000000   \n",
       "1068716     1068716       1068716         1068716            178.000000   \n",
       "1068717     1068717       1068717         1068717            272.875000   \n",
       "1068718     1068718       1068718         1068718            138.250000   \n",
       "1068719     1068719       1068719         1068719            270.750000   \n",
       "1068720     1068720       1068720         1068720             41.000000   \n",
       "1068721     1068721       1068721         1068721            219.909091   \n",
       "1068722     1068722       1068722         1068722             98.000000   \n",
       "1068723     1068723       1068723         1068723            607.000000   \n",
       "1068724     1068724       1068724         1068724            119.000000   \n",
       "1068725     1068725       1068725         1068725            348.000000   \n",
       "\n",
       "         churns_hard_lifetime  churns_soft_lifetime     cohort  \\\n",
       "0                         1.0                   1.0  treatment   \n",
       "1                         3.0                   3.0  treatment   \n",
       "2                         2.0                   7.0  treatment   \n",
       "3                         0.0                   3.0  treatment   \n",
       "4                         1.0                   0.0  treatment   \n",
       "5                         1.0                   9.0  treatment   \n",
       "6                         1.0                   3.0  treatment   \n",
       "7                         1.0                   7.0  treatment   \n",
       "8                         5.0                   4.0  treatment   \n",
       "9                         1.0                   8.0  treatment   \n",
       "10                        1.0                   3.0  treatment   \n",
       "11                        2.0                   1.0  treatment   \n",
       "12                        0.0                   1.0  treatment   \n",
       "13                        2.0                  12.0  treatment   \n",
       "14                        2.0                   5.0  treatment   \n",
       "15                        1.0                   5.0  treatment   \n",
       "16                        2.0                   7.0  treatment   \n",
       "17                        3.0                   9.0  treatment   \n",
       "18                        1.0                   6.0  treatment   \n",
       "19                        0.0                   5.0  treatment   \n",
       "20                        3.0                   6.0  treatment   \n",
       "21                        1.0                   0.0  treatment   \n",
       "22                        4.0                   0.0  treatment   \n",
       "23                        2.0                   5.0  treatment   \n",
       "24                        3.0                   7.0  treatment   \n",
       "25                        1.0                   4.0  treatment   \n",
       "26                        0.0                   6.0  treatment   \n",
       "27                        0.0                   6.0  treatment   \n",
       "28                        NaN                   NaN  treatment   \n",
       "29                        0.0                   1.0  treatment   \n",
       "...                       ...                   ...        ...   \n",
       "1068696                   1.0                   3.0    control   \n",
       "1068697                   0.0                   0.0    control   \n",
       "1068698                   1.0                   6.0    control   \n",
       "1068699                   NaN                   NaN    control   \n",
       "1068700                   0.0                   0.0    control   \n",
       "1068701                   1.0                   0.0    control   \n",
       "1068702                   3.0                   4.0    control   \n",
       "1068703                   3.0                   8.0    control   \n",
       "1068704                   0.0                   7.0    control   \n",
       "1068705                   0.0                   3.0    control   \n",
       "1068706                   0.0                   0.0    control   \n",
       "1068707                   3.0                   3.0    control   \n",
       "1068708                   0.0                   0.0    control   \n",
       "1068709                   5.0                   8.0    control   \n",
       "1068710                   1.0                   1.0    control   \n",
       "1068711                   1.0                   9.0    control   \n",
       "1068712                   0.0                   6.0    control   \n",
       "1068713                   1.0                   6.0    control   \n",
       "1068714                   1.0                   1.0    control   \n",
       "1068715                   3.0                   8.0    control   \n",
       "1068716                   6.0                   2.0    control   \n",
       "1068717                   1.0                   3.0    control   \n",
       "1068718                   0.0                  18.0    control   \n",
       "1068719                   0.0                   2.0    control   \n",
       "1068720                   3.0                   2.0    control   \n",
       "1068721                   0.0                   1.0    control   \n",
       "1068722                   1.0                   0.0    control   \n",
       "1068723                   0.0                   0.0    control   \n",
       "1068724                   0.0                   0.0    control   \n",
       "1068725                   1.0                   1.0    control   \n",
       "\n",
       "         days_active_84d  days_since_last_hard_churn_lifetime  \\\n",
       "0                    1.0                                641.0   \n",
       "1                    2.0                                196.0   \n",
       "2                   29.0                                899.0   \n",
       "3                   20.0                                918.0   \n",
       "4                   12.0                                953.0   \n",
       "5                    4.0                                293.0   \n",
       "6                    3.0                                503.0   \n",
       "7                    3.0                                997.0   \n",
       "8                    6.0                                239.0   \n",
       "9                    4.0                                377.0   \n",
       "10                   5.0                                296.0   \n",
       "11                   4.0                                184.0   \n",
       "12                   2.0                                 60.0   \n",
       "13                   3.0                                 89.0   \n",
       "14                  39.0                                357.0   \n",
       "15                  10.0                                647.0   \n",
       "16                   2.0                                524.0   \n",
       "17                  10.0                                555.0   \n",
       "18                  32.0                                295.0   \n",
       "19                   6.0                                567.0   \n",
       "20                   2.0                                 74.0   \n",
       "21                   1.0                                122.0   \n",
       "22                   1.0                                 51.0   \n",
       "23                   4.0                                382.0   \n",
       "24                   8.0                                540.0   \n",
       "25                  27.0                                919.0   \n",
       "26                   5.0                                578.0   \n",
       "27                  13.0                               1037.0   \n",
       "28                   NaN                                  NaN   \n",
       "29                   7.0                                127.0   \n",
       "...                  ...                                  ...   \n",
       "1068696             21.0                                202.0   \n",
       "1068697              4.0                                 26.0   \n",
       "1068698              4.0                                618.0   \n",
       "1068699              NaN                                  NaN   \n",
       "1068700              1.0                                 10.0   \n",
       "1068701              6.0                                909.0   \n",
       "1068702              1.0                                 78.0   \n",
       "1068703              2.0                                318.0   \n",
       "1068704              3.0                                802.0   \n",
       "1068705              2.0                                279.0   \n",
       "1068706             53.0                                244.0   \n",
       "1068707              1.0                                 28.0   \n",
       "1068708              2.0                                  8.0   \n",
       "1068709              6.0                                 60.0   \n",
       "1068710              1.0                                100.0   \n",
       "1068711              2.0                                126.0   \n",
       "1068712              3.0                                529.0   \n",
       "1068713              1.0                                327.0   \n",
       "1068714              2.0                                 99.0   \n",
       "1068715              4.0                                153.0   \n",
       "1068716              2.0                                 58.0   \n",
       "1068717              8.0                                762.0   \n",
       "1068718              4.0                               1175.0   \n",
       "1068719              4.0                                115.0   \n",
       "1068720              1.0                                236.0   \n",
       "1068721             11.0                                 85.0   \n",
       "1068722              1.0                                178.0   \n",
       "1068723              1.0                                 13.0   \n",
       "1068724              5.0                                 35.0   \n",
       "1068725              1.0                                217.0   \n",
       "\n",
       "         days_since_last_soft_churn_lifetime  ...  \\\n",
       "0                                       40.0  ...   \n",
       "1                                       17.0  ...   \n",
       "2                                      224.0  ...   \n",
       "3                                      405.0  ...   \n",
       "4                                     1047.0  ...   \n",
       "5                                        0.0  ...   \n",
       "6                                       41.0  ...   \n",
       "7                                       50.0  ...   \n",
       "8                                       46.0  ...   \n",
       "9                                        0.0  ...   \n",
       "10                                      36.0  ...   \n",
       "11                                      67.0  ...   \n",
       "12                                      19.0  ...   \n",
       "13                                      42.0  ...   \n",
       "14                                     458.0  ...   \n",
       "15                                     169.0  ...   \n",
       "16                                      48.0  ...   \n",
       "17                                      26.0  ...   \n",
       "18                                      84.0  ...   \n",
       "19                                       1.0  ...   \n",
       "20                                      26.0  ...   \n",
       "21                                     212.0  ...   \n",
       "22                                    1259.0  ...   \n",
       "23                                      62.0  ...   \n",
       "24                                      20.0  ...   \n",
       "25                                     804.0  ...   \n",
       "26                                      79.0  ...   \n",
       "27                                     153.0  ...   \n",
       "28                                       NaN  ...   \n",
       "29                                      83.0  ...   \n",
       "...                                      ...  ...   \n",
       "1068696                                371.0  ...   \n",
       "1068697                                 26.0  ...   \n",
       "1068698                                  7.0  ...   \n",
       "1068699                                  NaN  ...   \n",
       "1068700                                 10.0  ...   \n",
       "1068701                                993.0  ...   \n",
       "1068702                                497.0  ...   \n",
       "1068703                                 18.0  ...   \n",
       "1068704                                 46.0  ...   \n",
       "1068705                                 14.0  ...   \n",
       "1068706                                244.0  ...   \n",
       "1068707                                140.0  ...   \n",
       "1068708                                  8.0  ...   \n",
       "1068709                                 19.0  ...   \n",
       "1068710                                  9.0  ...   \n",
       "1068711                                  4.0  ...   \n",
       "1068712                                 73.0  ...   \n",
       "1068713                                 52.0  ...   \n",
       "1068714                                 36.0  ...   \n",
       "1068715                                 21.0  ...   \n",
       "1068716                                159.0  ...   \n",
       "1068717                                213.0  ...   \n",
       "1068718                                 11.0  ...   \n",
       "1068719                                 21.0  ...   \n",
       "1068720                                 52.0  ...   \n",
       "1068721                                 36.0  ...   \n",
       "1068722                                262.0  ...   \n",
       "1068723                                 13.0  ...   \n",
       "1068724                                 35.0  ...   \n",
       "1068725                                310.0  ...   \n",
       "\n",
       "         trip_complete_per_days_active_84d  trip_complete_win7d_sd_84d  \\\n",
       "0                                 1.000000                    0.276385   \n",
       "1                                 1.000000                    0.372678   \n",
       "2                                 1.482759                    2.984916   \n",
       "3                                 1.100000                    1.771691   \n",
       "4                                 1.750000                    2.711857   \n",
       "5                                 1.250000                    0.640095   \n",
       "6                                 1.000000                    0.433013   \n",
       "7                                 1.333333                    0.623610   \n",
       "8                                 1.666667                    1.771691   \n",
       "9                                 1.000000                    0.623610   \n",
       "10                                1.800000                    1.421560   \n",
       "11                                1.250000                    0.862007   \n",
       "12                                1.500000                    0.595119   \n",
       "13                                2.000000                    1.384437   \n",
       "14                                1.461538                    2.680951   \n",
       "15                                1.200000                    1.080123   \n",
       "16                                1.000000                    0.372678   \n",
       "17                                1.200000                    1.527525   \n",
       "18                                1.437500                    2.034426   \n",
       "19                                1.833333                    1.705791   \n",
       "20                                2.000000                    1.105542   \n",
       "21                                     NaN                    0.276385   \n",
       "22                                1.000000                    0.276385   \n",
       "23                                1.000000                    0.471405   \n",
       "24                                1.125000                    0.924211   \n",
       "25                                1.481481                    3.009245   \n",
       "26                                1.200000                    0.645497   \n",
       "27                                1.307692                    1.187317   \n",
       "28                                     NaN                         NaN   \n",
       "29                                     NaN                    0.640095   \n",
       "...                                    ...                         ...   \n",
       "1068696                           1.190476                    1.605113   \n",
       "1068697                           1.250000                    0.953794   \n",
       "1068698                           1.000000                    0.471405   \n",
       "1068699                                NaN                         NaN   \n",
       "1068700                           1.000000                    0.276385   \n",
       "1068701                           1.000000                    0.645497   \n",
       "1068702                           1.000000                    0.276385   \n",
       "1068703                           1.000000                    0.372678   \n",
       "1068704                           1.000000                    0.433013   \n",
       "1068705                           1.000000                    0.372678   \n",
       "1068706                           1.811321                    3.651484   \n",
       "1068707                           1.000000                    0.276385   \n",
       "1068708                           1.500000                    0.829156   \n",
       "1068709                           1.333333                    1.027402   \n",
       "1068710                           1.000000                    0.276385   \n",
       "1068711                           1.000000                    0.372678   \n",
       "1068712                           1.333333                    0.623610   \n",
       "1068713                           1.000000                    0.276385   \n",
       "1068714                           1.000000                    0.372678   \n",
       "1068715                           1.000000                    0.471405   \n",
       "1068716                           2.500000                    1.114924   \n",
       "1068717                           1.250000                    0.897527   \n",
       "1068718                           1.500000                    0.763763   \n",
       "1068719                           1.000000                    0.745356   \n",
       "1068720                           1.000000                    0.276385   \n",
       "1068721                           1.454545                    2.560382   \n",
       "1068722                           1.000000                    0.276385   \n",
       "1068723                           1.000000                    0.276385   \n",
       "1068724                           1.000000                    0.640095   \n",
       "1068725                           1.000000                    0.276385   \n",
       "\n",
       "         trip_incomplete_total_84d  trip_pool_matched_avg_84d  \\\n",
       "0                              0.0                   0.000000   \n",
       "1                              0.0                   0.000000   \n",
       "2                              7.0                   0.275862   \n",
       "3                              1.0                   0.000000   \n",
       "4                              3.0                   0.000000   \n",
       "5                              1.0                   0.000000   \n",
       "6                              0.0                   0.000000   \n",
       "7                              3.0                   0.000000   \n",
       "8                              1.0                   0.000000   \n",
       "9                              1.0                   0.000000   \n",
       "10                             1.0                   0.000000   \n",
       "11                             3.0                   0.000000   \n",
       "12                             0.0                   0.000000   \n",
       "13                             1.0                   0.000000   \n",
       "14                             8.0                   0.000000   \n",
       "15                             1.0                   0.000000   \n",
       "16                             0.0                   0.000000   \n",
       "17                             1.0                   0.000000   \n",
       "18                             8.0                   0.000000   \n",
       "19                             1.0                   0.000000   \n",
       "20                             0.0                   0.000000   \n",
       "21                             1.0                   0.000000   \n",
       "22                             0.0                   0.000000   \n",
       "23                             0.0                   0.000000   \n",
       "24                             3.0                   0.000000   \n",
       "25                             6.0                   0.000000   \n",
       "26                             0.0                   0.000000   \n",
       "27                             0.0                   0.000000   \n",
       "28                             NaN                        NaN   \n",
       "29                             0.0                   0.000000   \n",
       "...                            ...                        ...   \n",
       "1068696                        3.0                   0.000000   \n",
       "1068697                        1.0                   0.000000   \n",
       "1068698                        0.0                   0.000000   \n",
       "1068699                        NaN                        NaN   \n",
       "1068700                        0.0                   0.000000   \n",
       "1068701                        0.0                   0.000000   \n",
       "1068702                        0.0                   0.000000   \n",
       "1068703                        0.0                   0.000000   \n",
       "1068704                        0.0                   0.000000   \n",
       "1068705                        2.0                   0.000000   \n",
       "1068706                       19.0                   0.000000   \n",
       "1068707                        0.0                   0.000000   \n",
       "1068708                        0.0                   0.000000   \n",
       "1068709                        0.0                   0.000000   \n",
       "1068710                        0.0                   0.000000   \n",
       "1068711                        0.0                   0.000000   \n",
       "1068712                        0.0                   0.000000   \n",
       "1068713                        0.0                   0.000000   \n",
       "1068714                        0.0                   0.000000   \n",
       "1068715                        3.0                   0.000000   \n",
       "1068716                        0.0                   0.000000   \n",
       "1068717                        3.0                   0.000000   \n",
       "1068718                        0.0                   0.000000   \n",
       "1068719                        0.0                   0.000000   \n",
       "1068720                        1.0                   0.000000   \n",
       "1068721                        5.0                   0.000000   \n",
       "1068722                        0.0                   0.000000   \n",
       "1068723                        0.0                   0.000000   \n",
       "1068724                        0.0                   0.000000   \n",
       "1068725                        0.0                   0.000000   \n",
       "\n",
       "         trip_pool_per_x_84d  trip_pool_prc_84d  trip_x_prc_84d  \\\n",
       "0                   0.000000               0.00        1.000000   \n",
       "1                   0.000000               0.00        1.000000   \n",
       "2                   0.851852               0.46        0.540000   \n",
       "3                   0.000000               0.00        1.000000   \n",
       "4                   0.000000               0.00        1.000000   \n",
       "5                   0.000000               0.00        1.000000   \n",
       "6                   0.000000               0.00        1.000000   \n",
       "7                   0.000000               0.00        1.000000   \n",
       "8                   0.000000               0.00        1.000000   \n",
       "9                   0.000000               0.00        1.000000   \n",
       "10                  0.000000               0.00        1.000000   \n",
       "11                  0.000000               0.00        1.000000   \n",
       "12                  0.000000               0.00        1.000000   \n",
       "13                  0.000000               0.00        1.000000   \n",
       "14                  0.000000               0.00        1.000000   \n",
       "15                  0.000000               0.00        1.000000   \n",
       "16                  0.000000               0.00        1.000000   \n",
       "17                  0.000000               0.00        1.000000   \n",
       "18                  0.000000               0.00        0.981481   \n",
       "19                  0.000000               0.00        1.000000   \n",
       "20                  0.000000               0.00        1.000000   \n",
       "21                       NaN                NaN             NaN   \n",
       "22                  0.000000               0.00        1.000000   \n",
       "23                  0.000000               0.00        1.000000   \n",
       "24                  0.000000               0.00        1.000000   \n",
       "25                  0.000000               0.00        1.000000   \n",
       "26                  0.000000               0.00        1.000000   \n",
       "27                  0.000000               0.00        1.000000   \n",
       "28                       NaN                NaN             NaN   \n",
       "29                       NaN                NaN             NaN   \n",
       "...                      ...                ...             ...   \n",
       "1068696             0.000000               0.00        1.000000   \n",
       "1068697             0.000000               0.00        1.000000   \n",
       "1068698             0.000000               0.00        1.000000   \n",
       "1068699                  NaN                NaN             NaN   \n",
       "1068700             0.000000               0.00        1.000000   \n",
       "1068701             0.000000               0.00        1.000000   \n",
       "1068702             0.000000               0.00        1.000000   \n",
       "1068703             0.000000               0.00        1.000000   \n",
       "1068704             0.000000               0.00        1.000000   \n",
       "1068705             0.000000               0.00        1.000000   \n",
       "1068706             0.000000               0.00        1.000000   \n",
       "1068707             0.000000               0.00        1.000000   \n",
       "1068708             0.000000               0.00        1.000000   \n",
       "1068709             0.000000               0.00        0.875000   \n",
       "1068710             0.000000               0.00        1.000000   \n",
       "1068711             0.000000               0.00        1.000000   \n",
       "1068712             0.000000               0.00        1.000000   \n",
       "1068713             0.000000               0.00        1.000000   \n",
       "1068714             0.000000               0.00        1.000000   \n",
       "1068715             0.000000               0.00        1.000000   \n",
       "1068716             0.250000               0.20        0.800000   \n",
       "1068717             0.000000               0.00        1.000000   \n",
       "1068718             0.000000               0.00        1.000000   \n",
       "1068719             0.000000               0.00        1.000000   \n",
       "1068720             0.000000               0.00        1.000000   \n",
       "1068721             0.000000               0.00        1.000000   \n",
       "1068722             0.000000               0.00        1.000000   \n",
       "1068723             0.000000               0.00        1.000000   \n",
       "1068724             0.000000               0.00        1.000000   \n",
       "1068725             0.000000               0.00        1.000000   \n",
       "\n",
       "         trips_lifetime                              useruuid  \\\n",
       "0                   2.0  df140d8a-7733-4351-a41c-e01850b2bbaf   \n",
       "1                  31.0  174cff21-848b-4973-99ab-b3850e2308ae   \n",
       "2                 199.0  971d40d2-a965-49ac-ba37-87564bff2733   \n",
       "3                 228.0  dcb048e0-7388-4c5e-8afa-2d8c42a4a455   \n",
       "4                  75.0  b92beda1-ec65-4587-adee-01f486cd0b5a   \n",
       "5                  52.0  563332bf-e639-446e-9017-000933541ea4   \n",
       "6                   8.0  3774ca20-1002-42cd-b958-f9f492df533c   \n",
       "7                 144.0  884ae0a4-0689-4569-a4d3-1db40fdf51b6   \n",
       "8                  52.0  a3276f9f-5544-4e10-9dfd-b73796284caf   \n",
       "9                  48.0  c99d1b97-a85a-4d16-b6c3-d250a1d68f55   \n",
       "10                 33.0  85586bd0-2c5c-44b6-83f2-87450d59a47b   \n",
       "11                  8.0  7d3afcd0-bcd8-4e7c-8c39-f0b1f8e02f16   \n",
       "12                  3.0  68edb4b0-df6a-4a03-8195-5ef9280fc141   \n",
       "13                 54.0  113ee0dd-e992-47a1-ac64-c72fc796389e   \n",
       "14                134.0  354272c5-2427-4af3-b049-19e6ba642b44   \n",
       "15                269.0  4684a513-71b6-4894-b631-8f812e7fc7c5   \n",
       "16                 21.0  c6faea83-c88a-4411-ac7d-95a125dc65dc   \n",
       "17                 94.0  53aa1911-a29d-4218-ae90-7d80f6165af5   \n",
       "18                139.0  e0011c10-0846-4c43-a704-80e69bf48d6f   \n",
       "19                 66.0  1d1494f6-b34a-4783-b464-faba8113fa48   \n",
       "20                 91.0  01d63b42-0f29-4a80-b639-cb8193e5ee1d   \n",
       "21                  8.0  cb76ba0c-6e8e-42ec-8c8a-d205e038cade   \n",
       "22                  9.0  d8461714-d01f-4faf-9123-0c74539639fc   \n",
       "23                 88.0  e6adb12f-4ee9-4971-a303-a1464a732be9   \n",
       "24                 96.0  ec3f25b8-4bf9-4e1a-9913-23295fbafb21   \n",
       "25                483.0  9aa3873c-cc63-498a-bc57-15ab67a2d4ce   \n",
       "26                 33.0  123d411b-9357-41b4-a473-9d7081b3b7f0   \n",
       "27                225.0  04c2321b-ddc7-4932-887d-ee0aa8e99458   \n",
       "28                  NaN  62b16b8d-9642-43d2-b05e-994e5a7c826d   \n",
       "29                 11.0  c1962615-0448-4d21-8e7e-5a0dbf9fe17c   \n",
       "...                 ...                                   ...   \n",
       "1068696            93.0  221aae5e-c41a-4079-8852-1889c3ba7ce3   \n",
       "1068697             5.0  a7bcbd4a-23d4-494a-821d-bc8272572574   \n",
       "1068698            70.0  b8aab666-4b2b-492b-ae3d-bb9a42363424   \n",
       "1068699             NaN  5a7b3caf-a8aa-40de-a327-e25803761d2c   \n",
       "1068700             1.0  94936bd2-c03d-44c2-b873-13a4148ceea8   \n",
       "1068701             7.0  0517308d-b85a-4d7d-8c4a-9408d8d30c44   \n",
       "1068702            19.0  53dcb85b-1c2d-4bf9-9fec-fd22f82afa4f   \n",
       "1068703            37.0  5c0621c0-b51f-4a3a-b09a-20d6159bc6a5   \n",
       "1068704           119.0  4391eead-bae6-45c8-9307-137742f5e101   \n",
       "1068705            17.0  20202959-8005-469c-8c72-adf24bf87356   \n",
       "1068706           218.0  fbebc154-7165-4b15-8376-d61766d46828   \n",
       "1068707            14.0  023b1f83-909e-4520-b7ff-f242ebf57c65   \n",
       "1068708             3.0  478ddd49-750b-4ab2-b778-b7dffb0000be   \n",
       "1068709            80.0  c9124fc2-0348-463b-a20d-b394a6ab11f7   \n",
       "1068710             6.0  8fa3a74d-d9aa-447c-960a-072fe44d32bb   \n",
       "1068711            71.0  4165f41d-fa37-4b93-aedf-dbbf564cde7c   \n",
       "1068712            32.0  b4e75f35-2762-4b2b-a584-2f313672562c   \n",
       "1068713            39.0  64496eee-2eb5-4065-a682-94a28ddedc5e   \n",
       "1068714            10.0  834d0145-08ae-4cf8-bf56-996010516632   \n",
       "1068715            34.0  0dbb7cb8-312b-4f20-bfb8-11ef36d055f4   \n",
       "1068716            30.0  dec851ab-d314-4ac2-a9ad-e89be964d851   \n",
       "1068717            93.0  68440cd4-f24a-47c8-ba52-bc362099bc2f   \n",
       "1068718            61.0  ee459d97-31d5-4104-9c8c-be6fdc1ba564   \n",
       "1068719             6.0  d79bc1b5-81e5-4fbe-938c-baef8b2e8006   \n",
       "1068720            27.0  28c2924a-48a0-4297-80a3-cc25e72cdced   \n",
       "1068721            18.0  590c538c-4ad0-4df4-8831-5fa3fa20d7f2   \n",
       "1068722             2.0  fe13ffcb-9661-4226-b893-debdb11bc67e   \n",
       "1068723             1.0  3c4b299a-751d-4894-b7d2-d17f23f2563c   \n",
       "1068724             5.0  16c1dbaa-4d22-42ea-b548-d1ababe0cae6   \n",
       "1068725             7.0  c0d0762b-ce1d-49e9-b1a7-c1045f9740e0   \n",
       "\n",
       "                                         uuid  \n",
       "0        df140d8a-7733-4351-a41c-e01850b2bbaf  \n",
       "1        174cff21-848b-4973-99ab-b3850e2308ae  \n",
       "2        971d40d2-a965-49ac-ba37-87564bff2733  \n",
       "3        dcb048e0-7388-4c5e-8afa-2d8c42a4a455  \n",
       "4        b92beda1-ec65-4587-adee-01f486cd0b5a  \n",
       "5        563332bf-e639-446e-9017-000933541ea4  \n",
       "6        3774ca20-1002-42cd-b958-f9f492df533c  \n",
       "7        884ae0a4-0689-4569-a4d3-1db40fdf51b6  \n",
       "8        a3276f9f-5544-4e10-9dfd-b73796284caf  \n",
       "9        c99d1b97-a85a-4d16-b6c3-d250a1d68f55  \n",
       "10       85586bd0-2c5c-44b6-83f2-87450d59a47b  \n",
       "11       7d3afcd0-bcd8-4e7c-8c39-f0b1f8e02f16  \n",
       "12       68edb4b0-df6a-4a03-8195-5ef9280fc141  \n",
       "13       113ee0dd-e992-47a1-ac64-c72fc796389e  \n",
       "14       354272c5-2427-4af3-b049-19e6ba642b44  \n",
       "15       4684a513-71b6-4894-b631-8f812e7fc7c5  \n",
       "16       c6faea83-c88a-4411-ac7d-95a125dc65dc  \n",
       "17       53aa1911-a29d-4218-ae90-7d80f6165af5  \n",
       "18       e0011c10-0846-4c43-a704-80e69bf48d6f  \n",
       "19       1d1494f6-b34a-4783-b464-faba8113fa48  \n",
       "20       01d63b42-0f29-4a80-b639-cb8193e5ee1d  \n",
       "21       cb76ba0c-6e8e-42ec-8c8a-d205e038cade  \n",
       "22       d8461714-d01f-4faf-9123-0c74539639fc  \n",
       "23       e6adb12f-4ee9-4971-a303-a1464a732be9  \n",
       "24       ec3f25b8-4bf9-4e1a-9913-23295fbafb21  \n",
       "25       9aa3873c-cc63-498a-bc57-15ab67a2d4ce  \n",
       "26       123d411b-9357-41b4-a473-9d7081b3b7f0  \n",
       "27       04c2321b-ddc7-4932-887d-ee0aa8e99458  \n",
       "28                                        NaN  \n",
       "29       c1962615-0448-4d21-8e7e-5a0dbf9fe17c  \n",
       "...                                       ...  \n",
       "1068696  221aae5e-c41a-4079-8852-1889c3ba7ce3  \n",
       "1068697  a7bcbd4a-23d4-494a-821d-bc8272572574  \n",
       "1068698  b8aab666-4b2b-492b-ae3d-bb9a42363424  \n",
       "1068699                                   NaN  \n",
       "1068700  94936bd2-c03d-44c2-b873-13a4148ceea8  \n",
       "1068701  0517308d-b85a-4d7d-8c4a-9408d8d30c44  \n",
       "1068702  53dcb85b-1c2d-4bf9-9fec-fd22f82afa4f  \n",
       "1068703  5c0621c0-b51f-4a3a-b09a-20d6159bc6a5  \n",
       "1068704  4391eead-bae6-45c8-9307-137742f5e101  \n",
       "1068705  20202959-8005-469c-8c72-adf24bf87356  \n",
       "1068706  fbebc154-7165-4b15-8376-d61766d46828  \n",
       "1068707  023b1f83-909e-4520-b7ff-f242ebf57c65  \n",
       "1068708  478ddd49-750b-4ab2-b778-b7dffb0000be  \n",
       "1068709  c9124fc2-0348-463b-a20d-b394a6ab11f7  \n",
       "1068710  8fa3a74d-d9aa-447c-960a-072fe44d32bb  \n",
       "1068711  4165f41d-fa37-4b93-aedf-dbbf564cde7c  \n",
       "1068712  b4e75f35-2762-4b2b-a584-2f313672562c  \n",
       "1068713  64496eee-2eb5-4065-a682-94a28ddedc5e  \n",
       "1068714  834d0145-08ae-4cf8-bf56-996010516632  \n",
       "1068715  0dbb7cb8-312b-4f20-bfb8-11ef36d055f4  \n",
       "1068716  dec851ab-d314-4ac2-a9ad-e89be964d851  \n",
       "1068717  68440cd4-f24a-47c8-ba52-bc362099bc2f  \n",
       "1068718  ee459d97-31d5-4104-9c8c-be6fdc1ba564  \n",
       "1068719  d79bc1b5-81e5-4fbe-938c-baef8b2e8006  \n",
       "1068720  28c2924a-48a0-4297-80a3-cc25e72cdced  \n",
       "1068721  590c538c-4ad0-4df4-8831-5fa3fa20d7f2  \n",
       "1068722  fe13ffcb-9661-4226-b893-debdb11bc67e  \n",
       "1068723  3c4b299a-751d-4894-b7d2-d17f23f2563c  \n",
       "1068724  16c1dbaa-4d22-42ea-b548-d1ababe0cae6  \n",
       "1068725  c0d0762b-ce1d-49e9-b1a7-c1045f9740e0  \n",
       "\n",
       "[1068726 rows x 48 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predFrame2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/pandas/core/ops.py:1649: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nans: 0\n",
      "number of nans: 0\n",
      "number of nans: 0\n",
      "number of nans: 0\n",
      "number of nans: 0\n",
      "number of nans: 0\n",
      "number of nans: 0\n",
      "number of nans: 0\n",
      "number of nans: 0\n",
      "number of nans: 0\n",
      "number of nans: 0\n",
      "number of nans: 0\n",
      "number of nans: 0\n",
      "number of nans: 0\n",
      "number of nans: 0\n",
      "number of nans: 0\n",
      "number of nans: 0\n",
      "number of nans: 0\n",
      "number of nans: 0\n",
      "number of nans: 0\n",
      "number of nans: 0\n",
      "number of nans: 0\n",
      "number of nans: 0\n",
      "number of nans: 0\n",
      "number of nans: 0\n",
      "number of nans: 0\n",
      "number of nans: 0\n",
      "number of nans: 0\n",
      "number of nans: 0\n",
      "number of nans: 0\n",
      "number of nans: 0\n",
      "number of nans: 0\n",
      "number of nans: 0\n",
      "number of nans: 0\n",
      "number of nans: 0\n",
      "number of nans: 0\n",
      "number of nans: 0\n",
      "number of nans: 0\n",
      "number of nans: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rpu_treated : 0.26086751875\n",
      "nipu_treated : -0.186934646608\n",
      "rpu_untreated : 0.167524995575\n",
      "nipu_untreated : -0.0599816763466\n",
      "cpit : 1.360076479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:89: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:91: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:93: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:95: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "### preprocess the data \n",
    "### -- sample treatment to match control cohort \n",
    "### -- eliminate nulls, standard normalization \n",
    "\n",
    "D = predFrame2 \n",
    "D = D.sample(frac=1.0) \n",
    "\n",
    "feature_list = [ \n",
    "    'rating_2driver_min_avg_84d'\n",
    "    , 'trip_incomplete_total_84d'\n",
    "    , 'days_active_84d'\n",
    "    , 'days_since_trip_first_lifetime'\n",
    "    , 'days_since_last_hard_churn_lifetime'\n",
    "    , 'days_since_last_soft_churn_lifetime'\n",
    "    , 'fare_max_sd_84d'\n",
    "    , 'churns_hard_lifetime'\n",
    "    , 'trips_lifetime'\n",
    "    , 'fare_max_p50_84d'\n",
    "    , 'duration_session_pre_request_max_p50_84d'\n",
    "    , 'trip_pool_per_x_84d'\n",
    "    , 'fare_total_win7d_sd_84d'\n",
    "    , 'trip_complete_win7d_sd_84d'\n",
    "    , 'session_per_days_active_84d'\n",
    "    , 'churns_soft_lifetime'\n",
    "    , 'trip_complete_per_days_active_84d'\n",
    "    , 'trip_pool_prc_84d'\n",
    "    , 'session_background_pre_request_prc_84d'\n",
    "    , 'session_lt_1m_prc_84d'\n",
    "    , 'session_request_prc_84d'\n",
    "    , 'duration_session_outside_total_prc_84d'\n",
    "    , 'trip_x_prc_84d'\n",
    "    , 'days_since_trip_last_lifetime'\n",
    "    , 'has_session_request_84d'\n",
    "    , 'has_session_without_request_84d'\n",
    "    , 'promo_used_84d' \n",
    "    , 'fare_promo_total_avg_84d', \n",
    "    'fare_total_avg_84d', \n",
    "    'surge_trip_avg_84d', \n",
    "    'fare_total_win7d_potential_84d', \n",
    "    'fare_total_win28d_potential_84d', \n",
    "    'fare_lifetime', \n",
    "    'time_to_first_message_minutes_mean_lifetime', \n",
    "    'ata_trip_max_avg_84d', \n",
    "    'eta_trip_max_avg_84d', \n",
    "    'trip_pool_matched_avg_84d', \n",
    "    'payment_cash_trip_total_84d', \n",
    "    'duration_trip_total_p50_84d' \n",
    "] \n",
    "\n",
    "label_list = [ \n",
    "    'manual_apply_gb', \n",
    "    'manual_apply_ni' \n",
    "] \n",
    "\n",
    "for l in feature_list: \n",
    "    print('number of nans: ' + str(sum(D[l] == '\\N'))) \n",
    "    D[l] = pd.to_numeric(D[l], errors='coerce') \n",
    "    D[l] = D[l] - D[l].mean() \n",
    "    D[l] = D[l] / D[l].std() \n",
    "    D[l][pd.isnull(D[l])] = 0.0 ## at zero mean due to standard normalization \n",
    "\n",
    "for l in label_list: \n",
    "    D[l] = pd.to_numeric(D[l], errors='coerce') \n",
    "    D[l][pd.isnull(D[l])] = 0.0 ## at zero mean due to standard normalization \n",
    "\n",
    "### -- compute simple statistics \n",
    "### compute cpit \n",
    "treated_entries = D[D[cohort_column_name] == treatment_indicator_value] \n",
    "untreated_entries = D[D[cohort_column_name] == control_indicator_value] \n",
    "\n",
    "rpu_treated = float(treated_entries[label_list[0]].sum()) / len(treated_entries) \n",
    "nipu_treated = float(treated_entries[label_list[1]].sum()) / len(treated_entries) \n",
    "\n",
    "rpu_untreated = float(untreated_entries[label_list[0]].sum()) / len(untreated_entries) \n",
    "nipu_untreated = float(untreated_entries[label_list[1]].sum()) / len(untreated_entries) \n",
    "\n",
    "cpit = -1.0 * (nipu_treated - nipu_untreated) / (rpu_treated - rpu_untreated) \n",
    "\n",
    "print('rpu_treated : ' + str(rpu_treated)) \n",
    "print('nipu_treated : ' + str(nipu_treated)) \n",
    "print('rpu_untreated : ' + str(rpu_untreated)) \n",
    "print('nipu_untreated : ' + str(nipu_untreated)) \n",
    "print('cpit : ' + str(cpit)) \n",
    "\n",
    "### split the data into 3/1/1 train/val/test \n",
    "len_tr = len(D) / 5 * 4 \n",
    "len_va = len(D) / 10 \n",
    "\n",
    "nX = D[feature_list].as_matrix() \n",
    "w = D[cohort_column_name].apply(lambda x: 1.0 if x == treatment_indicator_value else 0.0) \n",
    "w = w.as_matrix() \n",
    "values = D[label_list[0]] \n",
    "values = values.as_matrix() * 1.0 \n",
    "negcost = D[label_list[1]] \n",
    "negcost = negcost.as_matrix() * 1.0 \n",
    "\n",
    "## split train/val/test sets \n",
    "\n",
    "nX_tr = nX[0:len_tr, :] \n",
    "nX_va = nX[len_tr:len_tr + len_va, :] \n",
    "nX_te = nX[len_tr + len_va:, :] \n",
    "\n",
    "w_tr = w[0:len_tr]\n",
    "w_va = w[len_tr:len_tr + len_va] \n",
    "w_te = w[len_tr + len_va:] \n",
    "\n",
    "values_tr = values[0:len_tr] \n",
    "values_va = values[len_tr:len_tr + len_va] \n",
    "values_te = values[len_tr + len_va:] \n",
    "\n",
    "negcost_tr = negcost[0:len_tr] \n",
    "\n",
    "negcost_va = negcost[len_tr:len_tr + len_va] \n",
    "\n",
    "negcost_te = negcost[len_tr + len_va:] \n",
    "\n",
    "## saving data using cPickel and naming the dictionaries \n",
    "saveD = {'nX_tr':nX_tr, \n",
    "         'w_tr':w_tr, \n",
    "         'values_tr':values_tr, \n",
    "         'nX_va':nX_va, \n",
    "         'w_va':w_va, \n",
    "         'values_va':values_va, \n",
    "         'nX_te':nX_te, \n",
    "         'w_te':w_te, \n",
    "         'values_te':values_te, \n",
    "         'feature_list':feature_list, \n",
    "         #'avg_ni_usd_tr':avg_ni_usd_tr, \n",
    "         'negcost_tr': negcost_tr, \n",
    "         #'avg_ni_usd_va':avg_ni_usd_va, \n",
    "         'negcost_va': negcost_va, \n",
    "         #'avg_ni_usd_te':avg_ni_usd_te, \n",
    "         'negcost_te': negcost_te \n",
    "         } \n",
    "\n",
    "pkl.dump(saveD, open('../data/r2e_ma_training_data_v5_2019_07_08_vc_tr_featuremod3', 'w')) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37209"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(predFrame2['manual_apply_orders'] > 0) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data from ../data/r2e_ma_training_data_v5_2019_07_08_vc_tr_featuremod3\n",
      "printing averages of c_tr, c_unt, o_tre, o_unt ... :\n",
      "0.18603590657645117\n",
      "0.059855716204436075\n",
      "0.2599077063039854\n",
      "0.16561748980938584\n",
      "### ----- start the training of deep learning models ------ \n",
      "------> Training TQR ranking model .... \n",
      "---> running cross validation, iteration: 0\n",
      "WARNING:tensorflow:From ../models/ModelDefinitions.py:37: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From ../models/ModelDefinitions.py:37: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "WARNING:tensorflow:From ../models/ModelDefinitions.py:38: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1d4cb2e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1d4cb2e90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1d4cb2e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1d4cb2e90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1d4cb2d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1d4cb2d90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1d4cb2d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1d4cb2d90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From ../models/ModelDefinitions.py:74: The name tf.ceil is deprecated. Please use tf.math.ceil instead.\n",
      "\n",
      "WARNING:tensorflow:From ../models/ModelDefinitions.py:115: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "opt. step : 0 obj: 1.348907551450355\n",
      "setting temperature to :0.6\n",
      "opt. step : 100 obj: 1.2929704592892022\n",
      "setting temperature to :0.7\n",
      "opt. step : 200 obj: 1.2381652816297701\n",
      "setting temperature to :0.7999999999999999\n",
      "opt. step : 300 obj: 1.2029295564982116\n",
      "setting temperature to :0.8999999999999999\n",
      "opt. step : 400 obj: 1.178210994871139\n",
      "setting temperature to :0.9999999999999999\n",
      "opt. step : 500 obj: 1.1601878666649659\n",
      "setting temperature to :1.0999999999999999\n",
      "opt. step : 600 obj: 1.1465543298172785\n",
      "setting temperature to :1.2\n",
      "opt. step : 700 obj: 1.135540166326903\n",
      "setting temperature to :1.3\n",
      "opt. step : 800 obj: 1.126261653059276\n",
      "setting temperature to :1.4000000000000001\n",
      "opt. step : 900 obj: 1.1185274853398244\n",
      "setting temperature to :1.5000000000000002\n",
      "opt. step : 1000 obj: 1.1118094288193427\n",
      "setting temperature to :1.6000000000000003\n",
      "opt. step : 1100 obj: 1.105883049753455\n",
      "setting temperature to :1.7000000000000004\n",
      "opt. step : 1200 obj: 1.1003578627479877\n",
      "setting temperature to :1.8000000000000005\n",
      "opt. step : 1300 obj: 1.0950563400414015\n",
      "setting temperature to :1.9000000000000006\n",
      "opt. step : 1400 obj: 1.089662157515186\n",
      "setting temperature to :2.0000000000000004\n",
      "opt. step : 1500 obj: 1.0845965637138728\n",
      "setting temperature to :2.1000000000000005\n",
      "opt. step : 1600 obj: 1.0800650635521112\n",
      "setting temperature to :2.2000000000000006\n",
      "opt. step : 1700 obj: 1.0758649313959505\n",
      "setting temperature to :2.3000000000000007\n",
      "opt. step : 1800 obj: 1.071163028046459\n",
      "setting temperature to :2.400000000000001\n",
      "opt. step : 1900 obj: 1.0665906509700964\n",
      "setting temperature to :2.500000000000001\n",
      "opt. step : 2000 obj: 1.0621597678794545\n",
      "setting temperature to :2.600000000000001\n",
      "opt. step : 2100 obj: 1.057690598770504\n",
      "setting temperature to :2.700000000000001\n",
      "opt. step : 2200 obj: 1.0532608587640158\n",
      "setting temperature to :2.800000000000001\n",
      "opt. step : 2300 obj: 1.049308563522765\n",
      "setting temperature to :2.9000000000000012\n",
      "opt. step : 2400 obj: 1.0459719058784782\n",
      "setting temperature to :3.0000000000000013\n",
      "---> optimization finished ... \n",
      "temp:\n",
      "3.048659483397571\n",
      "p_quantile:\n",
      "0.3\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x143fc1b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x143fc1b50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x143fc1b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x143fc1b50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x143fc1ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x143fc1ad0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x143fc1ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x143fc1ad0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "validation CPIT:\n",
      "1.305577580518769\n",
      "---> running cross validation, iteration: 1\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x14408b3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x14408b3d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x14408b3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x14408b3d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x14408b550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x14408b550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x14408b550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x14408b550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "opt. step : 0 obj: 1.336645223698074\n",
      "setting temperature to :0.6\n",
      "opt. step : 100 obj: 1.279777589803364\n",
      "setting temperature to :0.7\n",
      "opt. step : 200 obj: 1.2308898614797643\n",
      "setting temperature to :0.7999999999999999\n",
      "opt. step : 300 obj: 1.199692647373854\n",
      "setting temperature to :0.8999999999999999\n",
      "opt. step : 400 obj: 1.1785621713758967\n",
      "setting temperature to :0.9999999999999999\n",
      "opt. step : 500 obj: 1.1624762275927847\n",
      "setting temperature to :1.0999999999999999\n",
      "opt. step : 600 obj: 1.1488260038079994\n",
      "setting temperature to :1.2\n",
      "opt. step : 700 obj: 1.136883813990277\n",
      "setting temperature to :1.3\n",
      "opt. step : 800 obj: 1.1267798739528458\n",
      "setting temperature to :1.4000000000000001\n",
      "opt. step : 900 obj: 1.1179871401356254\n",
      "setting temperature to :1.5000000000000002\n",
      "opt. step : 1000 obj: 1.1095457286831492\n",
      "setting temperature to :1.6000000000000003\n",
      "opt. step : 1100 obj: 1.1011002768859384\n",
      "setting temperature to :1.7000000000000004\n",
      "opt. step : 1200 obj: 1.0933483502063754\n",
      "setting temperature to :1.8000000000000005\n",
      "opt. step : 1300 obj: 1.0868143319284906\n",
      "setting temperature to :1.9000000000000006\n",
      "opt. step : 1400 obj: 1.0812388511460913\n",
      "setting temperature to :2.0000000000000004\n",
      "opt. step : 1500 obj: 1.0760827019595507\n",
      "setting temperature to :2.1000000000000005\n",
      "opt. step : 1600 obj: 1.071204619360722\n",
      "setting temperature to :2.2000000000000006\n",
      "opt. step : 1700 obj: 1.066903643880312\n",
      "setting temperature to :2.3000000000000007\n",
      "opt. step : 1800 obj: 1.0632493374089522\n",
      "setting temperature to :2.400000000000001\n",
      "opt. step : 1900 obj: 1.0600338335779227\n",
      "setting temperature to :2.500000000000001\n",
      "opt. step : 2000 obj: 1.0571126600818614\n",
      "setting temperature to :2.600000000000001\n",
      "opt. step : 2100 obj: 1.054511807048192\n",
      "setting temperature to :2.700000000000001\n",
      "opt. step : 2200 obj: 1.0521855996677716\n",
      "setting temperature to :2.800000000000001\n",
      "opt. step : 2300 obj: 1.0500746292733736\n",
      "setting temperature to :2.9000000000000012\n",
      "opt. step : 2400 obj: 1.0480281401787424\n",
      "setting temperature to :3.0000000000000013\n",
      "---> optimization finished ... \n",
      "temp:\n",
      "3.0450352110246532\n",
      "p_quantile:\n",
      "0.3\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1444d3c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1444d3c10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1444d3c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1444d3c10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1444d3b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1444d3b90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1444d3b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1444d3b90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "validation CPIT:\n",
      "1.268979470106545\n",
      "---> running cross validation, iteration: 2\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x144599510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x144599510>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x144599510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x144599510>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1446a68d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1446a68d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1446a68d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1446a68d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "opt. step : 0 obj: 1.3390846807506809\n",
      "setting temperature to :0.6\n",
      "opt. step : 100 obj: 1.2841425596039728\n",
      "setting temperature to :0.7\n",
      "opt. step : 200 obj: 1.231334214255706\n",
      "setting temperature to :0.7999999999999999\n",
      "opt. step : 300 obj: 1.200920211008548\n",
      "setting temperature to :0.8999999999999999\n",
      "opt. step : 400 obj: 1.1810644541456001\n",
      "setting temperature to :0.9999999999999999\n",
      "opt. step : 500 obj: 1.1654607422051042\n",
      "setting temperature to :1.0999999999999999\n",
      "opt. step : 600 obj: 1.1508834881042467\n",
      "setting temperature to :1.2\n",
      "opt. step : 700 obj: 1.1366363556052124\n",
      "setting temperature to :1.3\n",
      "opt. step : 800 obj: 1.1237052837540773\n",
      "setting temperature to :1.4000000000000001\n",
      "opt. step : 900 obj: 1.112594123810824\n",
      "setting temperature to :1.5000000000000002\n",
      "opt. step : 1000 obj: 1.1031566317067418\n",
      "setting temperature to :1.6000000000000003\n",
      "opt. step : 1100 obj: 1.0951163658186647\n",
      "setting temperature to :1.7000000000000004\n",
      "opt. step : 1200 obj: 1.0882923757353329\n",
      "setting temperature to :1.8000000000000005\n",
      "opt. step : 1300 obj: 1.0824572160920667\n",
      "setting temperature to :1.9000000000000006\n",
      "opt. step : 1400 obj: 1.0773684164025326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting temperature to :2.0000000000000004\n",
      "opt. step : 1500 obj: 1.0728947364322332\n",
      "setting temperature to :2.1000000000000005\n",
      "opt. step : 1600 obj: 1.0690108224239157\n",
      "setting temperature to :2.2000000000000006\n",
      "opt. step : 1700 obj: 1.0658197245651129\n",
      "setting temperature to :2.3000000000000007\n",
      "opt. step : 1800 obj: 1.0628725126251273\n",
      "setting temperature to :2.400000000000001\n",
      "opt. step : 1900 obj: 1.0599926060013216\n",
      "setting temperature to :2.500000000000001\n",
      "opt. step : 2000 obj: 1.057540376583125\n",
      "setting temperature to :2.600000000000001\n",
      "opt. step : 2100 obj: 1.0550345387655509\n",
      "setting temperature to :2.700000000000001\n",
      "opt. step : 2200 obj: 1.0525492016767632\n",
      "setting temperature to :2.800000000000001\n",
      "opt. step : 2300 obj: 1.0501182947091914\n",
      "setting temperature to :2.9000000000000012\n",
      "opt. step : 2400 obj: 1.047374097238185\n",
      "setting temperature to :3.0000000000000013\n",
      "---> optimization finished ... \n",
      "temp:\n",
      "3.0469917555770163\n",
      "p_quantile:\n",
      "0.3\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x145a58c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x145a58c90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x145a58c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x145a58c90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x145a58e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x145a58e50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x145a58e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x145a58e50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "validation CPIT:\n",
      "1.2370762011980811\n",
      "best performing model: iteration 2\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x145b22450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x145b22450>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x145b22450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x145b22450>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "------> Training DRM ranking model .... \n",
      "---> running cross validation, iteration: 0\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x145b22790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x145b22790>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x145b22790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x145b22790>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x145c4e350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x145c4e350>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x145c4e350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x145c4e350>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "opt. step : 0 obj: 1.3760437519522664\n",
      "opt. step : 100 obj: 1.1961569683183024\n",
      "opt. step : 200 obj: 1.0746869763354452\n",
      "opt. step : 300 obj: 1.0120271689714482\n",
      "opt. step : 400 obj: 0.9730382003320451\n",
      "opt. step : 500 obj: 0.9439260765098773\n",
      "opt. step : 600 obj: 0.9244628378852553\n",
      "opt. step : 700 obj: 0.9086640259443018\n",
      "opt. step : 800 obj: 0.8947204458450876\n",
      "opt. step : 900 obj: 0.8836716366564947\n",
      "opt. step : 1000 obj: 0.8719887486319899\n",
      "opt. step : 1100 obj: 0.8600116817808198\n",
      "opt. step : 1200 obj: 0.8512455995024507\n",
      "opt. step : 1300 obj: 0.8440787439831305\n",
      "opt. step : 1400 obj: 0.8379837060976233\n",
      "opt. step : 1500 obj: 0.8325898257270403\n",
      "opt. step : 1600 obj: 0.8276633824181439\n",
      "opt. step : 1700 obj: 0.8229585716070088\n",
      "opt. step : 1800 obj: 0.8183181905624658\n",
      "opt. step : 1900 obj: 0.8138693355386158\n",
      "opt. step : 2000 obj: 0.8096668012693607\n",
      "opt. step : 2100 obj: 0.8056826455889882\n",
      "opt. step : 2200 obj: 0.801871735242784\n",
      "opt. step : 2300 obj: 0.7981059117172503\n",
      "opt. step : 2400 obj: 0.7943420014065409\n",
      "---> optimization finished ... \n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1447eaa50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1447eaa50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1447eaa50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1447eaa50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1448ffdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1448ffdd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1448ffdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1448ffdd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "validation CPIT:\n",
      "0.9847680262647761\n",
      "---> running cross validation, iteration: 1\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x144992fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x144992fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x144992fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x144992fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x144992b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x144992b50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x144992b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x144992b50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "opt. step : 0 obj: 1.3504638708058474\n",
      "opt. step : 100 obj: 1.1577458658935205\n",
      "opt. step : 200 obj: 1.0375762502319994\n",
      "opt. step : 300 obj: 0.9895141350071806\n",
      "opt. step : 400 obj: 0.9573179857924978\n",
      "opt. step : 500 obj: 0.9359365194301916\n",
      "opt. step : 600 obj: 0.9191276602825358\n",
      "opt. step : 700 obj: 0.9040486609975569\n",
      "opt. step : 800 obj: 0.8903470051815832\n",
      "opt. step : 900 obj: 0.8787107660882665\n",
      "opt. step : 1000 obj: 0.8686771514224931\n",
      "opt. step : 1100 obj: 0.8603005009815101\n",
      "opt. step : 1200 obj: 0.8531065601689141\n",
      "opt. step : 1300 obj: 0.8467608635345409\n",
      "opt. step : 1400 obj: 0.8411134358305844\n",
      "opt. step : 1500 obj: 0.8360271295550511\n",
      "opt. step : 1600 obj: 0.8313455588028165\n",
      "opt. step : 1700 obj: 0.826930251082512\n",
      "opt. step : 1800 obj: 0.8226880609112334\n",
      "opt. step : 1900 obj: 0.8185862992245695\n",
      "opt. step : 2000 obj: 0.81463105687838\n",
      "opt. step : 2100 obj: 0.8108301364141588\n",
      "opt. step : 2200 obj: 0.8071750426256353\n",
      "opt. step : 2300 obj: 0.8036340397648682\n",
      "opt. step : 2400 obj: 0.800112185504408\n",
      "---> optimization finished ... \n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x144b2a910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x144b2a910>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x144b2a910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x144b2a910>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x144c78dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x144c78dd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x144c78dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x144c78dd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "validation CPIT:\n",
      "0.9830970470514027\n",
      "---> running cross validation, iteration: 2\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x144d0cd10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x144d0cd10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x144d0cd10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x144d0cd10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x144dcde50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x144dcde50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x144dcde50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x144dcde50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "opt. step : 0 obj: 1.26291474646247\n",
      "opt. step : 100 obj: 1.126970320043475\n",
      "opt. step : 200 obj: 1.0691721746348888\n",
      "opt. step : 300 obj: 1.018046149022265\n",
      "opt. step : 400 obj: 0.9879279477549633\n",
      "opt. step : 500 obj: 0.9673478216937781\n",
      "opt. step : 600 obj: 0.9516166845433883\n",
      "opt. step : 700 obj: 0.9386070083331471\n",
      "opt. step : 800 obj: 0.9278626987456811\n",
      "opt. step : 900 obj: 0.916764496963091\n",
      "opt. step : 1000 obj: 0.9048710987714207\n",
      "opt. step : 1100 obj: 0.8928554810253712\n",
      "opt. step : 1200 obj: 0.8808141258061782\n",
      "opt. step : 1300 obj: 0.8676535676075049\n",
      "opt. step : 1400 obj: 0.8581469713328376\n",
      "opt. step : 1500 obj: 0.8482119860777954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt. step : 1600 obj: 0.8381938248324794\n",
      "opt. step : 1700 obj: 0.8312698513270652\n",
      "opt. step : 1800 obj: 0.8257135009144668\n",
      "opt. step : 1900 obj: 0.8209700034350997\n",
      "opt. step : 2000 obj: 0.8167158124702959\n",
      "opt. step : 2100 obj: 0.812788059236621\n",
      "opt. step : 2200 obj: 0.8091112628679233\n",
      "opt. step : 2300 obj: 0.805657323336613\n",
      "opt. step : 2400 obj: 0.8024172422786822\n",
      "---> optimization finished ... \n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x144f9ee90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x144f9ee90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x144f9ee90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x144f9ee90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x144f9eb10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x144f9eb10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x144f9eb10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x144f9eb10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "validation CPIT:\n",
      "0.9835544931646987\n",
      "best performing model: iteration 1\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x145086a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x145086a50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x145086a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x145086a50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" \\n### this section is to load the results trained by grf R code \\n### \\n\\not_cf = pd.read_csv('../results/causal_forest_grf_test_set_results_O_finalsize_numtrees1002.csv') \\nct_cf = pd.read_csv('../results/causal_forest_grf_test_set_results_C_finalsize_numtrees1002.csv') \\n\\not_cf = ot_cf.as_matrix() \\nOcfscores = ot_cf[0] \\n\\nct_cf = ct_cf.as_matrix() \\nCcfscores = ct_cf[0] \\n\\ncfscore = np.divide(Ocfscores, Ccfscores) \\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### code implements ranking model for treatment effect \n",
    "### for optimizing with respect to direct marketplace objectives \n",
    "### using tensorflow \n",
    "\n",
    "import numpy as np, tensorflow as tf, pandas as pd, pickle as pkl \n",
    "sys.path.append('../')  \n",
    "from ModelDefinitions import * \n",
    "from DataProcFunctions import * \n",
    "\n",
    "### RxGy TQR setting: \n",
    "p_quantile = 0.3 ## percentage of quantile to aim for \n",
    "num_optimize_iterations = 2500 ## number of optimization iterations \n",
    "num_modeling_inits = 3 ## number of random initializations \n",
    "num_hidden = 0 ## number of hidden units in DNN \n",
    "use_schedule = True ## option to use a constraint annealing schedule \n",
    "temp = 0.5 ## initial temperature for constraints \n",
    "inc_temp = 0.1 ## increment of temperature per 100 iterations \n",
    "save_cf_data = False ### whether to save data for causal forest training \n",
    "\n",
    "## set a random seed to reproduce results \n",
    "seed = 1234; tf.compat.v2.random.set_seed(seed); np.random.seed(seed) \n",
    "\n",
    "sample_frac = 1.0 ## option to sample data by a fraction \\in (0, 1) \n",
    "data_filename =  '../data/r2e_ma_training_data_v5_2019_07_08_vc_tr_featuremod3' \n",
    "prefix = 'r2e_v5_07_08_featuremod3_tr_iter100_run4' \n",
    "\n",
    "D_tre, D_unt, Dv_tre, Dv_unt, Dt_tre, Dt_unt, o_tre, o_unt, ov_tre, ov_unt, ot_tre, ot_unt, c_tre, c_unt, cv_tre, cv_unt, ct_tre, ct_unt, D, w, o, c, Dv, wv, ov, cv, Dt, wt, ot, ct = LoadDataFromPkl(data_filename, frac = sample_frac, save_cf_data=save_cf_data) \n",
    "\n",
    "print('### ----- start the training of deep learning models ------ ') \n",
    "gs_tqr = [] \n",
    "gs_drm = [] \n",
    "for i in range(num_modeling_inits): \n",
    "    gs_tqr.append(tf.Graph()) \n",
    "for i in range(num_modeling_inits): \n",
    "    gs_drm.append(tf.Graph()) \n",
    "\n",
    "print('------> Training TQR ranking model .... ') \n",
    "val_results = [] \n",
    "sess_list = [] \n",
    "for i in range(num_modeling_inits): \n",
    "    print('---> running cross validation, iteration: ' + str(i)) \n",
    "    obj, opt, dumh, dumhu, vtemp, p_quantile = TunableTQRankingModelDNN(gs_tqr[i], D_tre, D_unt, o_tre, o_unt, c_tre, c_unt, 'train-first', temp, p_quantile, num_hidden, use_schedule) \n",
    "    ### session definitions and variable initialization \n",
    "    sess = tf.Session(graph = gs_tqr[i]) \n",
    "    sess_list.append(sess) \n",
    "    \n",
    "    ### initialize variables and run optimization \n",
    "    with gs_tqr[i].as_default() as g: \n",
    "        init = tf.global_variables_initializer() \n",
    "    sess.run(init) \n",
    "    cur_temp = temp \n",
    "    for step in range(num_optimize_iterations): \n",
    "        _, objres = sess.run([opt, obj]) \n",
    "        if step % 100 == 0: \n",
    "            cur_temp = cur_temp + inc_temp \n",
    "            print('opt. step : ' + str(step) + ' obj: ' + str(objres)) \n",
    "            if use_schedule: \n",
    "                sess.run(vtemp.assign(cur_temp))\n",
    "                print('setting temperature to :' + str(sess.run(vtemp))) \n",
    "    \n",
    "    print('---> optimization finished ... ') \n",
    "    tempvalue = sess.run(vtemp)\n",
    "    p_quantilevalue = p_quantile\n",
    "    print('temp:') \n",
    "    print(tempvalue)\n",
    "    print('p_quantile:')\n",
    "    print(p_quantilevalue) \n",
    "    \n",
    "    ### evaluate CPIT metric on validation set \n",
    "    objv, dumo, dumh, dumhu, dvtemp, dp_quantile = TunableTQRankingModelDNN(gs_tqr[i], Dv_tre, Dv_unt, ov_tre, ov_unt, cv_tre, cv_unt, 'eval', temp, p_quantile, num_hidden, use_schedule) \n",
    "    \n",
    "    val_result = sess.run(objv) \n",
    "    print('validation CPIT:') \n",
    "    print(val_result) \n",
    "    val_results.append(val_result) \n",
    "\n",
    "from operator import itemgetter \n",
    "best_index = min(enumerate(val_results), key=itemgetter(1))[0] \n",
    "\n",
    "print('best performing model: iteration ' + str(best_index)) \n",
    "\n",
    "### run scoring on whole test set \n",
    "with gs_tqr[best_index].as_default() as g: \n",
    "    if num_hidden > 0: \n",
    "        with tf.variable_scope(\"tqrhidden\") as scope: \n",
    "            h1_test = tf.contrib.layers.fully_connected(Dt, num_hidden, activation_fn=tf.nn.tanh, reuse=tf.AUTO_REUSE, scope=scope, weights_initializer=tf.contrib.layers.xavier_initializer()) \n",
    "        with tf.variable_scope(\"tqranker\") as scope: \n",
    "            h_test = tf.contrib.layers.fully_connected(h1_test, 1, activation_fn=None, reuse=tf.AUTO_REUSE, scope=scope) \n",
    "    else: \n",
    "        with tf.variable_scope(\"tqranker\") as scope: \n",
    "            h_test = tf.contrib.layers.fully_connected(Dt, 1, activation_fn=None, reuse=tf.AUTO_REUSE, scope=scope) \n",
    "    tqrscore = sess_list[best_index].run(h_test) \n",
    "\n",
    "print('------> Training DRM ranking model .... ') \n",
    "sess_list = [] \n",
    "val_results = [] \n",
    "for i in range(num_modeling_inits): \n",
    "    print('---> running cross validation, iteration: ' + str(i)) \n",
    "    ### ---- train cpit ranking model for comparison --- \n",
    "    dobjc, doptc, ddumh, ddumu = DirectRankingModelDNN(gs_drm[i], D_tre, D_unt, o_tre, o_unt, c_tre, c_unt, 'train-first-drm', num_hidden) \n",
    "    \n",
    "    dsess = tf.Session(graph = gs_drm[i]) \n",
    "    sess_list.append(dsess) \n",
    "    \n",
    "    ### initialize variables and run optimization \n",
    "    with gs_drm[i].as_default() as g: \n",
    "        dinit = tf.global_variables_initializer() \n",
    "    dsess.run(dinit) \n",
    "    for step in range(num_optimize_iterations): \n",
    "        _, dobjres = dsess.run([doptc, dobjc]) \n",
    "        if step % 100 == 0: \n",
    "            print('opt. step : ' + str(step) + ' obj: ' + str(dobjres)) \n",
    "    \n",
    "    print('---> optimization finished ... ') \n",
    "    \n",
    "    ### evaluate CPIT metric on validation set \n",
    "    dobjv, ddumo, dumh, dumhu = DirectRankingModelDNN(gs_drm[i], Dv_tre, Dv_unt, ov_tre, ov_unt, cv_tre, cv_unt, 'eval', num_hidden)\n",
    "    val_result = dsess.run(dobjv) \n",
    "    print('validation CPIT:') \n",
    "    print(val_result) \n",
    "    val_results.append(val_result) \n",
    "\n",
    "best_index = min(enumerate(val_results), key=itemgetter(1))[0] \n",
    "\n",
    "print('best performing model: iteration ' + str(best_index)) \n",
    "\n",
    "### run scoring on whole test set \n",
    "with gs_drm[best_index].as_default() as g: \n",
    "    if num_hidden > 0: \n",
    "        with tf.variable_scope(\"drmhidden\") as scope: \n",
    "            h1_test = tf.contrib.layers.fully_connected(Dt, num_hidden, activation_fn=tf.nn.tanh, reuse=tf.AUTO_REUSE, scope=scope, weights_initializer=tf.contrib.layers.xavier_initializer()) \n",
    "        with tf.variable_scope(\"drmranker\") as scope: \n",
    "            h_test = tf.contrib.layers.fully_connected(h1_test, 1, activation_fn=tf.nn.tanh, reuse=tf.AUTO_REUSE, scope=scope) \n",
    "    else: \n",
    "        with tf.variable_scope(\"drmranker\") as scope: \n",
    "            h_test = tf.contrib.layers.fully_connected(Dt, 1, activation_fn=tf.nn.tanh, reuse=tf.AUTO_REUSE, scope=scope) \n",
    "    drmscore = sess_list[best_index].run(h_test) \n",
    "\n",
    "### ---- train hte model for comparison ---- \n",
    "### we could utimize the original HTE functions \n",
    "from LinearHTEModels import * \n",
    "from PromotionModels import PromotionModels \n",
    "\n",
    "pmodels = PromotionModels() \n",
    "\n",
    "## set-up RLearner \n",
    "rl_ridge_model_O, rl_ridge_model_C = pmodels.fit_rlearner(D, o, c, w) \n",
    "\n",
    "## one model for order lift and one model for cost drop \n",
    "pred_values_va_rlearner_O = rl_ridge_model_O.predict(Dt) \n",
    "pred_values_va_rlearner_C = rl_ridge_model_C.predict(Dt) \n",
    "\n",
    "#if ranking_model == 'effectiveness-ratio': ## if we use the effectiveness ratio model, compute effectiveness ratio \n",
    "pred_values_va_rlearner = np.divide(np.maximum(pred_values_va_rlearner_O, 0), pred_values_va_rlearner_C + 1e-7) \n",
    "\n",
    "lhmodels = LinearHTEModels() \n",
    "\n",
    "\"\"\" \n",
    "### this section is to load the results trained by grf R code \n",
    "### \n",
    "\n",
    "ot_cf = pd.read_csv('../results/causal_forest_grf_test_set_results_O_finalsize_numtrees1002.csv') \n",
    "ct_cf = pd.read_csv('../results/causal_forest_grf_test_set_results_C_finalsize_numtrees1002.csv') \n",
    "\n",
    "ot_cf = ot_cf.as_matrix() \n",
    "Ocfscores = ot_cf[0] \n",
    "\n",
    "ct_cf = ct_cf.as_matrix() \n",
    "Ccfscores = ct_cf[0] \n",
    "\n",
    "cfscore = np.divide(Ocfscores, Ccfscores) \n",
    "\"\"\" \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>ata_trip_max_avg_84d</th>\n",
       "      <th>churns_hard_lifetime</th>\n",
       "      <th>churns_soft_lifetime</th>\n",
       "      <th>cohort</th>\n",
       "      <th>days_active_84d</th>\n",
       "      <th>days_since_last_hard_churn_lifetime</th>\n",
       "      <th>days_since_last_soft_churn_lifetime</th>\n",
       "      <th>...</th>\n",
       "      <th>trip_complete_per_days_active_84d</th>\n",
       "      <th>trip_complete_win7d_sd_84d</th>\n",
       "      <th>trip_incomplete_total_84d</th>\n",
       "      <th>trip_pool_matched_avg_84d</th>\n",
       "      <th>trip_pool_per_x_84d</th>\n",
       "      <th>trip_pool_prc_84d</th>\n",
       "      <th>trip_x_prc_84d</th>\n",
       "      <th>trips_lifetime</th>\n",
       "      <th>useruuid</th>\n",
       "      <th>uuid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>1.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.276385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>df140d8a-7733-4351-a41c-e01850b2bbaf</td>\n",
       "      <td>df140d8a-7733-4351-a41c-e01850b2bbaf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>272.500000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>2.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.372678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>174cff21-848b-4973-99ab-b3850e2308ae</td>\n",
       "      <td>174cff21-848b-4973-99ab-b3850e2308ae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>198.214286</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>29.0</td>\n",
       "      <td>899.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.482759</td>\n",
       "      <td>2.984916</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>199.0</td>\n",
       "      <td>971d40d2-a965-49ac-ba37-87564bff2733</td>\n",
       "      <td>971d40d2-a965-49ac-ba37-87564bff2733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>173.450000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>20.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>1.771691</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>228.0</td>\n",
       "      <td>dcb048e0-7388-4c5e-8afa-2d8c42a4a455</td>\n",
       "      <td>dcb048e0-7388-4c5e-8afa-2d8c42a4a455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>166.083333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>12.0</td>\n",
       "      <td>953.0</td>\n",
       "      <td>1047.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>2.711857</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>75.0</td>\n",
       "      <td>b92beda1-ec65-4587-adee-01f486cd0b5a</td>\n",
       "      <td>b92beda1-ec65-4587-adee-01f486cd0b5a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>260.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>4.0</td>\n",
       "      <td>293.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.640095</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>52.0</td>\n",
       "      <td>563332bf-e639-446e-9017-000933541ea4</td>\n",
       "      <td>563332bf-e639-446e-9017-000933541ea4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>231.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>3.0</td>\n",
       "      <td>503.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3774ca20-1002-42cd-b958-f9f492df533c</td>\n",
       "      <td>3774ca20-1002-42cd-b958-f9f492df533c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>3.0</td>\n",
       "      <td>997.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.623610</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>144.0</td>\n",
       "      <td>884ae0a4-0689-4569-a4d3-1db40fdf51b6</td>\n",
       "      <td>884ae0a4-0689-4569-a4d3-1db40fdf51b6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>208.666667</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>6.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.771691</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>52.0</td>\n",
       "      <td>a3276f9f-5544-4e10-9dfd-b73796284caf</td>\n",
       "      <td>a3276f9f-5544-4e10-9dfd-b73796284caf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>273.250000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>4.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.623610</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>48.0</td>\n",
       "      <td>c99d1b97-a85a-4d16-b6c3-d250a1d68f55</td>\n",
       "      <td>c99d1b97-a85a-4d16-b6c3-d250a1d68f55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>304.600000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>5.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>1.421560</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>33.0</td>\n",
       "      <td>85586bd0-2c5c-44b6-83f2-87450d59a47b</td>\n",
       "      <td>85586bd0-2c5c-44b6-83f2-87450d59a47b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>4.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.862007</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7d3afcd0-bcd8-4e7c-8c39-f0b1f8e02f16</td>\n",
       "      <td>7d3afcd0-bcd8-4e7c-8c39-f0b1f8e02f16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>418.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.595119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>68edb4b0-df6a-4a03-8195-5ef9280fc141</td>\n",
       "      <td>68edb4b0-df6a-4a03-8195-5ef9280fc141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>349.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>3.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.384437</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>54.0</td>\n",
       "      <td>113ee0dd-e992-47a1-ac64-c72fc796389e</td>\n",
       "      <td>113ee0dd-e992-47a1-ac64-c72fc796389e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>287.282051</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>39.0</td>\n",
       "      <td>357.0</td>\n",
       "      <td>458.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.461538</td>\n",
       "      <td>2.680951</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>134.0</td>\n",
       "      <td>354272c5-2427-4af3-b049-19e6ba642b44</td>\n",
       "      <td>354272c5-2427-4af3-b049-19e6ba642b44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>244.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>10.0</td>\n",
       "      <td>647.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.080123</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>269.0</td>\n",
       "      <td>4684a513-71b6-4894-b631-8f812e7fc7c5</td>\n",
       "      <td>4684a513-71b6-4894-b631-8f812e7fc7c5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>464.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>2.0</td>\n",
       "      <td>524.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.372678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>c6faea83-c88a-4411-ac7d-95a125dc65dc</td>\n",
       "      <td>c6faea83-c88a-4411-ac7d-95a125dc65dc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>320.900000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>10.0</td>\n",
       "      <td>555.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.527525</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>94.0</td>\n",
       "      <td>53aa1911-a29d-4218-ae90-7d80f6165af5</td>\n",
       "      <td>53aa1911-a29d-4218-ae90-7d80f6165af5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>236.937500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>32.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.437500</td>\n",
       "      <td>2.034426</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>139.0</td>\n",
       "      <td>e0011c10-0846-4c43-a704-80e69bf48d6f</td>\n",
       "      <td>e0011c10-0846-4c43-a704-80e69bf48d6f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>276.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>6.0</td>\n",
       "      <td>567.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.705791</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1d1494f6-b34a-4783-b464-faba8113fa48</td>\n",
       "      <td>1d1494f6-b34a-4783-b464-faba8113fa48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>2.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.105542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>91.0</td>\n",
       "      <td>01d63b42-0f29-4a80-b639-cb8193e5ee1d</td>\n",
       "      <td>01d63b42-0f29-4a80-b639-cb8193e5ee1d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>1.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.276385</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>cb76ba0c-6e8e-42ec-8c8a-d205e038cade</td>\n",
       "      <td>cb76ba0c-6e8e-42ec-8c8a-d205e038cade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>525.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1259.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.276385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>d8461714-d01f-4faf-9123-0c74539639fc</td>\n",
       "      <td>d8461714-d01f-4faf-9123-0c74539639fc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>172.500000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>4.0</td>\n",
       "      <td>382.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>88.0</td>\n",
       "      <td>e6adb12f-4ee9-4971-a303-a1464a732be9</td>\n",
       "      <td>e6adb12f-4ee9-4971-a303-a1464a732be9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>151.250000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>8.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>0.924211</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>96.0</td>\n",
       "      <td>ec3f25b8-4bf9-4e1a-9913-23295fbafb21</td>\n",
       "      <td>ec3f25b8-4bf9-4e1a-9913-23295fbafb21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>336.111111</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>27.0</td>\n",
       "      <td>919.0</td>\n",
       "      <td>804.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.481481</td>\n",
       "      <td>3.009245</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>483.0</td>\n",
       "      <td>9aa3873c-cc63-498a-bc57-15ab67a2d4ce</td>\n",
       "      <td>9aa3873c-cc63-498a-bc57-15ab67a2d4ce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>206.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>5.0</td>\n",
       "      <td>578.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.645497</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>33.0</td>\n",
       "      <td>123d411b-9357-41b4-a473-9d7081b3b7f0</td>\n",
       "      <td>123d411b-9357-41b4-a473-9d7081b3b7f0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>346.538462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.307692</td>\n",
       "      <td>1.187317</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>225.0</td>\n",
       "      <td>04c2321b-ddc7-4932-887d-ee0aa8e99458</td>\n",
       "      <td>04c2321b-ddc7-4932-887d-ee0aa8e99458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>treatment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62b16b8d-9642-43d2-b05e-994e5a7c826d</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>227.714286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>treatment</td>\n",
       "      <td>7.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.640095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>c1962615-0448-4d21-8e7e-5a0dbf9fe17c</td>\n",
       "      <td>c1962615-0448-4d21-8e7e-5a0dbf9fe17c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068696</th>\n",
       "      <td>1068696</td>\n",
       "      <td>1068696</td>\n",
       "      <td>1068696</td>\n",
       "      <td>309.857143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>control</td>\n",
       "      <td>21.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.190476</td>\n",
       "      <td>1.605113</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>93.0</td>\n",
       "      <td>221aae5e-c41a-4079-8852-1889c3ba7ce3</td>\n",
       "      <td>221aae5e-c41a-4079-8852-1889c3ba7ce3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068697</th>\n",
       "      <td>1068697</td>\n",
       "      <td>1068697</td>\n",
       "      <td>1068697</td>\n",
       "      <td>545.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>control</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.953794</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>a7bcbd4a-23d4-494a-821d-bc8272572574</td>\n",
       "      <td>a7bcbd4a-23d4-494a-821d-bc8272572574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068698</th>\n",
       "      <td>1068698</td>\n",
       "      <td>1068698</td>\n",
       "      <td>1068698</td>\n",
       "      <td>218.750000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>control</td>\n",
       "      <td>4.0</td>\n",
       "      <td>618.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>70.0</td>\n",
       "      <td>b8aab666-4b2b-492b-ae3d-bb9a42363424</td>\n",
       "      <td>b8aab666-4b2b-492b-ae3d-bb9a42363424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068699</th>\n",
       "      <td>1068699</td>\n",
       "      <td>1068699</td>\n",
       "      <td>1068699</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>control</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5a7b3caf-a8aa-40de-a327-e25803761d2c</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068700</th>\n",
       "      <td>1068700</td>\n",
       "      <td>1068700</td>\n",
       "      <td>1068700</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>control</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.276385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94936bd2-c03d-44c2-b873-13a4148ceea8</td>\n",
       "      <td>94936bd2-c03d-44c2-b873-13a4148ceea8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068701</th>\n",
       "      <td>1068701</td>\n",
       "      <td>1068701</td>\n",
       "      <td>1068701</td>\n",
       "      <td>260.166667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>control</td>\n",
       "      <td>6.0</td>\n",
       "      <td>909.0</td>\n",
       "      <td>993.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.645497</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0517308d-b85a-4d7d-8c4a-9408d8d30c44</td>\n",
       "      <td>0517308d-b85a-4d7d-8c4a-9408d8d30c44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068702</th>\n",
       "      <td>1068702</td>\n",
       "      <td>1068702</td>\n",
       "      <td>1068702</td>\n",
       "      <td>171.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>control</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>497.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.276385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>53dcb85b-1c2d-4bf9-9fec-fd22f82afa4f</td>\n",
       "      <td>53dcb85b-1c2d-4bf9-9fec-fd22f82afa4f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068703</th>\n",
       "      <td>1068703</td>\n",
       "      <td>1068703</td>\n",
       "      <td>1068703</td>\n",
       "      <td>61.500000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>control</td>\n",
       "      <td>2.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.372678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>37.0</td>\n",
       "      <td>5c0621c0-b51f-4a3a-b09a-20d6159bc6a5</td>\n",
       "      <td>5c0621c0-b51f-4a3a-b09a-20d6159bc6a5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068704</th>\n",
       "      <td>1068704</td>\n",
       "      <td>1068704</td>\n",
       "      <td>1068704</td>\n",
       "      <td>216.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>control</td>\n",
       "      <td>3.0</td>\n",
       "      <td>802.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>119.0</td>\n",
       "      <td>4391eead-bae6-45c8-9307-137742f5e101</td>\n",
       "      <td>4391eead-bae6-45c8-9307-137742f5e101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068705</th>\n",
       "      <td>1068705</td>\n",
       "      <td>1068705</td>\n",
       "      <td>1068705</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>control</td>\n",
       "      <td>2.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.372678</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20202959-8005-469c-8c72-adf24bf87356</td>\n",
       "      <td>20202959-8005-469c-8c72-adf24bf87356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068706</th>\n",
       "      <td>1068706</td>\n",
       "      <td>1068706</td>\n",
       "      <td>1068706</td>\n",
       "      <td>271.037736</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>control</td>\n",
       "      <td>53.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.811321</td>\n",
       "      <td>3.651484</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>218.0</td>\n",
       "      <td>fbebc154-7165-4b15-8376-d61766d46828</td>\n",
       "      <td>fbebc154-7165-4b15-8376-d61766d46828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068707</th>\n",
       "      <td>1068707</td>\n",
       "      <td>1068707</td>\n",
       "      <td>1068707</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>control</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.276385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>023b1f83-909e-4520-b7ff-f242ebf57c65</td>\n",
       "      <td>023b1f83-909e-4520-b7ff-f242ebf57c65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068708</th>\n",
       "      <td>1068708</td>\n",
       "      <td>1068708</td>\n",
       "      <td>1068708</td>\n",
       "      <td>356.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>control</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.829156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>478ddd49-750b-4ab2-b778-b7dffb0000be</td>\n",
       "      <td>478ddd49-750b-4ab2-b778-b7dffb0000be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068709</th>\n",
       "      <td>1068709</td>\n",
       "      <td>1068709</td>\n",
       "      <td>1068709</td>\n",
       "      <td>266.166667</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>control</td>\n",
       "      <td>6.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.027402</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>c9124fc2-0348-463b-a20d-b394a6ab11f7</td>\n",
       "      <td>c9124fc2-0348-463b-a20d-b394a6ab11f7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068710</th>\n",
       "      <td>1068710</td>\n",
       "      <td>1068710</td>\n",
       "      <td>1068710</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>control</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.276385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8fa3a74d-d9aa-447c-960a-072fe44d32bb</td>\n",
       "      <td>8fa3a74d-d9aa-447c-960a-072fe44d32bb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068711</th>\n",
       "      <td>1068711</td>\n",
       "      <td>1068711</td>\n",
       "      <td>1068711</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>control</td>\n",
       "      <td>2.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.372678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>71.0</td>\n",
       "      <td>4165f41d-fa37-4b93-aedf-dbbf564cde7c</td>\n",
       "      <td>4165f41d-fa37-4b93-aedf-dbbf564cde7c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068712</th>\n",
       "      <td>1068712</td>\n",
       "      <td>1068712</td>\n",
       "      <td>1068712</td>\n",
       "      <td>282.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>control</td>\n",
       "      <td>3.0</td>\n",
       "      <td>529.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.623610</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>32.0</td>\n",
       "      <td>b4e75f35-2762-4b2b-a584-2f313672562c</td>\n",
       "      <td>b4e75f35-2762-4b2b-a584-2f313672562c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068713</th>\n",
       "      <td>1068713</td>\n",
       "      <td>1068713</td>\n",
       "      <td>1068713</td>\n",
       "      <td>488.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>control</td>\n",
       "      <td>1.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.276385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>39.0</td>\n",
       "      <td>64496eee-2eb5-4065-a682-94a28ddedc5e</td>\n",
       "      <td>64496eee-2eb5-4065-a682-94a28ddedc5e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068714</th>\n",
       "      <td>1068714</td>\n",
       "      <td>1068714</td>\n",
       "      <td>1068714</td>\n",
       "      <td>131.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>control</td>\n",
       "      <td>2.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.372678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>834d0145-08ae-4cf8-bf56-996010516632</td>\n",
       "      <td>834d0145-08ae-4cf8-bf56-996010516632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068715</th>\n",
       "      <td>1068715</td>\n",
       "      <td>1068715</td>\n",
       "      <td>1068715</td>\n",
       "      <td>242.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>control</td>\n",
       "      <td>4.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0dbb7cb8-312b-4f20-bfb8-11ef36d055f4</td>\n",
       "      <td>0dbb7cb8-312b-4f20-bfb8-11ef36d055f4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068716</th>\n",
       "      <td>1068716</td>\n",
       "      <td>1068716</td>\n",
       "      <td>1068716</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>control</td>\n",
       "      <td>2.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.114924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>dec851ab-d314-4ac2-a9ad-e89be964d851</td>\n",
       "      <td>dec851ab-d314-4ac2-a9ad-e89be964d851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068717</th>\n",
       "      <td>1068717</td>\n",
       "      <td>1068717</td>\n",
       "      <td>1068717</td>\n",
       "      <td>272.875000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>control</td>\n",
       "      <td>8.0</td>\n",
       "      <td>762.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.897527</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>93.0</td>\n",
       "      <td>68440cd4-f24a-47c8-ba52-bc362099bc2f</td>\n",
       "      <td>68440cd4-f24a-47c8-ba52-bc362099bc2f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068718</th>\n",
       "      <td>1068718</td>\n",
       "      <td>1068718</td>\n",
       "      <td>1068718</td>\n",
       "      <td>138.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>control</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1175.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.763763</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>61.0</td>\n",
       "      <td>ee459d97-31d5-4104-9c8c-be6fdc1ba564</td>\n",
       "      <td>ee459d97-31d5-4104-9c8c-be6fdc1ba564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068719</th>\n",
       "      <td>1068719</td>\n",
       "      <td>1068719</td>\n",
       "      <td>1068719</td>\n",
       "      <td>270.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>control</td>\n",
       "      <td>4.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.745356</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>d79bc1b5-81e5-4fbe-938c-baef8b2e8006</td>\n",
       "      <td>d79bc1b5-81e5-4fbe-938c-baef8b2e8006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068720</th>\n",
       "      <td>1068720</td>\n",
       "      <td>1068720</td>\n",
       "      <td>1068720</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>control</td>\n",
       "      <td>1.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.276385</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>27.0</td>\n",
       "      <td>28c2924a-48a0-4297-80a3-cc25e72cdced</td>\n",
       "      <td>28c2924a-48a0-4297-80a3-cc25e72cdced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068721</th>\n",
       "      <td>1068721</td>\n",
       "      <td>1068721</td>\n",
       "      <td>1068721</td>\n",
       "      <td>219.909091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>control</td>\n",
       "      <td>11.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.454545</td>\n",
       "      <td>2.560382</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>590c538c-4ad0-4df4-8831-5fa3fa20d7f2</td>\n",
       "      <td>590c538c-4ad0-4df4-8831-5fa3fa20d7f2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068722</th>\n",
       "      <td>1068722</td>\n",
       "      <td>1068722</td>\n",
       "      <td>1068722</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>control</td>\n",
       "      <td>1.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.276385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>fe13ffcb-9661-4226-b893-debdb11bc67e</td>\n",
       "      <td>fe13ffcb-9661-4226-b893-debdb11bc67e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068723</th>\n",
       "      <td>1068723</td>\n",
       "      <td>1068723</td>\n",
       "      <td>1068723</td>\n",
       "      <td>607.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>control</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.276385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3c4b299a-751d-4894-b7d2-d17f23f2563c</td>\n",
       "      <td>3c4b299a-751d-4894-b7d2-d17f23f2563c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068724</th>\n",
       "      <td>1068724</td>\n",
       "      <td>1068724</td>\n",
       "      <td>1068724</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>control</td>\n",
       "      <td>5.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.640095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16c1dbaa-4d22-42ea-b548-d1ababe0cae6</td>\n",
       "      <td>16c1dbaa-4d22-42ea-b548-d1ababe0cae6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068725</th>\n",
       "      <td>1068725</td>\n",
       "      <td>1068725</td>\n",
       "      <td>1068725</td>\n",
       "      <td>348.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>control</td>\n",
       "      <td>1.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.276385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>c0d0762b-ce1d-49e9-b1a7-c1045f9740e0</td>\n",
       "      <td>c0d0762b-ce1d-49e9-b1a7-c1045f9740e0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1068726 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  ata_trip_max_avg_84d  \\\n",
       "0                 0             0               0            113.000000   \n",
       "1                 1             1               1            272.500000   \n",
       "2                 2             2               2            198.214286   \n",
       "3                 3             3               3            173.450000   \n",
       "4                 4             4               4            166.083333   \n",
       "5                 5             5               5            260.500000   \n",
       "6                 6             6               6            231.666667   \n",
       "7                 7             7               7            161.000000   \n",
       "8                 8             8               8            208.666667   \n",
       "9                 9             9               9            273.250000   \n",
       "10               10            10              10            304.600000   \n",
       "11               11            11              11            247.000000   \n",
       "12               12            12              12            418.500000   \n",
       "13               13            13              13            349.333333   \n",
       "14               14            14              14            287.282051   \n",
       "15               15            15              15            244.800000   \n",
       "16               16            16              16            464.000000   \n",
       "17               17            17              17            320.900000   \n",
       "18               18            18              18            236.937500   \n",
       "19               19            19              19            276.000000   \n",
       "20               20            20              20            108.000000   \n",
       "21               21            21              21            203.000000   \n",
       "22               22            22              22            525.000000   \n",
       "23               23            23              23            172.500000   \n",
       "24               24            24              24            151.250000   \n",
       "25               25            25              25            336.111111   \n",
       "26               26            26              26            206.200000   \n",
       "27               27            27              27            346.538462   \n",
       "28               28            28              28                   NaN   \n",
       "29               29            29              29            227.714286   \n",
       "...             ...           ...             ...                   ...   \n",
       "1068696     1068696       1068696         1068696            309.857143   \n",
       "1068697     1068697       1068697         1068697            545.250000   \n",
       "1068698     1068698       1068698         1068698            218.750000   \n",
       "1068699     1068699       1068699         1068699                   NaN   \n",
       "1068700     1068700       1068700         1068700            139.000000   \n",
       "1068701     1068701       1068701         1068701            260.166667   \n",
       "1068702     1068702       1068702         1068702            171.000000   \n",
       "1068703     1068703       1068703         1068703             61.500000   \n",
       "1068704     1068704       1068704         1068704            216.666667   \n",
       "1068705     1068705       1068705         1068705            420.000000   \n",
       "1068706     1068706       1068706         1068706            271.037736   \n",
       "1068707     1068707       1068707         1068707            110.000000   \n",
       "1068708     1068708       1068708         1068708            356.000000   \n",
       "1068709     1068709       1068709         1068709            266.166667   \n",
       "1068710     1068710       1068710         1068710            192.000000   \n",
       "1068711     1068711       1068711         1068711            143.000000   \n",
       "1068712     1068712       1068712         1068712            282.333333   \n",
       "1068713     1068713       1068713         1068713            488.000000   \n",
       "1068714     1068714       1068714         1068714            131.500000   \n",
       "1068715     1068715       1068715         1068715            242.000000   \n",
       "1068716     1068716       1068716         1068716            178.000000   \n",
       "1068717     1068717       1068717         1068717            272.875000   \n",
       "1068718     1068718       1068718         1068718            138.250000   \n",
       "1068719     1068719       1068719         1068719            270.750000   \n",
       "1068720     1068720       1068720         1068720             41.000000   \n",
       "1068721     1068721       1068721         1068721            219.909091   \n",
       "1068722     1068722       1068722         1068722             98.000000   \n",
       "1068723     1068723       1068723         1068723            607.000000   \n",
       "1068724     1068724       1068724         1068724            119.000000   \n",
       "1068725     1068725       1068725         1068725            348.000000   \n",
       "\n",
       "         churns_hard_lifetime  churns_soft_lifetime     cohort  \\\n",
       "0                         1.0                   1.0  treatment   \n",
       "1                         3.0                   3.0  treatment   \n",
       "2                         2.0                   7.0  treatment   \n",
       "3                         0.0                   3.0  treatment   \n",
       "4                         1.0                   0.0  treatment   \n",
       "5                         1.0                   9.0  treatment   \n",
       "6                         1.0                   3.0  treatment   \n",
       "7                         1.0                   7.0  treatment   \n",
       "8                         5.0                   4.0  treatment   \n",
       "9                         1.0                   8.0  treatment   \n",
       "10                        1.0                   3.0  treatment   \n",
       "11                        2.0                   1.0  treatment   \n",
       "12                        0.0                   1.0  treatment   \n",
       "13                        2.0                  12.0  treatment   \n",
       "14                        2.0                   5.0  treatment   \n",
       "15                        1.0                   5.0  treatment   \n",
       "16                        2.0                   7.0  treatment   \n",
       "17                        3.0                   9.0  treatment   \n",
       "18                        1.0                   6.0  treatment   \n",
       "19                        0.0                   5.0  treatment   \n",
       "20                        3.0                   6.0  treatment   \n",
       "21                        1.0                   0.0  treatment   \n",
       "22                        4.0                   0.0  treatment   \n",
       "23                        2.0                   5.0  treatment   \n",
       "24                        3.0                   7.0  treatment   \n",
       "25                        1.0                   4.0  treatment   \n",
       "26                        0.0                   6.0  treatment   \n",
       "27                        0.0                   6.0  treatment   \n",
       "28                        NaN                   NaN  treatment   \n",
       "29                        0.0                   1.0  treatment   \n",
       "...                       ...                   ...        ...   \n",
       "1068696                   1.0                   3.0    control   \n",
       "1068697                   0.0                   0.0    control   \n",
       "1068698                   1.0                   6.0    control   \n",
       "1068699                   NaN                   NaN    control   \n",
       "1068700                   0.0                   0.0    control   \n",
       "1068701                   1.0                   0.0    control   \n",
       "1068702                   3.0                   4.0    control   \n",
       "1068703                   3.0                   8.0    control   \n",
       "1068704                   0.0                   7.0    control   \n",
       "1068705                   0.0                   3.0    control   \n",
       "1068706                   0.0                   0.0    control   \n",
       "1068707                   3.0                   3.0    control   \n",
       "1068708                   0.0                   0.0    control   \n",
       "1068709                   5.0                   8.0    control   \n",
       "1068710                   1.0                   1.0    control   \n",
       "1068711                   1.0                   9.0    control   \n",
       "1068712                   0.0                   6.0    control   \n",
       "1068713                   1.0                   6.0    control   \n",
       "1068714                   1.0                   1.0    control   \n",
       "1068715                   3.0                   8.0    control   \n",
       "1068716                   6.0                   2.0    control   \n",
       "1068717                   1.0                   3.0    control   \n",
       "1068718                   0.0                  18.0    control   \n",
       "1068719                   0.0                   2.0    control   \n",
       "1068720                   3.0                   2.0    control   \n",
       "1068721                   0.0                   1.0    control   \n",
       "1068722                   1.0                   0.0    control   \n",
       "1068723                   0.0                   0.0    control   \n",
       "1068724                   0.0                   0.0    control   \n",
       "1068725                   1.0                   1.0    control   \n",
       "\n",
       "         days_active_84d  days_since_last_hard_churn_lifetime  \\\n",
       "0                    1.0                                641.0   \n",
       "1                    2.0                                196.0   \n",
       "2                   29.0                                899.0   \n",
       "3                   20.0                                918.0   \n",
       "4                   12.0                                953.0   \n",
       "5                    4.0                                293.0   \n",
       "6                    3.0                                503.0   \n",
       "7                    3.0                                997.0   \n",
       "8                    6.0                                239.0   \n",
       "9                    4.0                                377.0   \n",
       "10                   5.0                                296.0   \n",
       "11                   4.0                                184.0   \n",
       "12                   2.0                                 60.0   \n",
       "13                   3.0                                 89.0   \n",
       "14                  39.0                                357.0   \n",
       "15                  10.0                                647.0   \n",
       "16                   2.0                                524.0   \n",
       "17                  10.0                                555.0   \n",
       "18                  32.0                                295.0   \n",
       "19                   6.0                                567.0   \n",
       "20                   2.0                                 74.0   \n",
       "21                   1.0                                122.0   \n",
       "22                   1.0                                 51.0   \n",
       "23                   4.0                                382.0   \n",
       "24                   8.0                                540.0   \n",
       "25                  27.0                                919.0   \n",
       "26                   5.0                                578.0   \n",
       "27                  13.0                               1037.0   \n",
       "28                   NaN                                  NaN   \n",
       "29                   7.0                                127.0   \n",
       "...                  ...                                  ...   \n",
       "1068696             21.0                                202.0   \n",
       "1068697              4.0                                 26.0   \n",
       "1068698              4.0                                618.0   \n",
       "1068699              NaN                                  NaN   \n",
       "1068700              1.0                                 10.0   \n",
       "1068701              6.0                                909.0   \n",
       "1068702              1.0                                 78.0   \n",
       "1068703              2.0                                318.0   \n",
       "1068704              3.0                                802.0   \n",
       "1068705              2.0                                279.0   \n",
       "1068706             53.0                                244.0   \n",
       "1068707              1.0                                 28.0   \n",
       "1068708              2.0                                  8.0   \n",
       "1068709              6.0                                 60.0   \n",
       "1068710              1.0                                100.0   \n",
       "1068711              2.0                                126.0   \n",
       "1068712              3.0                                529.0   \n",
       "1068713              1.0                                327.0   \n",
       "1068714              2.0                                 99.0   \n",
       "1068715              4.0                                153.0   \n",
       "1068716              2.0                                 58.0   \n",
       "1068717              8.0                                762.0   \n",
       "1068718              4.0                               1175.0   \n",
       "1068719              4.0                                115.0   \n",
       "1068720              1.0                                236.0   \n",
       "1068721             11.0                                 85.0   \n",
       "1068722              1.0                                178.0   \n",
       "1068723              1.0                                 13.0   \n",
       "1068724              5.0                                 35.0   \n",
       "1068725              1.0                                217.0   \n",
       "\n",
       "         days_since_last_soft_churn_lifetime  ...  \\\n",
       "0                                       40.0  ...   \n",
       "1                                       17.0  ...   \n",
       "2                                      224.0  ...   \n",
       "3                                      405.0  ...   \n",
       "4                                     1047.0  ...   \n",
       "5                                        0.0  ...   \n",
       "6                                       41.0  ...   \n",
       "7                                       50.0  ...   \n",
       "8                                       46.0  ...   \n",
       "9                                        0.0  ...   \n",
       "10                                      36.0  ...   \n",
       "11                                      67.0  ...   \n",
       "12                                      19.0  ...   \n",
       "13                                      42.0  ...   \n",
       "14                                     458.0  ...   \n",
       "15                                     169.0  ...   \n",
       "16                                      48.0  ...   \n",
       "17                                      26.0  ...   \n",
       "18                                      84.0  ...   \n",
       "19                                       1.0  ...   \n",
       "20                                      26.0  ...   \n",
       "21                                     212.0  ...   \n",
       "22                                    1259.0  ...   \n",
       "23                                      62.0  ...   \n",
       "24                                      20.0  ...   \n",
       "25                                     804.0  ...   \n",
       "26                                      79.0  ...   \n",
       "27                                     153.0  ...   \n",
       "28                                       NaN  ...   \n",
       "29                                      83.0  ...   \n",
       "...                                      ...  ...   \n",
       "1068696                                371.0  ...   \n",
       "1068697                                 26.0  ...   \n",
       "1068698                                  7.0  ...   \n",
       "1068699                                  NaN  ...   \n",
       "1068700                                 10.0  ...   \n",
       "1068701                                993.0  ...   \n",
       "1068702                                497.0  ...   \n",
       "1068703                                 18.0  ...   \n",
       "1068704                                 46.0  ...   \n",
       "1068705                                 14.0  ...   \n",
       "1068706                                244.0  ...   \n",
       "1068707                                140.0  ...   \n",
       "1068708                                  8.0  ...   \n",
       "1068709                                 19.0  ...   \n",
       "1068710                                  9.0  ...   \n",
       "1068711                                  4.0  ...   \n",
       "1068712                                 73.0  ...   \n",
       "1068713                                 52.0  ...   \n",
       "1068714                                 36.0  ...   \n",
       "1068715                                 21.0  ...   \n",
       "1068716                                159.0  ...   \n",
       "1068717                                213.0  ...   \n",
       "1068718                                 11.0  ...   \n",
       "1068719                                 21.0  ...   \n",
       "1068720                                 52.0  ...   \n",
       "1068721                                 36.0  ...   \n",
       "1068722                                262.0  ...   \n",
       "1068723                                 13.0  ...   \n",
       "1068724                                 35.0  ...   \n",
       "1068725                                310.0  ...   \n",
       "\n",
       "         trip_complete_per_days_active_84d  trip_complete_win7d_sd_84d  \\\n",
       "0                                 1.000000                    0.276385   \n",
       "1                                 1.000000                    0.372678   \n",
       "2                                 1.482759                    2.984916   \n",
       "3                                 1.100000                    1.771691   \n",
       "4                                 1.750000                    2.711857   \n",
       "5                                 1.250000                    0.640095   \n",
       "6                                 1.000000                    0.433013   \n",
       "7                                 1.333333                    0.623610   \n",
       "8                                 1.666667                    1.771691   \n",
       "9                                 1.000000                    0.623610   \n",
       "10                                1.800000                    1.421560   \n",
       "11                                1.250000                    0.862007   \n",
       "12                                1.500000                    0.595119   \n",
       "13                                2.000000                    1.384437   \n",
       "14                                1.461538                    2.680951   \n",
       "15                                1.200000                    1.080123   \n",
       "16                                1.000000                    0.372678   \n",
       "17                                1.200000                    1.527525   \n",
       "18                                1.437500                    2.034426   \n",
       "19                                1.833333                    1.705791   \n",
       "20                                2.000000                    1.105542   \n",
       "21                                     NaN                    0.276385   \n",
       "22                                1.000000                    0.276385   \n",
       "23                                1.000000                    0.471405   \n",
       "24                                1.125000                    0.924211   \n",
       "25                                1.481481                    3.009245   \n",
       "26                                1.200000                    0.645497   \n",
       "27                                1.307692                    1.187317   \n",
       "28                                     NaN                         NaN   \n",
       "29                                     NaN                    0.640095   \n",
       "...                                    ...                         ...   \n",
       "1068696                           1.190476                    1.605113   \n",
       "1068697                           1.250000                    0.953794   \n",
       "1068698                           1.000000                    0.471405   \n",
       "1068699                                NaN                         NaN   \n",
       "1068700                           1.000000                    0.276385   \n",
       "1068701                           1.000000                    0.645497   \n",
       "1068702                           1.000000                    0.276385   \n",
       "1068703                           1.000000                    0.372678   \n",
       "1068704                           1.000000                    0.433013   \n",
       "1068705                           1.000000                    0.372678   \n",
       "1068706                           1.811321                    3.651484   \n",
       "1068707                           1.000000                    0.276385   \n",
       "1068708                           1.500000                    0.829156   \n",
       "1068709                           1.333333                    1.027402   \n",
       "1068710                           1.000000                    0.276385   \n",
       "1068711                           1.000000                    0.372678   \n",
       "1068712                           1.333333                    0.623610   \n",
       "1068713                           1.000000                    0.276385   \n",
       "1068714                           1.000000                    0.372678   \n",
       "1068715                           1.000000                    0.471405   \n",
       "1068716                           2.500000                    1.114924   \n",
       "1068717                           1.250000                    0.897527   \n",
       "1068718                           1.500000                    0.763763   \n",
       "1068719                           1.000000                    0.745356   \n",
       "1068720                           1.000000                    0.276385   \n",
       "1068721                           1.454545                    2.560382   \n",
       "1068722                           1.000000                    0.276385   \n",
       "1068723                           1.000000                    0.276385   \n",
       "1068724                           1.000000                    0.640095   \n",
       "1068725                           1.000000                    0.276385   \n",
       "\n",
       "         trip_incomplete_total_84d  trip_pool_matched_avg_84d  \\\n",
       "0                              0.0                   0.000000   \n",
       "1                              0.0                   0.000000   \n",
       "2                              7.0                   0.275862   \n",
       "3                              1.0                   0.000000   \n",
       "4                              3.0                   0.000000   \n",
       "5                              1.0                   0.000000   \n",
       "6                              0.0                   0.000000   \n",
       "7                              3.0                   0.000000   \n",
       "8                              1.0                   0.000000   \n",
       "9                              1.0                   0.000000   \n",
       "10                             1.0                   0.000000   \n",
       "11                             3.0                   0.000000   \n",
       "12                             0.0                   0.000000   \n",
       "13                             1.0                   0.000000   \n",
       "14                             8.0                   0.000000   \n",
       "15                             1.0                   0.000000   \n",
       "16                             0.0                   0.000000   \n",
       "17                             1.0                   0.000000   \n",
       "18                             8.0                   0.000000   \n",
       "19                             1.0                   0.000000   \n",
       "20                             0.0                   0.000000   \n",
       "21                             1.0                   0.000000   \n",
       "22                             0.0                   0.000000   \n",
       "23                             0.0                   0.000000   \n",
       "24                             3.0                   0.000000   \n",
       "25                             6.0                   0.000000   \n",
       "26                             0.0                   0.000000   \n",
       "27                             0.0                   0.000000   \n",
       "28                             NaN                        NaN   \n",
       "29                             0.0                   0.000000   \n",
       "...                            ...                        ...   \n",
       "1068696                        3.0                   0.000000   \n",
       "1068697                        1.0                   0.000000   \n",
       "1068698                        0.0                   0.000000   \n",
       "1068699                        NaN                        NaN   \n",
       "1068700                        0.0                   0.000000   \n",
       "1068701                        0.0                   0.000000   \n",
       "1068702                        0.0                   0.000000   \n",
       "1068703                        0.0                   0.000000   \n",
       "1068704                        0.0                   0.000000   \n",
       "1068705                        2.0                   0.000000   \n",
       "1068706                       19.0                   0.000000   \n",
       "1068707                        0.0                   0.000000   \n",
       "1068708                        0.0                   0.000000   \n",
       "1068709                        0.0                   0.000000   \n",
       "1068710                        0.0                   0.000000   \n",
       "1068711                        0.0                   0.000000   \n",
       "1068712                        0.0                   0.000000   \n",
       "1068713                        0.0                   0.000000   \n",
       "1068714                        0.0                   0.000000   \n",
       "1068715                        3.0                   0.000000   \n",
       "1068716                        0.0                   0.000000   \n",
       "1068717                        3.0                   0.000000   \n",
       "1068718                        0.0                   0.000000   \n",
       "1068719                        0.0                   0.000000   \n",
       "1068720                        1.0                   0.000000   \n",
       "1068721                        5.0                   0.000000   \n",
       "1068722                        0.0                   0.000000   \n",
       "1068723                        0.0                   0.000000   \n",
       "1068724                        0.0                   0.000000   \n",
       "1068725                        0.0                   0.000000   \n",
       "\n",
       "         trip_pool_per_x_84d  trip_pool_prc_84d  trip_x_prc_84d  \\\n",
       "0                   0.000000               0.00        1.000000   \n",
       "1                   0.000000               0.00        1.000000   \n",
       "2                   0.851852               0.46        0.540000   \n",
       "3                   0.000000               0.00        1.000000   \n",
       "4                   0.000000               0.00        1.000000   \n",
       "5                   0.000000               0.00        1.000000   \n",
       "6                   0.000000               0.00        1.000000   \n",
       "7                   0.000000               0.00        1.000000   \n",
       "8                   0.000000               0.00        1.000000   \n",
       "9                   0.000000               0.00        1.000000   \n",
       "10                  0.000000               0.00        1.000000   \n",
       "11                  0.000000               0.00        1.000000   \n",
       "12                  0.000000               0.00        1.000000   \n",
       "13                  0.000000               0.00        1.000000   \n",
       "14                  0.000000               0.00        1.000000   \n",
       "15                  0.000000               0.00        1.000000   \n",
       "16                  0.000000               0.00        1.000000   \n",
       "17                  0.000000               0.00        1.000000   \n",
       "18                  0.000000               0.00        0.981481   \n",
       "19                  0.000000               0.00        1.000000   \n",
       "20                  0.000000               0.00        1.000000   \n",
       "21                       NaN                NaN             NaN   \n",
       "22                  0.000000               0.00        1.000000   \n",
       "23                  0.000000               0.00        1.000000   \n",
       "24                  0.000000               0.00        1.000000   \n",
       "25                  0.000000               0.00        1.000000   \n",
       "26                  0.000000               0.00        1.000000   \n",
       "27                  0.000000               0.00        1.000000   \n",
       "28                       NaN                NaN             NaN   \n",
       "29                       NaN                NaN             NaN   \n",
       "...                      ...                ...             ...   \n",
       "1068696             0.000000               0.00        1.000000   \n",
       "1068697             0.000000               0.00        1.000000   \n",
       "1068698             0.000000               0.00        1.000000   \n",
       "1068699                  NaN                NaN             NaN   \n",
       "1068700             0.000000               0.00        1.000000   \n",
       "1068701             0.000000               0.00        1.000000   \n",
       "1068702             0.000000               0.00        1.000000   \n",
       "1068703             0.000000               0.00        1.000000   \n",
       "1068704             0.000000               0.00        1.000000   \n",
       "1068705             0.000000               0.00        1.000000   \n",
       "1068706             0.000000               0.00        1.000000   \n",
       "1068707             0.000000               0.00        1.000000   \n",
       "1068708             0.000000               0.00        1.000000   \n",
       "1068709             0.000000               0.00        0.875000   \n",
       "1068710             0.000000               0.00        1.000000   \n",
       "1068711             0.000000               0.00        1.000000   \n",
       "1068712             0.000000               0.00        1.000000   \n",
       "1068713             0.000000               0.00        1.000000   \n",
       "1068714             0.000000               0.00        1.000000   \n",
       "1068715             0.000000               0.00        1.000000   \n",
       "1068716             0.250000               0.20        0.800000   \n",
       "1068717             0.000000               0.00        1.000000   \n",
       "1068718             0.000000               0.00        1.000000   \n",
       "1068719             0.000000               0.00        1.000000   \n",
       "1068720             0.000000               0.00        1.000000   \n",
       "1068721             0.000000               0.00        1.000000   \n",
       "1068722             0.000000               0.00        1.000000   \n",
       "1068723             0.000000               0.00        1.000000   \n",
       "1068724             0.000000               0.00        1.000000   \n",
       "1068725             0.000000               0.00        1.000000   \n",
       "\n",
       "         trips_lifetime                              useruuid  \\\n",
       "0                   2.0  df140d8a-7733-4351-a41c-e01850b2bbaf   \n",
       "1                  31.0  174cff21-848b-4973-99ab-b3850e2308ae   \n",
       "2                 199.0  971d40d2-a965-49ac-ba37-87564bff2733   \n",
       "3                 228.0  dcb048e0-7388-4c5e-8afa-2d8c42a4a455   \n",
       "4                  75.0  b92beda1-ec65-4587-adee-01f486cd0b5a   \n",
       "5                  52.0  563332bf-e639-446e-9017-000933541ea4   \n",
       "6                   8.0  3774ca20-1002-42cd-b958-f9f492df533c   \n",
       "7                 144.0  884ae0a4-0689-4569-a4d3-1db40fdf51b6   \n",
       "8                  52.0  a3276f9f-5544-4e10-9dfd-b73796284caf   \n",
       "9                  48.0  c99d1b97-a85a-4d16-b6c3-d250a1d68f55   \n",
       "10                 33.0  85586bd0-2c5c-44b6-83f2-87450d59a47b   \n",
       "11                  8.0  7d3afcd0-bcd8-4e7c-8c39-f0b1f8e02f16   \n",
       "12                  3.0  68edb4b0-df6a-4a03-8195-5ef9280fc141   \n",
       "13                 54.0  113ee0dd-e992-47a1-ac64-c72fc796389e   \n",
       "14                134.0  354272c5-2427-4af3-b049-19e6ba642b44   \n",
       "15                269.0  4684a513-71b6-4894-b631-8f812e7fc7c5   \n",
       "16                 21.0  c6faea83-c88a-4411-ac7d-95a125dc65dc   \n",
       "17                 94.0  53aa1911-a29d-4218-ae90-7d80f6165af5   \n",
       "18                139.0  e0011c10-0846-4c43-a704-80e69bf48d6f   \n",
       "19                 66.0  1d1494f6-b34a-4783-b464-faba8113fa48   \n",
       "20                 91.0  01d63b42-0f29-4a80-b639-cb8193e5ee1d   \n",
       "21                  8.0  cb76ba0c-6e8e-42ec-8c8a-d205e038cade   \n",
       "22                  9.0  d8461714-d01f-4faf-9123-0c74539639fc   \n",
       "23                 88.0  e6adb12f-4ee9-4971-a303-a1464a732be9   \n",
       "24                 96.0  ec3f25b8-4bf9-4e1a-9913-23295fbafb21   \n",
       "25                483.0  9aa3873c-cc63-498a-bc57-15ab67a2d4ce   \n",
       "26                 33.0  123d411b-9357-41b4-a473-9d7081b3b7f0   \n",
       "27                225.0  04c2321b-ddc7-4932-887d-ee0aa8e99458   \n",
       "28                  NaN  62b16b8d-9642-43d2-b05e-994e5a7c826d   \n",
       "29                 11.0  c1962615-0448-4d21-8e7e-5a0dbf9fe17c   \n",
       "...                 ...                                   ...   \n",
       "1068696            93.0  221aae5e-c41a-4079-8852-1889c3ba7ce3   \n",
       "1068697             5.0  a7bcbd4a-23d4-494a-821d-bc8272572574   \n",
       "1068698            70.0  b8aab666-4b2b-492b-ae3d-bb9a42363424   \n",
       "1068699             NaN  5a7b3caf-a8aa-40de-a327-e25803761d2c   \n",
       "1068700             1.0  94936bd2-c03d-44c2-b873-13a4148ceea8   \n",
       "1068701             7.0  0517308d-b85a-4d7d-8c4a-9408d8d30c44   \n",
       "1068702            19.0  53dcb85b-1c2d-4bf9-9fec-fd22f82afa4f   \n",
       "1068703            37.0  5c0621c0-b51f-4a3a-b09a-20d6159bc6a5   \n",
       "1068704           119.0  4391eead-bae6-45c8-9307-137742f5e101   \n",
       "1068705            17.0  20202959-8005-469c-8c72-adf24bf87356   \n",
       "1068706           218.0  fbebc154-7165-4b15-8376-d61766d46828   \n",
       "1068707            14.0  023b1f83-909e-4520-b7ff-f242ebf57c65   \n",
       "1068708             3.0  478ddd49-750b-4ab2-b778-b7dffb0000be   \n",
       "1068709            80.0  c9124fc2-0348-463b-a20d-b394a6ab11f7   \n",
       "1068710             6.0  8fa3a74d-d9aa-447c-960a-072fe44d32bb   \n",
       "1068711            71.0  4165f41d-fa37-4b93-aedf-dbbf564cde7c   \n",
       "1068712            32.0  b4e75f35-2762-4b2b-a584-2f313672562c   \n",
       "1068713            39.0  64496eee-2eb5-4065-a682-94a28ddedc5e   \n",
       "1068714            10.0  834d0145-08ae-4cf8-bf56-996010516632   \n",
       "1068715            34.0  0dbb7cb8-312b-4f20-bfb8-11ef36d055f4   \n",
       "1068716            30.0  dec851ab-d314-4ac2-a9ad-e89be964d851   \n",
       "1068717            93.0  68440cd4-f24a-47c8-ba52-bc362099bc2f   \n",
       "1068718            61.0  ee459d97-31d5-4104-9c8c-be6fdc1ba564   \n",
       "1068719             6.0  d79bc1b5-81e5-4fbe-938c-baef8b2e8006   \n",
       "1068720            27.0  28c2924a-48a0-4297-80a3-cc25e72cdced   \n",
       "1068721            18.0  590c538c-4ad0-4df4-8831-5fa3fa20d7f2   \n",
       "1068722             2.0  fe13ffcb-9661-4226-b893-debdb11bc67e   \n",
       "1068723             1.0  3c4b299a-751d-4894-b7d2-d17f23f2563c   \n",
       "1068724             5.0  16c1dbaa-4d22-42ea-b548-d1ababe0cae6   \n",
       "1068725             7.0  c0d0762b-ce1d-49e9-b1a7-c1045f9740e0   \n",
       "\n",
       "                                         uuid  \n",
       "0        df140d8a-7733-4351-a41c-e01850b2bbaf  \n",
       "1        174cff21-848b-4973-99ab-b3850e2308ae  \n",
       "2        971d40d2-a965-49ac-ba37-87564bff2733  \n",
       "3        dcb048e0-7388-4c5e-8afa-2d8c42a4a455  \n",
       "4        b92beda1-ec65-4587-adee-01f486cd0b5a  \n",
       "5        563332bf-e639-446e-9017-000933541ea4  \n",
       "6        3774ca20-1002-42cd-b958-f9f492df533c  \n",
       "7        884ae0a4-0689-4569-a4d3-1db40fdf51b6  \n",
       "8        a3276f9f-5544-4e10-9dfd-b73796284caf  \n",
       "9        c99d1b97-a85a-4d16-b6c3-d250a1d68f55  \n",
       "10       85586bd0-2c5c-44b6-83f2-87450d59a47b  \n",
       "11       7d3afcd0-bcd8-4e7c-8c39-f0b1f8e02f16  \n",
       "12       68edb4b0-df6a-4a03-8195-5ef9280fc141  \n",
       "13       113ee0dd-e992-47a1-ac64-c72fc796389e  \n",
       "14       354272c5-2427-4af3-b049-19e6ba642b44  \n",
       "15       4684a513-71b6-4894-b631-8f812e7fc7c5  \n",
       "16       c6faea83-c88a-4411-ac7d-95a125dc65dc  \n",
       "17       53aa1911-a29d-4218-ae90-7d80f6165af5  \n",
       "18       e0011c10-0846-4c43-a704-80e69bf48d6f  \n",
       "19       1d1494f6-b34a-4783-b464-faba8113fa48  \n",
       "20       01d63b42-0f29-4a80-b639-cb8193e5ee1d  \n",
       "21       cb76ba0c-6e8e-42ec-8c8a-d205e038cade  \n",
       "22       d8461714-d01f-4faf-9123-0c74539639fc  \n",
       "23       e6adb12f-4ee9-4971-a303-a1464a732be9  \n",
       "24       ec3f25b8-4bf9-4e1a-9913-23295fbafb21  \n",
       "25       9aa3873c-cc63-498a-bc57-15ab67a2d4ce  \n",
       "26       123d411b-9357-41b4-a473-9d7081b3b7f0  \n",
       "27       04c2321b-ddc7-4932-887d-ee0aa8e99458  \n",
       "28                                        NaN  \n",
       "29       c1962615-0448-4d21-8e7e-5a0dbf9fe17c  \n",
       "...                                       ...  \n",
       "1068696  221aae5e-c41a-4079-8852-1889c3ba7ce3  \n",
       "1068697  a7bcbd4a-23d4-494a-821d-bc8272572574  \n",
       "1068698  b8aab666-4b2b-492b-ae3d-bb9a42363424  \n",
       "1068699                                   NaN  \n",
       "1068700  94936bd2-c03d-44c2-b873-13a4148ceea8  \n",
       "1068701  0517308d-b85a-4d7d-8c4a-9408d8d30c44  \n",
       "1068702  53dcb85b-1c2d-4bf9-9fec-fd22f82afa4f  \n",
       "1068703  5c0621c0-b51f-4a3a-b09a-20d6159bc6a5  \n",
       "1068704  4391eead-bae6-45c8-9307-137742f5e101  \n",
       "1068705  20202959-8005-469c-8c72-adf24bf87356  \n",
       "1068706  fbebc154-7165-4b15-8376-d61766d46828  \n",
       "1068707  023b1f83-909e-4520-b7ff-f242ebf57c65  \n",
       "1068708  478ddd49-750b-4ab2-b778-b7dffb0000be  \n",
       "1068709  c9124fc2-0348-463b-a20d-b394a6ab11f7  \n",
       "1068710  8fa3a74d-d9aa-447c-960a-072fe44d32bb  \n",
       "1068711  4165f41d-fa37-4b93-aedf-dbbf564cde7c  \n",
       "1068712  b4e75f35-2762-4b2b-a584-2f313672562c  \n",
       "1068713  64496eee-2eb5-4065-a682-94a28ddedc5e  \n",
       "1068714  834d0145-08ae-4cf8-bf56-996010516632  \n",
       "1068715  0dbb7cb8-312b-4f20-bfb8-11ef36d055f4  \n",
       "1068716  dec851ab-d314-4ac2-a9ad-e89be964d851  \n",
       "1068717  68440cd4-f24a-47c8-ba52-bc362099bc2f  \n",
       "1068718  ee459d97-31d5-4104-9c8c-be6fdc1ba564  \n",
       "1068719  d79bc1b5-81e5-4fbe-938c-baef8b2e8006  \n",
       "1068720  28c2924a-48a0-4297-80a3-cc25e72cdced  \n",
       "1068721  590c538c-4ad0-4df4-8831-5fa3fa20d7f2  \n",
       "1068722  fe13ffcb-9661-4226-b893-debdb11bc67e  \n",
       "1068723  3c4b299a-751d-4894-b7d2-d17f23f2563c  \n",
       "1068724  16c1dbaa-4d22-42ea-b548-d1ababe0cae6  \n",
       "1068725  c0d0762b-ce1d-49e9-b1a7-c1045f9740e0  \n",
       "\n",
       "[1068726 rows x 48 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predFrame2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rpu_control: 0.16929032468981642\n",
      "nipu_control: -0.05992151597869827\n",
      "rpu_ft: 0.2640930222848291\n",
      "nipu_ft: -0.18780860567102814\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.10\n",
      "treated_target_rpu: 0.30\n",
      "treated_target_nipu: -0.19\n",
      "nontreated_target_rpu: 0.19\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.26\n",
      "treated_nontarget_nipu: -0.19\n",
      "nontreated_nontarget_rpu: 0.17\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 9.999719292992618% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.234514635172661\n",
      "--> in non-targeted users: \n",
      "cpit = 1.3633334595501208\n",
      "rpu_control: 0.17\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.26\n",
      "nipu_ft: -0.19\n",
      "rpu_cohort: 0.18\n",
      "nipu_cohort: -0.07\n",
      "lift targeted cohort vs control: 0.06\n",
      "lift random vs control: 0.56\n",
      "cpit cohort vs control: 1.24\n",
      "lift targeted-treated vs control: 0.75\n",
      "cpit cohort: 1.235748\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.20\n",
      "treated_target_rpu: 0.28\n",
      "treated_target_nipu: -0.19\n",
      "nontreated_target_rpu: 0.17\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.26\n",
      "treated_nontarget_nipu: -0.19\n",
      "nontreated_nontarget_rpu: 0.17\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 19.999438585985235% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.185474642559321\n",
      "--> in non-targeted users: \n",
      "cpit = 1.3973775883640198\n",
      "rpu_control: 0.17\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.26\n",
      "nipu_ft: -0.19\n",
      "rpu_cohort: 0.19\n",
      "nipu_cohort: -0.09\n",
      "lift targeted cohort vs control: 0.13\n",
      "lift random vs control: 0.56\n",
      "cpit cohort vs control: 1.19\n",
      "lift targeted-treated vs control: 0.64\n",
      "cpit cohort: 1.185559\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.30\n",
      "treated_target_rpu: 0.27\n",
      "treated_target_nipu: -0.20\n",
      "nontreated_target_rpu: 0.17\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.26\n",
      "treated_nontarget_nipu: -0.18\n",
      "nontreated_nontarget_rpu: 0.17\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 29.99915787897785% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.3473973148670417\n",
      "--> in non-targeted users: \n",
      "cpit = 1.3496905747204189\n",
      "rpu_control: 0.17\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.26\n",
      "nipu_ft: -0.19\n",
      "rpu_cohort: 0.20\n",
      "nipu_cohort: -0.10\n",
      "lift targeted cohort vs control: 0.18\n",
      "lift random vs control: 0.56\n",
      "cpit cohort vs control: 1.35\n",
      "lift targeted-treated vs control: 0.59\n",
      "cpit cohort: 1.347431\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.40\n",
      "treated_target_rpu: 0.26\n",
      "treated_target_nipu: -0.19\n",
      "nontreated_target_rpu: 0.17\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.27\n",
      "treated_nontarget_nipu: -0.19\n",
      "nontreated_nontarget_rpu: 0.17\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 39.99887717197047% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.4618327071190624\n",
      "--> in non-targeted users: \n",
      "cpit = 1.2794092073332268\n",
      "rpu_control: 0.17\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.26\n",
      "nipu_ft: -0.19\n",
      "rpu_cohort: 0.21\n",
      "nipu_cohort: -0.11\n",
      "lift targeted cohort vs control: 0.21\n",
      "lift random vs control: 0.56\n",
      "cpit cohort vs control: 1.46\n",
      "lift targeted-treated vs control: 0.54\n",
      "cpit cohort: 1.461755\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.50\n",
      "treated_target_rpu: 0.27\n",
      "treated_target_nipu: -0.19\n",
      "nontreated_target_rpu: 0.17\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.26\n",
      "treated_nontarget_nipu: -0.19\n",
      "nontreated_nontarget_rpu: 0.17\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 49.998596464963086% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.3146330796317076\n",
      "--> in non-targeted users: \n",
      "cpit = 1.3875978706379017\n",
      "rpu_control: 0.17\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.26\n",
      "nipu_ft: -0.19\n",
      "rpu_cohort: 0.22\n",
      "nipu_cohort: -0.13\n",
      "lift targeted cohort vs control: 0.30\n",
      "lift random vs control: 0.56\n",
      "cpit cohort vs control: 1.31\n",
      "lift targeted-treated vs control: 0.58\n",
      "cpit cohort: 1.314723\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.60\n",
      "treated_target_rpu: 0.27\n",
      "treated_target_nipu: -0.19\n",
      "nontreated_target_rpu: 0.17\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.26\n",
      "treated_nontarget_nipu: -0.18\n",
      "nontreated_nontarget_rpu: 0.17\n",
      "nontreated_nontarget_nipu: -0.07\n",
      "--- with 59.9983157579557% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.3388480041744513\n",
      "--> in non-targeted users: \n",
      "cpit = 1.3668436014126546\n",
      "rpu_control: 0.17\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.26\n",
      "nipu_ft: -0.19\n",
      "rpu_cohort: 0.23\n",
      "nipu_cohort: -0.14\n",
      "lift targeted cohort vs control: 0.36\n",
      "lift random vs control: 0.56\n",
      "cpit cohort vs control: 1.34\n",
      "lift targeted-treated vs control: 0.58\n",
      "cpit cohort: 1.338844\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.70\n",
      "treated_target_rpu: 0.27\n",
      "treated_target_nipu: -0.19\n",
      "nontreated_target_rpu: 0.17\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.26\n",
      "treated_nontarget_nipu: -0.18\n",
      "nontreated_nontarget_rpu: 0.18\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 69.99803505094833% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.3003158989852337\n",
      "--> in non-targeted users: \n",
      "cpit = 1.4892321550427643\n",
      "rpu_control: 0.17\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.26\n",
      "nipu_ft: -0.19\n",
      "rpu_cohort: 0.24\n",
      "nipu_cohort: -0.15\n",
      "lift targeted cohort vs control: 0.42\n",
      "lift random vs control: 0.56\n",
      "cpit cohort vs control: 1.30\n",
      "lift targeted-treated vs control: 0.58\n",
      "cpit cohort: 1.300460\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.80\n",
      "treated_target_rpu: 0.27\n",
      "treated_target_nipu: -0.19\n",
      "nontreated_target_rpu: 0.17\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.25\n",
      "treated_nontarget_nipu: -0.17\n",
      "nontreated_nontarget_rpu: 0.17\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 79.99775434394094% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.315689988018832\n",
      "--> in non-targeted users: \n",
      "cpit = 1.5181884737059448\n",
      "rpu_control: 0.17\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.26\n",
      "nipu_ft: -0.19\n",
      "rpu_cohort: 0.25\n",
      "nipu_cohort: -0.16\n",
      "lift targeted cohort vs control: 0.47\n",
      "lift random vs control: 0.56\n",
      "cpit cohort vs control: 1.32\n",
      "lift targeted-treated vs control: 0.58\n",
      "cpit cohort: 1.315964\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.90\n",
      "treated_target_rpu: 0.26\n",
      "treated_target_nipu: -0.19\n",
      "nontreated_target_rpu: 0.17\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.26\n",
      "treated_nontarget_nipu: -0.17\n",
      "nontreated_nontarget_rpu: 0.18\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 89.99747363693356% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.3488218971972556\n",
      "--> in non-targeted users: \n",
      "cpit = 1.3467185845655103\n",
      "rpu_control: 0.17\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.26\n",
      "nipu_ft: -0.19\n",
      "rpu_cohort: 0.26\n",
      "nipu_cohort: -0.18\n",
      "lift targeted cohort vs control: 0.51\n",
      "lift random vs control: 0.56\n",
      "cpit cohort vs control: 1.35\n",
      "lift targeted-treated vs control: 0.56\n",
      "cpit cohort: 1.349066\n",
      "rpu_cohort\n",
      "0.2558641845802791\n",
      "treated_target_rpu\n",
      "0.2640986780275754\n",
      "---------------------------->>>>>>\n",
      "perc - target: 1.00\n",
      "treated_target_rpu: 0.26\n",
      "treated_target_nipu: -0.19\n",
      "nontreated_target_rpu: 0.17\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.00\n",
      "treated_nontarget_nipu: 0.00\n",
      "nontreated_nontarget_rpu: 1.03\n",
      "nontreated_nontarget_nipu: -1.29\n",
      "--- with 99.99719292992617% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.3489711159470092\n",
      "--> in non-targeted users: \n",
      "cpit = 1.2482722159734636\n",
      "rpu_control: 0.17\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.26\n",
      "nipu_ft: -0.19\n",
      "rpu_cohort: 0.26\n",
      "nipu_cohort: -0.19\n",
      "lift targeted cohort vs control: 0.56\n",
      "lift random vs control: 0.56\n",
      "cpit cohort vs control: 1.35\n",
      "lift targeted-treated vs control: 0.56\n",
      "cpit cohort: 1.348943\n",
      "rpu_control: 0.16929032468981642\n",
      "nipu_control: -0.05992151597869827\n",
      "rpu_ft: 0.2640930222848291\n",
      "nipu_ft: -0.18780860567102814\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.10\n",
      "treated_target_rpu: 0.49\n",
      "treated_target_nipu: -0.31\n",
      "nontreated_target_rpu: 0.35\n",
      "nontreated_target_nipu: -0.09\n",
      "treated_nontarget_rpu: 0.24\n",
      "treated_nontarget_nipu: -0.17\n",
      "nontreated_nontarget_rpu: 0.15\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 9.999719292992618% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.6459587858713343\n",
      "--> in non-targeted users: \n",
      "cpit = 1.3064818302812171\n",
      "rpu_control: 0.17\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.26\n",
      "nipu_ft: -0.19\n",
      "rpu_cohort: 0.18\n",
      "nipu_cohort: -0.08\n",
      "lift targeted cohort vs control: 0.08\n",
      "lift random vs control: 0.56\n",
      "cpit cohort vs control: 1.61\n",
      "lift targeted-treated vs control: 1.87\n",
      "cpit cohort: 1.608635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------->>>>>>\n",
      "perc - target: 0.20\n",
      "treated_target_rpu: 0.41\n",
      "treated_target_nipu: -0.29\n",
      "nontreated_target_rpu: 0.28\n",
      "nontreated_target_nipu: -0.09\n",
      "treated_nontarget_rpu: 0.23\n",
      "treated_nontarget_nipu: -0.16\n",
      "nontreated_nontarget_rpu: 0.14\n",
      "nontreated_nontarget_nipu: -0.05\n",
      "--- with 19.999438585985235% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.5583956889291801\n",
      "--> in non-targeted users: \n",
      "cpit = 1.2756823516381333\n",
      "rpu_control: 0.17\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.26\n",
      "nipu_ft: -0.19\n",
      "rpu_cohort: 0.20\n",
      "nipu_cohort: -0.10\n",
      "lift targeted cohort vs control: 0.16\n",
      "lift random vs control: 0.56\n",
      "cpit cohort vs control: 1.54\n",
      "lift targeted-treated vs control: 1.43\n",
      "cpit cohort: 1.542911\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.30\n",
      "treated_target_rpu: 0.38\n",
      "treated_target_nipu: -0.27\n",
      "nontreated_target_rpu: 0.25\n",
      "nontreated_target_nipu: -0.08\n",
      "treated_nontarget_rpu: 0.21\n",
      "treated_nontarget_nipu: -0.15\n",
      "nontreated_nontarget_rpu: 0.14\n",
      "nontreated_nontarget_nipu: -0.05\n",
      "--- with 29.99915787897785% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.3316745266401087\n",
      "--> in non-targeted users: \n",
      "cpit = 1.3716192325573116\n",
      "rpu_control: 0.17\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.26\n",
      "nipu_ft: -0.19\n",
      "rpu_cohort: 0.21\n",
      "nipu_cohort: -0.11\n",
      "lift targeted cohort vs control: 0.24\n",
      "lift random vs control: 0.56\n",
      "cpit cohort vs control: 1.32\n",
      "lift targeted-treated vs control: 1.25\n",
      "cpit cohort: 1.323862\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.40\n",
      "treated_target_rpu: 0.35\n",
      "treated_target_nipu: -0.25\n",
      "nontreated_target_rpu: 0.22\n",
      "nontreated_target_nipu: -0.08\n",
      "treated_nontarget_rpu: 0.21\n",
      "treated_nontarget_nipu: -0.15\n",
      "nontreated_nontarget_rpu: 0.13\n",
      "nontreated_nontarget_nipu: -0.05\n",
      "--- with 39.99887717197047% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.3440986257051626\n",
      "--> in non-targeted users: \n",
      "cpit = 1.3584199277014641\n",
      "rpu_control: 0.17\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.26\n",
      "nipu_ft: -0.19\n",
      "rpu_cohort: 0.22\n",
      "nipu_cohort: -0.13\n",
      "lift targeted cohort vs control: 0.30\n",
      "lift random vs control: 0.56\n",
      "cpit cohort vs control: 1.34\n",
      "lift targeted-treated vs control: 1.06\n",
      "cpit cohort: 1.341843\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.50\n",
      "treated_target_rpu: 0.33\n",
      "treated_target_nipu: -0.24\n",
      "nontreated_target_rpu: 0.21\n",
      "nontreated_target_nipu: -0.08\n",
      "treated_nontarget_rpu: 0.20\n",
      "treated_nontarget_nipu: -0.14\n",
      "nontreated_nontarget_rpu: 0.13\n",
      "nontreated_nontarget_nipu: -0.04\n",
      "--- with 49.998596464963086% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.4047100267060362\n",
      "--> in non-targeted users: \n",
      "cpit = 1.2725529327153697\n",
      "rpu_control: 0.17\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.26\n",
      "nipu_ft: -0.19\n",
      "rpu_cohort: 0.23\n",
      "nipu_cohort: -0.14\n",
      "lift targeted cohort vs control: 0.34\n",
      "lift random vs control: 0.56\n",
      "cpit cohort vs control: 1.40\n",
      "lift targeted-treated vs control: 0.92\n",
      "cpit cohort: 1.401466\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.60\n",
      "treated_target_rpu: 0.31\n",
      "treated_target_nipu: -0.23\n",
      "nontreated_target_rpu: 0.20\n",
      "nontreated_target_nipu: -0.07\n",
      "treated_nontarget_rpu: 0.20\n",
      "treated_nontarget_nipu: -0.13\n",
      "nontreated_nontarget_rpu: 0.13\n",
      "nontreated_nontarget_nipu: -0.04\n",
      "--- with 59.9983157579557% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.3835600417796905\n",
      "--> in non-targeted users: \n",
      "cpit = 1.2660960005280848\n",
      "rpu_control: 0.17\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.26\n",
      "nipu_ft: -0.19\n",
      "rpu_cohort: 0.24\n",
      "nipu_cohort: -0.15\n",
      "lift targeted cohort vs control: 0.40\n",
      "lift random vs control: 0.56\n",
      "cpit cohort vs control: 1.38\n",
      "lift targeted-treated vs control: 0.83\n",
      "cpit cohort: 1.383397\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.70\n",
      "treated_target_rpu: 0.30\n",
      "treated_target_nipu: -0.22\n",
      "nontreated_target_rpu: 0.19\n",
      "nontreated_target_nipu: -0.07\n",
      "treated_nontarget_rpu: 0.19\n",
      "treated_nontarget_nipu: -0.12\n",
      "nontreated_nontarget_rpu: 0.12\n",
      "nontreated_nontarget_nipu: -0.04\n",
      "--- with 69.99803505094833% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.3750615237131922\n",
      "--> in non-targeted users: \n",
      "cpit = 1.2501172272195313\n",
      "rpu_control: 0.17\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.26\n",
      "nipu_ft: -0.19\n",
      "rpu_cohort: 0.24\n",
      "nipu_cohort: -0.16\n",
      "lift targeted cohort vs control: 0.44\n",
      "lift random vs control: 0.56\n",
      "cpit cohort vs control: 1.37\n",
      "lift targeted-treated vs control: 0.76\n",
      "cpit cohort: 1.374768\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.80\n",
      "treated_target_rpu: 0.29\n",
      "treated_target_nipu: -0.21\n",
      "nontreated_target_rpu: 0.18\n",
      "nontreated_target_nipu: -0.07\n",
      "treated_nontarget_rpu: 0.17\n",
      "treated_nontarget_nipu: -0.11\n",
      "nontreated_nontarget_rpu: 0.12\n",
      "nontreated_nontarget_nipu: -0.03\n",
      "--- with 79.99775434394094% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.3399766278248029\n",
      "--> in non-targeted users: \n",
      "cpit = 1.4182181943406154\n",
      "rpu_control: 0.17\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.26\n",
      "nipu_ft: -0.19\n",
      "rpu_cohort: 0.25\n",
      "nipu_cohort: -0.17\n",
      "lift targeted cohort vs control: 0.49\n",
      "lift random vs control: 0.56\n",
      "cpit cohort vs control: 1.34\n",
      "lift targeted-treated vs control: 0.70\n",
      "cpit cohort: 1.339918\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.90\n",
      "treated_target_rpu: 0.27\n",
      "treated_target_nipu: -0.20\n",
      "nontreated_target_rpu: 0.18\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.17\n",
      "treated_nontarget_nipu: -0.10\n",
      "nontreated_nontarget_rpu: 0.09\n",
      "nontreated_nontarget_nipu: -0.03\n",
      "--- with 89.99747363693356% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.395510376072695\n",
      "--> in non-targeted users: \n",
      "cpit = 0.8543961868413784\n",
      "rpu_control: 0.17\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.26\n",
      "nipu_ft: -0.19\n",
      "rpu_cohort: 0.26\n",
      "nipu_cohort: -0.18\n",
      "lift targeted cohort vs control: 0.51\n",
      "lift random vs control: 0.56\n",
      "cpit cohort vs control: 1.40\n",
      "lift targeted-treated vs control: 0.62\n",
      "cpit cohort: 1.395568\n",
      "rpu_cohort\n",
      "0.25593222260630516\n",
      "treated_target_rpu\n",
      "0.26410244865732124\n",
      "---------------------------->>>>>>\n",
      "perc - target: 1.00\n",
      "treated_target_rpu: 0.26\n",
      "treated_target_nipu: -0.19\n",
      "nontreated_target_rpu: 0.17\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.00\n",
      "treated_nontarget_nipu: -1.26\n",
      "nontreated_nontarget_rpu: 0.00\n",
      "nontreated_nontarget_nipu: 0.00\n",
      "--- with 99.99719292992617% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.3484671912105848\n",
      "--> in non-targeted users: \n",
      "cpit = inf\n",
      "rpu_control: 0.17\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.26\n",
      "nipu_ft: -0.19\n",
      "rpu_cohort: 0.26\n",
      "nipu_cohort: -0.19\n",
      "lift targeted cohort vs control: 0.56\n",
      "lift random vs control: 0.56\n",
      "cpit cohort vs control: 1.35\n",
      "lift targeted-treated vs control: 0.56\n",
      "cpit cohort: 1.348443\n",
      "rpu_control: 0.16929032468981642\n",
      "nipu_control: -0.05992151597869827\n",
      "rpu_ft: 0.2640930222848291\n",
      "nipu_ft: -0.18780860567102814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../experimentation.py:154: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  cpit_nontargeted = -1.0 * (treated_untarget_nipu - untreated_untarget_nipu) / (treated_untarget_rpu - untreated_untarget_rpu)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------->>>>>>\n",
      "perc - target: 0.10\n",
      "treated_target_rpu: 0.30\n",
      "treated_target_nipu: -0.11\n",
      "nontreated_target_rpu: 0.21\n",
      "nontreated_target_nipu: -0.05\n",
      "treated_nontarget_rpu: 0.26\n",
      "treated_nontarget_nipu: -0.20\n",
      "nontreated_nontarget_rpu: 0.16\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 9.999719292992618% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 0.6276786120221962\n",
      "--> in non-targeted users: \n",
      "cpit = 1.4287422979112898\n",
      "rpu_control: 0.17\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.26\n",
      "nipu_ft: -0.19\n",
      "rpu_cohort: 0.18\n",
      "nipu_cohort: -0.07\n",
      "lift targeted cohort vs control: 0.06\n",
      "lift random vs control: 0.56\n",
      "cpit cohort vs control: 0.63\n",
      "lift targeted-treated vs control: 0.79\n",
      "cpit cohort: 0.625545\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.20\n",
      "treated_target_rpu: 0.28\n",
      "treated_target_nipu: -0.11\n",
      "nontreated_target_rpu: 0.18\n",
      "nontreated_target_nipu: -0.05\n",
      "treated_nontarget_rpu: 0.26\n",
      "treated_nontarget_nipu: -0.21\n",
      "nontreated_nontarget_rpu: 0.17\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 19.999438585985235% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 0.6550819080124244\n",
      "--> in non-targeted users: \n",
      "cpit = 1.5238552273997366\n",
      "rpu_control: 0.17\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.26\n",
      "nipu_ft: -0.19\n",
      "rpu_cohort: 0.19\n",
      "nipu_cohort: -0.07\n",
      "lift targeted cohort vs control: 0.11\n",
      "lift random vs control: 0.56\n",
      "cpit cohort vs control: 0.65\n",
      "lift targeted-treated vs control: 0.65\n",
      "cpit cohort: 0.654477\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.30\n",
      "treated_target_rpu: 0.26\n",
      "treated_target_nipu: -0.13\n",
      "nontreated_target_rpu: 0.19\n",
      "nontreated_target_nipu: -0.05\n",
      "treated_nontarget_rpu: 0.26\n",
      "treated_nontarget_nipu: -0.21\n",
      "nontreated_nontarget_rpu: 0.16\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 29.99915787897785% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.0045222289678675\n",
      "--> in non-targeted users: \n",
      "cpit = 1.4611337436616845\n",
      "rpu_control: 0.17\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.26\n",
      "nipu_ft: -0.19\n",
      "rpu_cohort: 0.19\n",
      "nipu_cohort: -0.08\n",
      "lift targeted cohort vs control: 0.14\n",
      "lift random vs control: 0.56\n",
      "cpit cohort vs control: 1.00\n",
      "lift targeted-treated vs control: 0.56\n",
      "cpit cohort: 1.003780\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.40\n",
      "treated_target_rpu: 0.25\n",
      "treated_target_nipu: -0.14\n",
      "nontreated_target_rpu: 0.18\n",
      "nontreated_target_nipu: -0.05\n",
      "treated_nontarget_rpu: 0.27\n",
      "treated_nontarget_nipu: -0.22\n",
      "nontreated_nontarget_rpu: 0.16\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 39.99887717197047% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.1166995021798871\n",
      "--> in non-targeted users: \n",
      "cpit = 1.458895183631764\n",
      "rpu_control: 0.17\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.26\n",
      "nipu_ft: -0.19\n",
      "rpu_cohort: 0.20\n",
      "nipu_cohort: -0.09\n",
      "lift targeted cohort vs control: 0.18\n",
      "lift random vs control: 0.56\n",
      "cpit cohort vs control: 1.12\n",
      "lift targeted-treated vs control: 0.49\n",
      "cpit cohort: 1.116524\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.50\n",
      "treated_target_rpu: 0.25\n",
      "treated_target_nipu: -0.14\n",
      "nontreated_target_rpu: 0.17\n",
      "nontreated_target_nipu: -0.05\n",
      "treated_nontarget_rpu: 0.28\n",
      "treated_nontarget_nipu: -0.23\n",
      "nontreated_nontarget_rpu: 0.17\n",
      "nontreated_nontarget_nipu: -0.07\n",
      "--- with 49.998596464963086% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.1231580046694196\n",
      "--> in non-targeted users: \n",
      "cpit = 1.5066617706335637\n",
      "rpu_control: 0.17\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.26\n",
      "nipu_ft: -0.19\n",
      "rpu_cohort: 0.21\n",
      "nipu_cohort: -0.10\n",
      "lift targeted cohort vs control: 0.23\n",
      "lift random vs control: 0.56\n",
      "cpit cohort vs control: 1.12\n",
      "lift targeted-treated vs control: 0.47\n",
      "cpit cohort: 1.123349\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.60\n",
      "treated_target_rpu: 0.25\n",
      "treated_target_nipu: -0.15\n",
      "nontreated_target_rpu: 0.17\n",
      "nontreated_target_nipu: -0.05\n",
      "treated_nontarget_rpu: 0.28\n",
      "treated_nontarget_nipu: -0.25\n",
      "nontreated_nontarget_rpu: 0.17\n",
      "nontreated_nontarget_nipu: -0.07\n",
      "--- with 59.9983157579557% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.0868183449197466\n",
      "--> in non-targeted users: \n",
      "cpit = 1.645147847830743\n",
      "rpu_control: 0.17\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.26\n",
      "nipu_ft: -0.19\n",
      "rpu_cohort: 0.22\n",
      "nipu_cohort: -0.11\n",
      "lift targeted cohort vs control: 0.30\n",
      "lift random vs control: 0.56\n",
      "cpit cohort vs control: 1.09\n",
      "lift targeted-treated vs control: 0.49\n",
      "cpit cohort: 1.086983\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.70\n",
      "treated_target_rpu: 0.25\n",
      "treated_target_nipu: -0.15\n",
      "nontreated_target_rpu: 0.17\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.29\n",
      "treated_nontarget_nipu: -0.26\n",
      "nontreated_nontarget_rpu: 0.18\n",
      "nontreated_nontarget_nipu: -0.07\n",
      "--- with 69.99803505094833% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.1193453342615944\n",
      "--> in non-targeted users: \n",
      "cpit = 1.780052175148034\n",
      "rpu_control: 0.17\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.26\n",
      "nipu_ft: -0.19\n",
      "rpu_cohort: 0.23\n",
      "nipu_cohort: -0.13\n",
      "lift targeted cohort vs control: 0.37\n",
      "lift random vs control: 0.56\n",
      "cpit cohort vs control: 1.12\n",
      "lift targeted-treated vs control: 0.50\n",
      "cpit cohort: 1.119345\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.80\n",
      "treated_target_rpu: 0.25\n",
      "treated_target_nipu: -0.16\n",
      "nontreated_target_rpu: 0.17\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.31\n",
      "treated_nontarget_nipu: -0.28\n",
      "nontreated_nontarget_rpu: 0.16\n",
      "nontreated_nontarget_nipu: -0.07\n",
      "--- with 79.99775434394094% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.3013698507960856\n",
      "--> in non-targeted users: \n",
      "cpit = 1.4578792655299715\n",
      "rpu_control: 0.17\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.26\n",
      "nipu_ft: -0.19\n",
      "rpu_cohort: 0.23\n",
      "nipu_cohort: -0.14\n",
      "lift targeted cohort vs control: 0.39\n",
      "lift random vs control: 0.56\n",
      "cpit cohort vs control: 1.30\n",
      "lift targeted-treated vs control: 0.50\n",
      "cpit cohort: 1.300622\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.90\n",
      "treated_target_rpu: 0.26\n",
      "treated_target_nipu: -0.18\n",
      "nontreated_target_rpu: 0.17\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.33\n",
      "treated_nontarget_nipu: -0.30\n",
      "nontreated_nontarget_rpu: 0.15\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 89.99747363693356% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.3547740819108323\n",
      "--> in non-targeted users: \n",
      "cpit = 1.324911941545921\n",
      "rpu_control: 0.17\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.26\n",
      "nipu_ft: -0.19\n",
      "rpu_cohort: 0.25\n",
      "nipu_cohort: -0.16\n",
      "lift targeted cohort vs control: 0.45\n",
      "lift random vs control: 0.56\n",
      "cpit cohort vs control: 1.35\n",
      "lift targeted-treated vs control: 0.52\n",
      "cpit cohort: 1.354738\n",
      "rpu_cohort\n",
      "0.24583833920236303\n",
      "treated_target_rpu\n",
      "0.26410244865732124\n",
      "---------------------------->>>>>>\n",
      "perc - target: 1.00\n",
      "treated_target_rpu: 0.26\n",
      "treated_target_nipu: -0.19\n",
      "nontreated_target_rpu: 0.17\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.00\n",
      "treated_nontarget_nipu: -1.26\n",
      "nontreated_nontarget_rpu: 0.00\n",
      "nontreated_nontarget_nipu: 0.00\n",
      "--- with 99.99719292992617% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.3484671912105848\n",
      "--> in non-targeted users: \n",
      "cpit = inf\n",
      "rpu_control: 0.17\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.26\n",
      "nipu_ft: -0.19\n",
      "rpu_cohort: 0.26\n",
      "nipu_cohort: -0.19\n",
      "lift targeted cohort vs control: 0.56\n",
      "lift random vs control: 0.56\n",
      "cpit cohort vs control: 1.35\n",
      "lift targeted-treated vs control: 0.56\n",
      "cpit cohort: 1.348443\n",
      "rpu_control: 0.16929032468981642\n",
      "nipu_control: -0.05992151597869827\n",
      "rpu_ft: 0.2640930222848291\n",
      "nipu_ft: -0.18780860567102814\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.10\n",
      "treated_target_rpu: 0.32\n",
      "treated_target_nipu: -0.11\n",
      "nontreated_target_rpu: 0.21\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.26\n",
      "treated_nontarget_nipu: -0.20\n",
      "nontreated_nontarget_rpu: 0.16\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 9.999719292992618% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 0.5311067381354079\n",
      "--> in non-targeted users: \n",
      "cpit = 1.4494999109417426\n",
      "rpu_control: 0.17\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.26\n",
      "nipu_ft: -0.19\n",
      "rpu_cohort: 0.18\n",
      "nipu_cohort: -0.07\n",
      "lift targeted cohort vs control: 0.06\n",
      "lift random vs control: 0.56\n",
      "cpit cohort vs control: 0.53\n",
      "lift targeted-treated vs control: 0.87\n",
      "cpit cohort: 0.532622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------->>>>>>\n",
      "perc - target: 0.20\n",
      "treated_target_rpu: 0.29\n",
      "treated_target_nipu: -0.13\n",
      "nontreated_target_rpu: 0.18\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.26\n",
      "treated_nontarget_nipu: -0.20\n",
      "nontreated_nontarget_rpu: 0.17\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 19.999438585985235% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 0.6423237930820678\n",
      "--> in non-targeted users: \n",
      "cpit = 1.56428008037552\n",
      "rpu_control: 0.17\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.26\n",
      "nipu_ft: -0.19\n",
      "rpu_cohort: 0.19\n",
      "nipu_cohort: -0.07\n",
      "lift targeted cohort vs control: 0.13\n",
      "lift random vs control: 0.56\n",
      "cpit cohort vs control: 0.64\n",
      "lift targeted-treated vs control: 0.74\n",
      "cpit cohort: 0.642796\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.30\n",
      "treated_target_rpu: 0.27\n",
      "treated_target_nipu: -0.14\n",
      "nontreated_target_rpu: 0.18\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.26\n",
      "treated_nontarget_nipu: -0.21\n",
      "nontreated_nontarget_rpu: 0.16\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 29.99915787897785% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 0.8118491882396054\n",
      "--> in non-targeted users: \n",
      "cpit = 1.5768533390669914\n",
      "rpu_control: 0.17\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.26\n",
      "nipu_ft: -0.19\n",
      "rpu_cohort: 0.20\n",
      "nipu_cohort: -0.08\n",
      "lift targeted cohort vs control: 0.17\n",
      "lift random vs control: 0.56\n",
      "cpit cohort vs control: 0.81\n",
      "lift targeted-treated vs control: 0.62\n",
      "cpit cohort: 0.811957\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.40\n",
      "treated_target_rpu: 0.27\n",
      "treated_target_nipu: -0.15\n",
      "nontreated_target_rpu: 0.18\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.26\n",
      "treated_nontarget_nipu: -0.21\n",
      "nontreated_nontarget_rpu: 0.16\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 39.99887717197047% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 0.9711176410482325\n",
      "--> in non-targeted users: \n",
      "cpit = 1.5819935816320758\n",
      "rpu_control: 0.17\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.26\n",
      "nipu_ft: -0.19\n",
      "rpu_cohort: 0.21\n",
      "nipu_cohort: -0.10\n",
      "lift targeted cohort vs control: 0.21\n",
      "lift random vs control: 0.56\n",
      "cpit cohort vs control: 0.97\n",
      "lift targeted-treated vs control: 0.58\n",
      "cpit cohort: 0.971032\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.50\n",
      "treated_target_rpu: 0.26\n",
      "treated_target_nipu: -0.16\n",
      "nontreated_target_rpu: 0.18\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.27\n",
      "treated_nontarget_nipu: -0.22\n",
      "nontreated_nontarget_rpu: 0.16\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 49.998596464963086% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.2037729794168188\n",
      "--> in non-targeted users: \n",
      "cpit = 1.456811637515548\n",
      "rpu_control: 0.17\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.26\n",
      "nipu_ft: -0.19\n",
      "rpu_cohort: 0.21\n",
      "nipu_cohort: -0.11\n",
      "lift targeted cohort vs control: 0.24\n",
      "lift random vs control: 0.56\n",
      "cpit cohort vs control: 1.20\n",
      "lift targeted-treated vs control: 0.54\n",
      "cpit cohort: 1.203335\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.60\n",
      "treated_target_rpu: 0.26\n",
      "treated_target_nipu: -0.16\n",
      "nontreated_target_rpu: 0.18\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.27\n",
      "treated_nontarget_nipu: -0.23\n",
      "nontreated_nontarget_rpu: 0.15\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 59.9983157579557% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.275779942045359\n",
      "--> in non-targeted users: \n",
      "cpit = 1.4208495267309118\n",
      "rpu_control: 0.17\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.26\n",
      "nipu_ft: -0.19\n",
      "rpu_cohort: 0.22\n",
      "nipu_cohort: -0.12\n",
      "lift targeted cohort vs control: 0.27\n",
      "lift random vs control: 0.56\n",
      "cpit cohort vs control: 1.27\n",
      "lift targeted-treated vs control: 0.52\n",
      "cpit cohort: 1.274940\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.70\n",
      "treated_target_rpu: 0.26\n",
      "treated_target_nipu: -0.17\n",
      "nontreated_target_rpu: 0.18\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.28\n",
      "treated_nontarget_nipu: -0.24\n",
      "nontreated_nontarget_rpu: 0.15\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 69.99803505094833% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.3044233881261103\n",
      "--> in non-targeted users: \n",
      "cpit = 1.415178647429036\n",
      "rpu_control: 0.17\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.26\n",
      "nipu_ft: -0.19\n",
      "rpu_cohort: 0.23\n",
      "nipu_cohort: -0.13\n",
      "lift targeted cohort vs control: 0.34\n",
      "lift random vs control: 0.56\n",
      "cpit cohort vs control: 1.30\n",
      "lift targeted-treated vs control: 0.52\n",
      "cpit cohort: 1.304805\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.80\n",
      "treated_target_rpu: 0.26\n",
      "treated_target_nipu: -0.17\n",
      "nontreated_target_rpu: 0.17\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.29\n",
      "treated_nontarget_nipu: -0.25\n",
      "nontreated_nontarget_rpu: 0.15\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 79.99775434394094% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.3482149248249018\n",
      "--> in non-targeted users: \n",
      "cpit = 1.350109194333962\n",
      "rpu_control: 0.17\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.26\n",
      "nipu_ft: -0.19\n",
      "rpu_cohort: 0.24\n",
      "nipu_cohort: -0.15\n",
      "lift targeted cohort vs control: 0.40\n",
      "lift random vs control: 0.56\n",
      "cpit cohort vs control: 1.35\n",
      "lift targeted-treated vs control: 0.53\n",
      "cpit cohort: 1.348412\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.90\n",
      "treated_target_rpu: 0.26\n",
      "treated_target_nipu: -0.18\n",
      "nontreated_target_rpu: 0.17\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.29\n",
      "treated_nontarget_nipu: -0.26\n",
      "nontreated_nontarget_rpu: 0.13\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 89.99747363693356% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.3792670389922377\n",
      "--> in non-targeted users: \n",
      "cpit = 1.2066272738701174\n",
      "rpu_control: 0.17\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.26\n",
      "nipu_ft: -0.19\n",
      "rpu_cohort: 0.25\n",
      "nipu_cohort: -0.17\n",
      "lift targeted cohort vs control: 0.46\n",
      "lift random vs control: 0.56\n",
      "cpit cohort vs control: 1.38\n",
      "lift targeted-treated vs control: 0.54\n",
      "cpit cohort: 1.379469\n",
      "rpu_cohort\n",
      "0.24733990020038904\n",
      "treated_target_rpu\n",
      "0.26410244865732124\n",
      "---------------------------->>>>>>\n",
      "perc - target: 1.00\n",
      "treated_target_rpu: 0.26\n",
      "treated_target_nipu: -0.19\n",
      "nontreated_target_rpu: 0.17\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.00\n",
      "treated_nontarget_nipu: -1.26\n",
      "nontreated_nontarget_rpu: 0.00\n",
      "nontreated_nontarget_nipu: 0.00\n",
      "--- with 99.99719292992617% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.3484671912105848\n",
      "--> in non-targeted users: \n",
      "cpit = inf\n",
      "rpu_control: 0.17\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.26\n",
      "nipu_ft: -0.19\n",
      "rpu_cohort: 0.26\n",
      "nipu_cohort: -0.19\n",
      "lift targeted cohort vs control: 0.56\n",
      "lift random vs control: 0.56\n",
      "cpit cohort vs control: 1.35\n",
      "lift targeted-treated vs control: 0.56\n",
      "cpit cohort: 1.348443\n",
      "rpu_control: 0.16929032468981642\n",
      "nipu_control: -0.05992151597869827\n",
      "rpu_ft: 0.2640930222848291\n",
      "nipu_ft: -0.18780860567102814\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.10\n",
      "treated_target_rpu: 0.31\n",
      "treated_target_nipu: -0.11\n",
      "nontreated_target_rpu: 0.22\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.26\n",
      "treated_nontarget_nipu: -0.20\n",
      "nontreated_nontarget_rpu: 0.16\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 9.999719292992618% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 0.5805735039403072\n",
      "--> in non-targeted users: \n",
      "cpit = 1.4235713781539865\n",
      "rpu_control: 0.17\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.26\n",
      "nipu_ft: -0.19\n",
      "rpu_cohort: 0.18\n",
      "nipu_cohort: -0.06\n",
      "lift targeted cohort vs control: 0.05\n",
      "lift random vs control: 0.56\n",
      "cpit cohort vs control: 0.58\n",
      "lift targeted-treated vs control: 0.81\n",
      "cpit cohort: 0.582020\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.20\n",
      "treated_target_rpu: 0.27\n",
      "treated_target_nipu: -0.12\n",
      "nontreated_target_rpu: 0.18\n",
      "nontreated_target_nipu: -0.05\n",
      "treated_nontarget_rpu: 0.26\n",
      "treated_nontarget_nipu: -0.20\n",
      "nontreated_nontarget_rpu: 0.17\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 19.999438585985235% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 0.8256417099329857\n",
      "--> in non-targeted users: \n",
      "cpit = 1.4653425982610826\n",
      "rpu_control: 0.17\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.26\n",
      "nipu_ft: -0.19\n",
      "rpu_cohort: 0.19\n",
      "nipu_cohort: -0.07\n",
      "lift targeted cohort vs control: 0.10\n",
      "lift random vs control: 0.56\n",
      "cpit cohort vs control: 0.83\n",
      "lift targeted-treated vs control: 0.57\n",
      "cpit cohort: 0.825260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------->>>>>>\n",
      "perc - target: 0.30\n",
      "treated_target_rpu: 0.26\n",
      "treated_target_nipu: -0.13\n",
      "nontreated_target_rpu: 0.18\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.26\n",
      "treated_nontarget_nipu: -0.21\n",
      "nontreated_nontarget_rpu: 0.16\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 29.99915787897785% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 0.8684251353044907\n",
      "--> in non-targeted users: \n",
      "cpit = 1.523622504406445\n",
      "rpu_control: 0.17\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.26\n",
      "nipu_ft: -0.19\n",
      "rpu_cohort: 0.19\n",
      "nipu_cohort: -0.08\n",
      "lift targeted cohort vs control: 0.15\n",
      "lift random vs control: 0.56\n",
      "cpit cohort vs control: 0.87\n",
      "lift targeted-treated vs control: 0.56\n",
      "cpit cohort: 0.868374\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.40\n",
      "treated_target_rpu: 0.27\n",
      "treated_target_nipu: -0.14\n",
      "nontreated_target_rpu: 0.17\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.26\n",
      "treated_nontarget_nipu: -0.22\n",
      "nontreated_nontarget_rpu: 0.17\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 39.99887717197047% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 0.8822693971306546\n",
      "--> in non-targeted users: \n",
      "cpit = 1.6416212704744755\n",
      "rpu_control: 0.17\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.26\n",
      "nipu_ft: -0.19\n",
      "rpu_cohort: 0.21\n",
      "nipu_cohort: -0.09\n",
      "lift targeted cohort vs control: 0.22\n",
      "lift random vs control: 0.56\n",
      "cpit cohort vs control: 0.88\n",
      "lift targeted-treated vs control: 0.57\n",
      "cpit cohort: 0.882101\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.50\n",
      "treated_target_rpu: 0.26\n",
      "treated_target_nipu: -0.14\n",
      "nontreated_target_rpu: 0.17\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.27\n",
      "treated_nontarget_nipu: -0.23\n",
      "nontreated_nontarget_rpu: 0.16\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 49.998596464963086% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.0728862199312827\n",
      "--> in non-targeted users: \n",
      "cpit = 1.5618738635887939\n",
      "rpu_control: 0.17\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.26\n",
      "nipu_ft: -0.19\n",
      "rpu_cohort: 0.21\n",
      "nipu_cohort: -0.10\n",
      "lift targeted cohort vs control: 0.24\n",
      "lift random vs control: 0.56\n",
      "cpit cohort vs control: 1.07\n",
      "lift targeted-treated vs control: 0.52\n",
      "cpit cohort: 1.072801\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.60\n",
      "treated_target_rpu: 0.25\n",
      "treated_target_nipu: -0.15\n",
      "nontreated_target_rpu: 0.17\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.28\n",
      "treated_nontarget_nipu: -0.24\n",
      "nontreated_nontarget_rpu: 0.17\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 59.9983157579557% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.1218393861221527\n",
      "--> in non-targeted users: \n",
      "cpit = 1.596831856217488\n",
      "rpu_control: 0.17\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.26\n",
      "nipu_ft: -0.19\n",
      "rpu_cohort: 0.22\n",
      "nipu_cohort: -0.12\n",
      "lift targeted cohort vs control: 0.29\n",
      "lift random vs control: 0.56\n",
      "cpit cohort vs control: 1.12\n",
      "lift targeted-treated vs control: 0.50\n",
      "cpit cohort: 1.121701\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.70\n",
      "treated_target_rpu: 0.25\n",
      "treated_target_nipu: -0.16\n",
      "nontreated_target_rpu: 0.17\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.30\n",
      "treated_nontarget_nipu: -0.25\n",
      "nontreated_nontarget_rpu: 0.17\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 69.99803505094833% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.2569123263969801\n",
      "--> in non-targeted users: \n",
      "cpit = 1.4802232765428576\n",
      "rpu_control: 0.17\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.26\n",
      "nipu_ft: -0.19\n",
      "rpu_cohort: 0.23\n",
      "nipu_cohort: -0.13\n",
      "lift targeted cohort vs control: 0.33\n",
      "lift random vs control: 0.56\n",
      "cpit cohort vs control: 1.26\n",
      "lift targeted-treated vs control: 0.48\n",
      "cpit cohort: 1.256988\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.80\n",
      "treated_target_rpu: 0.25\n",
      "treated_target_nipu: -0.17\n",
      "nontreated_target_rpu: 0.17\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.30\n",
      "treated_nontarget_nipu: -0.27\n",
      "nontreated_nontarget_rpu: 0.15\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 79.99775434394094% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.320263351171631\n",
      "--> in non-targeted users: \n",
      "cpit = 1.4098648204045061\n",
      "rpu_control: 0.17\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.26\n",
      "nipu_ft: -0.19\n",
      "rpu_cohort: 0.23\n",
      "nipu_cohort: -0.15\n",
      "lift targeted cohort vs control: 0.38\n",
      "lift random vs control: 0.56\n",
      "cpit cohort vs control: 1.32\n",
      "lift targeted-treated vs control: 0.51\n",
      "cpit cohort: 1.320768\n",
      "---------------------------->>>>>>\n",
      "perc - target: 0.90\n",
      "treated_target_rpu: 0.26\n",
      "treated_target_nipu: -0.17\n",
      "nontreated_target_rpu: 0.17\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.30\n",
      "treated_nontarget_nipu: -0.30\n",
      "nontreated_nontarget_rpu: 0.15\n",
      "nontreated_nontarget_nipu: -0.06\n",
      "--- with 89.99747363693356% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.3006080987931887\n",
      "--> in non-targeted users: \n",
      "cpit = 1.6013784552650563\n",
      "rpu_control: 0.17\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.26\n",
      "nipu_ft: -0.19\n",
      "rpu_cohort: 0.25\n",
      "nipu_cohort: -0.16\n",
      "lift targeted cohort vs control: 0.47\n",
      "lift random vs control: 0.56\n",
      "cpit cohort vs control: 1.30\n",
      "lift targeted-treated vs control: 0.53\n",
      "cpit cohort: 1.300816\n",
      "rpu_cohort\n",
      "0.24896818617713293\n",
      "treated_target_rpu\n",
      "0.2641005633289898\n",
      "---------------------------->>>>>>\n",
      "perc - target: 1.00\n",
      "treated_target_rpu: 0.26\n",
      "treated_target_nipu: -0.19\n",
      "nontreated_target_rpu: 0.17\n",
      "nontreated_target_nipu: -0.06\n",
      "treated_nontarget_rpu: 0.00\n",
      "treated_nontarget_nipu: 0.00\n",
      "nontreated_nontarget_rpu: 0.00\n",
      "nontreated_nontarget_nipu: 0.00\n",
      "--- with 99.99719292992617% targeting, print cpits to treat users and create incrementality in users ---\n",
      "--> in targeted users: \n",
      "cpit = 1.3489790569740938\n",
      "--> in non-targeted users: \n",
      "cpit = nan\n",
      "rpu_control: 0.17\n",
      "nipu_control: -0.06\n",
      "rpu_ft: 0.26\n",
      "nipu_ft: -0.19\n",
      "rpu_cohort: 0.26\n",
      "nipu_cohort: -0.19\n",
      "lift targeted cohort vs control: 0.56\n",
      "lift random vs control: 0.56\n",
      "cpit cohort vs control: 1.35\n",
      "lift targeted-treated vs control: 0.56\n",
      "cpit cohort: 1.348931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../experimentation.py:154: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cpit_nontargeted = -1.0 * (treated_untarget_nipu - untreated_untarget_nipu) / (treated_untarget_rpu - untreated_untarget_rpu)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp:\n",
      "3.0469917555770163\n",
      "p_quantile:\n",
      "0.3\n",
      "AUCC results: \n",
      "random: [0.5]\n",
      "rlearner: [0.48472446]\n",
      "duality rlearner 1 with lambda = 1.0:[0.55093487]\n",
      "drm: [0.55433062]\n",
      "tqr: [0.53898977]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lhmodels = LinearHTEModels() \n",
    "lambds = [5.0] #[50, 10, 5.0, 1.0, 0.5, 0.1, 0.01, 0.001] #[0.001, 0.0001, 0.00001] #[0.5, 0.1, 0.01] #[5.0, 1.0] #[0.01, 0.001] #[0.0001, 0.00001] \n",
    "rlearnerscores = [] \n",
    "rl_ridge_model_L_list = [] \n",
    "## set-up lagrangian rlearner \n",
    "for i in range(len(lambds)): \n",
    "    lambd = lambds[i] \n",
    "    rl_ridge_model_L = lhmodels.fit_rlearner_lagrangian(D, o, c, w, lambd) \n",
    "    rl_ridge_model_L_list.append(rl_ridge_model_L) \n",
    "    rlearnerscores.append(rl_ridge_model_L.predict(Dt)) \n",
    "\n",
    "### ---- experimentation and plotting cost-curves ----- \n",
    "from experimentation import * \n",
    "exp = Experimentation() \n",
    "ranscore = np.random.rand(ot.shape[0], ) \n",
    "colors = ['b', 'c', 'g', 'y', 'b', 'c', 'g', 'y', 'b', 'c', 'g', 'y', 'b', 'c', 'g', 'y'] \n",
    "plt.figure() \n",
    "rlearnerauccs = [] \n",
    "ranaucc = exp.AUC_cpit_cost_curve_deciles_cohort(ranscore, ot, wt, -1.0 * ct, 'k', plot_random=True) \n",
    "quasiaucc = exp.AUC_cpit_cost_curve_deciles_cohort(pred_values_va_rlearner_O, ot, wt, -1.0 * ct, 'c') \n",
    "for i in range(len(lambds)): \n",
    "    rlearnerauccs.append(exp.AUC_cpit_cost_curve_deciles_cohort(rlearnerscores[i], ot, wt, -1.0 * ct, colors[i] )) \n",
    "#cfaucc = exp.AUC_cpit_cost_curve_deciles_cohort(cfscore, ot, wt, -1.0 * ct, 'g') # causal forest aucc and plotting \n",
    "tqraucc = exp.AUC_cpit_cost_curve_deciles_cohort(tqrscore, ot, wt, -1.0 * ct, 'r' ) \n",
    "drmaucc = exp.AUC_cpit_cost_curve_deciles_cohort(drmscore, ot, wt, -1.0 * ct, 'm' ) \n",
    "plt.title('Causal learning cost curves using targeting models') \n",
    "\n",
    "### --- saving data to results folder ---- \n",
    "save_filename = '../results/benchmarkwithcv_tqr_drm_hte_'+prefix+'_main_results.pkl' \n",
    "saveD = {'tqrscore':tqrscore, 'drmscore':drmscore, 'quasiscore':pred_values_va_rlearner, 'quasiscore_O':pred_values_va_rlearner_O, 'rlearnerscore':rlearnerscores, 'ot':ot, 'wt':wt, 'ct':ct, 'tempvalue':tempvalue, 'p_quantilevalue':p_quantilevalue, \n",
    "         'tqraucc':tqraucc, 'drmaucc':drmaucc, 'rlearnerauccs':rlearnerauccs, 'ranaucc':ranaucc, 'quasiaucc':quasiaucc} \n",
    "#'cfscore':cfscore, causal forest scores \n",
    "pkl.dump(saveD, open(save_filename, 'w')) \n",
    "\n",
    "print('temp:') \n",
    "print(tempvalue) \n",
    "print('p_quantile:') \n",
    "print(p_quantilevalue) \n",
    "\n",
    "### --- add legeneds to plot ---- \n",
    "leg_str = ['Random'] \n",
    "leg_str.append('R-learner on Incremental Gain') \n",
    "for i in range(len(lambds)): \n",
    "    leg_str.append('Duality R-learner lambda='+str(lambds[i])) \n",
    "#leg_str.append('Causal Forest') # causal forest result \n",
    "leg_str.append('Top Quantile Ranking at ' + str(p_quantile*100) + '%') \n",
    "leg_str.append('Direct Ranking Model') \n",
    "plt.legend(leg_str) \n",
    "\n",
    "### --- print out aucc results for different models --- \n",
    "print('AUCC results: ') \n",
    "print('random: ' + str(ranaucc)) \n",
    "print('rlearner: ' + str(quasiaucc)) \n",
    "i = 0\n",
    "for rlearneraucc in rlearnerauccs: \n",
    "    print('duality rlearner ' + str(i + 1) + ' with lambda = ' + str(lambds[i]) + ':' + str(rlearneraucc)) \n",
    "    i = i + 1\n",
    "print('drm: ' + str(drmaucc)) \n",
    "print('tqr: ' + str(tqraucc)) \n",
    "\n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
